{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43e5b74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import notebook_login\n",
    "\n",
    "# notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3405b5e2-9efa-478b-b812-7eb046b4a543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !huggingface-cli login "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bca9377-bcec-41bd-b15a-0951e1ff6cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jclynn\r\n",
      "\u001b[1morgs: \u001b[0m pinnacleaerospace\r\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli whoami"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682cc4d4-ebb1-4e48-b84e-1e62006da233",
   "metadata": {},
   "source": [
    "# Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f61331a7-f1dd-442e-b58a-a5adb337fec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"]=\"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "873ec5c8-c16a-4697-86b5-e22292d3266a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/it/anaconda3/envs/genety/lib/python3.11/site-packages/torchtext/data/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-14 11:08:58,504] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
      "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/it/anaconda3/envs/genety/compiler_compat/ld: /lib/x86_64-linux-gnu/libc.so.6: undefined reference to `_dl_audit_symbind_alt@GLIBC_PRIVATE'\n",
      "/home/it/anaconda3/envs/genety/compiler_compat/ld: /lib/x86_64-linux-gnu/libc.so.6: undefined reference to `__nptl_change_stack_perm@GLIBC_PRIVATE'\n",
      "/home/it/anaconda3/envs/genety/compiler_compat/ld: /lib/x86_64-linux-gnu/libc.so.6: undefined reference to `_dl_find_dso_for_object@GLIBC_PRIVATE'\n",
      "/home/it/anaconda3/envs/genety/compiler_compat/ld: /lib/x86_64-linux-gnu/libc.so.6: undefined reference to `_dl_fatal_printf@GLIBC_PRIVATE'\n",
      "/home/it/anaconda3/envs/genety/compiler_compat/ld: /lib/x86_64-linux-gnu/libc.so.6: undefined reference to `_dl_exception_create@GLIBC_PRIVATE'\n",
      "/home/it/anaconda3/envs/genety/compiler_compat/ld: /lib/x86_64-linux-gnu/libc.so.6: undefined reference to `__tunable_get_val@GLIBC_PRIVATE'\n",
      "/home/it/anaconda3/envs/genety/compiler_compat/ld: /lib/x86_64-linux-gnu/libc.so.6: undefined reference to `_dl_audit_preinit@GLIBC_PRIVATE'\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "\n",
    "from sklearn.model_selection  import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "from datetime import datetime, date\n",
    "import time\n",
    "\n",
    "# DeepSpeed ZeRO-3\n",
    "import deepspeed\n",
    "from deepspeed.accelerator import get_accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edd5b450-0317-4c55-847e-7723042940f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "# device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8522ac8-36cb-45f8-9ea5-8a7abf01db15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free(GB): 23.25750732421875, Global(GB): 23.64971923828125, Free(%): 0.9834157898404292\n"
     ]
    }
   ],
   "source": [
    "(free_memory, global_memory) = torch.cuda.mem_get_info()\n",
    "print(f\"Free(GB): {free_memory/1024/1024/1024}, Global(GB): {global_memory/1024/1024/1024}, Free(%): {free_memory/global_memory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c439d2-2280-4823-90dd-0867012b907c",
   "metadata": {},
   "source": [
    "# Load Excel File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a715f751-ab65-45a3-ae17-c795b8c78d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Identity</th>\n",
       "      <th>Text</th>\n",
       "      <th>A2-Unambiguous</th>\n",
       "      <th>A4-Tolerances</th>\n",
       "      <th>A5-Sources specified</th>\n",
       "      <th>E1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GSS_CONNECTIVITY</td>\n",
       "      <td>SRD_GSS_FUNC_61</td>\n",
       "      <td>The User and Rights Administration HMI shall p...</td>\n",
       "      <td>1</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cobham_ATR</td>\n",
       "      <td>SHLR-ATR2146</td>\n",
       "      <td>The Network Function shall support WiFi 802.11...</td>\n",
       "      <td>1</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cobham_ATR</td>\n",
       "      <td>SHLR-ATR797</td>\n",
       "      <td>The PwrCon software shall monitor the output v...</td>\n",
       "      <td>1</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cobham_ATR</td>\n",
       "      <td>SHLR-ATR3013</td>\n",
       "      <td>When prompted, the TETRA Software shall place ...</td>\n",
       "      <td>1</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cobham_ATR</td>\n",
       "      <td>SHLR-ATR3198</td>\n",
       "      <td>The TETRA software shall allow users to select...</td>\n",
       "      <td>1</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Type         Identity  \\\n",
       "0  GSS_CONNECTIVITY  SRD_GSS_FUNC_61   \n",
       "1        Cobham_ATR     SHLR-ATR2146   \n",
       "2        Cobham_ATR      SHLR-ATR797   \n",
       "3        Cobham_ATR     SHLR-ATR3013   \n",
       "4        Cobham_ATR     SHLR-ATR3198   \n",
       "\n",
       "                                                Text A2-Unambiguous  \\\n",
       "0  The User and Rights Administration HMI shall p...              1   \n",
       "1  The Network Function shall support WiFi 802.11...              1   \n",
       "2  The PwrCon software shall monitor the output v...              1   \n",
       "3  When prompted, the TETRA Software shall place ...              1   \n",
       "4  The TETRA software shall allow users to select...              1   \n",
       "\n",
       "  A4-Tolerances A5-Sources specified  E1  \n",
       "0            na                   na   1  \n",
       "1            na                   na   1  \n",
       "2            na                   na   1  \n",
       "3            na                   na   1  \n",
       "4            na                   na   1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "master_df = pd.read_excel('./DATASETS/Training_Dataset.xlsx')\n",
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70bdf637-9e84-4cee-a95c-e5c7bd8075d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E1</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The User and Rights Administration HMI shall p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The Network Function shall support WiFi 802.11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>The PwrCon software shall monitor the output v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>When prompted, the TETRA Software shall place ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>The TETRA software shall allow users to select...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   E1                                               Text\n",
       "0   1  The User and Rights Administration HMI shall p...\n",
       "1   1  The Network Function shall support WiFi 802.11...\n",
       "2   1  The PwrCon software shall monitor the output v...\n",
       "3   1  When prompted, the TETRA Software shall place ...\n",
       "4   1  The TETRA software shall allow users to select..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df = master_df[['E1','Text']].copy()\n",
    "model_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9296d035-a173-4c8e-81d9-a30a5021dcc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3255 entries, 0 to 3254\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   E1      3255 non-null   int64 \n",
      " 1   Text    3255 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 51.0+ KB\n"
     ]
    }
   ],
   "source": [
    "model_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c738bf70-5be7-4b1e-9d88-1e09f2f497a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2127"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df_label1 = model_df.query('E1 == 1')\n",
    "len(model_df_label1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a967f2ce-ce0f-4aa7-8b6e-759011eef775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1128"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df_label0 = model_df.query('E1 == 0')\n",
    "len(model_df_label0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fceb9f5-cd13-4779-b8db-57ff9cda386f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = pd.concat([model_df_label1[:1000],model_df_label0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea7716b-cbb9-40df-8796-9e2718512f6b",
   "metadata": {},
   "source": [
    "# Data process and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4e0084e-559e-46cc-b1a4-892e5e0fcb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection  import train_test_split\n",
    "train_df, test_df = train_test_split(model_df, test_size=0.1, shuffle=True)\n",
    "\n",
    "train_iter = iter(list(train_df.itertuples(index=False, name=None)))\n",
    "test_iter = iter(list(test_df.itertuples(index=False, name=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6daca09-ad60-40b6-90f2-e91c79aabb0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1915"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6424905-7a3d-4fd5-a22d-f2be29be1f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/it/.cache/torch/hub/huggingface_pytorch-transformers_main\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = torch.hub.load(\n",
    "    \"huggingface/pytorch-transformers\",\n",
    "    \"tokenizer\",\n",
    "    # \"meta-llama/Llama-2-7b-hf\",\n",
    "    \"meta-llama/Meta-Llama-3-8B\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc4e1ac2-7bff-4984-8bf5-bde7daceef2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='meta-llama/Meta-Llama-3-8B', vocab_size=128000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|begin_of_text|>', 'eos_token': '<|end_of_text|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t128000: AddedToken(\"<|begin_of_text|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128001: AddedToken(\"<|end_of_text|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128002: AddedToken(\"<|reserved_special_token_0|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128003: AddedToken(\"<|reserved_special_token_1|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128004: AddedToken(\"<|reserved_special_token_2|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128005: AddedToken(\"<|reserved_special_token_3|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128006: AddedToken(\"<|start_header_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128007: AddedToken(\"<|end_header_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128008: AddedToken(\"<|reserved_special_token_4|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128009: AddedToken(\"<|eot_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128010: AddedToken(\"<|reserved_special_token_5|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128011: AddedToken(\"<|reserved_special_token_6|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128012: AddedToken(\"<|reserved_special_token_7|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128013: AddedToken(\"<|reserved_special_token_8|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128014: AddedToken(\"<|reserved_special_token_9|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128015: AddedToken(\"<|reserved_special_token_10|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128016: AddedToken(\"<|reserved_special_token_11|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128017: AddedToken(\"<|reserved_special_token_12|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128018: AddedToken(\"<|reserved_special_token_13|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128019: AddedToken(\"<|reserved_special_token_14|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128020: AddedToken(\"<|reserved_special_token_15|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128021: AddedToken(\"<|reserved_special_token_16|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128022: AddedToken(\"<|reserved_special_token_17|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128023: AddedToken(\"<|reserved_special_token_18|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128024: AddedToken(\"<|reserved_special_token_19|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128025: AddedToken(\"<|reserved_special_token_20|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128026: AddedToken(\"<|reserved_special_token_21|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128027: AddedToken(\"<|reserved_special_token_22|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128028: AddedToken(\"<|reserved_special_token_23|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128029: AddedToken(\"<|reserved_special_token_24|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128030: AddedToken(\"<|reserved_special_token_25|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128031: AddedToken(\"<|reserved_special_token_26|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128032: AddedToken(\"<|reserved_special_token_27|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128033: AddedToken(\"<|reserved_special_token_28|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128034: AddedToken(\"<|reserved_special_token_29|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128035: AddedToken(\"<|reserved_special_token_30|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128036: AddedToken(\"<|reserved_special_token_31|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128037: AddedToken(\"<|reserved_special_token_32|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128038: AddedToken(\"<|reserved_special_token_33|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128039: AddedToken(\"<|reserved_special_token_34|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128040: AddedToken(\"<|reserved_special_token_35|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128041: AddedToken(\"<|reserved_special_token_36|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128042: AddedToken(\"<|reserved_special_token_37|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128043: AddedToken(\"<|reserved_special_token_38|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128044: AddedToken(\"<|reserved_special_token_39|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128045: AddedToken(\"<|reserved_special_token_40|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128046: AddedToken(\"<|reserved_special_token_41|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128047: AddedToken(\"<|reserved_special_token_42|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128048: AddedToken(\"<|reserved_special_token_43|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128049: AddedToken(\"<|reserved_special_token_44|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128050: AddedToken(\"<|reserved_special_token_45|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128051: AddedToken(\"<|reserved_special_token_46|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128052: AddedToken(\"<|reserved_special_token_47|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128053: AddedToken(\"<|reserved_special_token_48|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128054: AddedToken(\"<|reserved_special_token_49|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128055: AddedToken(\"<|reserved_special_token_50|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128056: AddedToken(\"<|reserved_special_token_51|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128057: AddedToken(\"<|reserved_special_token_52|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128058: AddedToken(\"<|reserved_special_token_53|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128059: AddedToken(\"<|reserved_special_token_54|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128060: AddedToken(\"<|reserved_special_token_55|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128061: AddedToken(\"<|reserved_special_token_56|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128062: AddedToken(\"<|reserved_special_token_57|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128063: AddedToken(\"<|reserved_special_token_58|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128064: AddedToken(\"<|reserved_special_token_59|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128065: AddedToken(\"<|reserved_special_token_60|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128066: AddedToken(\"<|reserved_special_token_61|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128067: AddedToken(\"<|reserved_special_token_62|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128068: AddedToken(\"<|reserved_special_token_63|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128069: AddedToken(\"<|reserved_special_token_64|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128070: AddedToken(\"<|reserved_special_token_65|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128071: AddedToken(\"<|reserved_special_token_66|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128072: AddedToken(\"<|reserved_special_token_67|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128073: AddedToken(\"<|reserved_special_token_68|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128074: AddedToken(\"<|reserved_special_token_69|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128075: AddedToken(\"<|reserved_special_token_70|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128076: AddedToken(\"<|reserved_special_token_71|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128077: AddedToken(\"<|reserved_special_token_72|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128078: AddedToken(\"<|reserved_special_token_73|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128079: AddedToken(\"<|reserved_special_token_74|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128080: AddedToken(\"<|reserved_special_token_75|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128081: AddedToken(\"<|reserved_special_token_76|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128082: AddedToken(\"<|reserved_special_token_77|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128083: AddedToken(\"<|reserved_special_token_78|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128084: AddedToken(\"<|reserved_special_token_79|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128085: AddedToken(\"<|reserved_special_token_80|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128086: AddedToken(\"<|reserved_special_token_81|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128087: AddedToken(\"<|reserved_special_token_82|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128088: AddedToken(\"<|reserved_special_token_83|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128089: AddedToken(\"<|reserved_special_token_84|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128090: AddedToken(\"<|reserved_special_token_85|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128091: AddedToken(\"<|reserved_special_token_86|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128092: AddedToken(\"<|reserved_special_token_87|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128093: AddedToken(\"<|reserved_special_token_88|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128094: AddedToken(\"<|reserved_special_token_89|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128095: AddedToken(\"<|reserved_special_token_90|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128096: AddedToken(\"<|reserved_special_token_91|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128097: AddedToken(\"<|reserved_special_token_92|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128098: AddedToken(\"<|reserved_special_token_93|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128099: AddedToken(\"<|reserved_special_token_94|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128100: AddedToken(\"<|reserved_special_token_95|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128101: AddedToken(\"<|reserved_special_token_96|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128102: AddedToken(\"<|reserved_special_token_97|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128103: AddedToken(\"<|reserved_special_token_98|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128104: AddedToken(\"<|reserved_special_token_99|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128105: AddedToken(\"<|reserved_special_token_100|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128106: AddedToken(\"<|reserved_special_token_101|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128107: AddedToken(\"<|reserved_special_token_102|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128108: AddedToken(\"<|reserved_special_token_103|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128109: AddedToken(\"<|reserved_special_token_104|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128110: AddedToken(\"<|reserved_special_token_105|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128111: AddedToken(\"<|reserved_special_token_106|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128112: AddedToken(\"<|reserved_special_token_107|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128113: AddedToken(\"<|reserved_special_token_108|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128114: AddedToken(\"<|reserved_special_token_109|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128115: AddedToken(\"<|reserved_special_token_110|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128116: AddedToken(\"<|reserved_special_token_111|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128117: AddedToken(\"<|reserved_special_token_112|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128118: AddedToken(\"<|reserved_special_token_113|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128119: AddedToken(\"<|reserved_special_token_114|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128120: AddedToken(\"<|reserved_special_token_115|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128121: AddedToken(\"<|reserved_special_token_116|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128122: AddedToken(\"<|reserved_special_token_117|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128123: AddedToken(\"<|reserved_special_token_118|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128124: AddedToken(\"<|reserved_special_token_119|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128125: AddedToken(\"<|reserved_special_token_120|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128126: AddedToken(\"<|reserved_special_token_121|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128127: AddedToken(\"<|reserved_special_token_122|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128128: AddedToken(\"<|reserved_special_token_123|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128129: AddedToken(\"<|reserved_special_token_124|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128130: AddedToken(\"<|reserved_special_token_125|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128131: AddedToken(\"<|reserved_special_token_126|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128132: AddedToken(\"<|reserved_special_token_127|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128133: AddedToken(\"<|reserved_special_token_128|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128134: AddedToken(\"<|reserved_special_token_129|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128135: AddedToken(\"<|reserved_special_token_130|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128136: AddedToken(\"<|reserved_special_token_131|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128137: AddedToken(\"<|reserved_special_token_132|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128138: AddedToken(\"<|reserved_special_token_133|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128139: AddedToken(\"<|reserved_special_token_134|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128140: AddedToken(\"<|reserved_special_token_135|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128141: AddedToken(\"<|reserved_special_token_136|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128142: AddedToken(\"<|reserved_special_token_137|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128143: AddedToken(\"<|reserved_special_token_138|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128144: AddedToken(\"<|reserved_special_token_139|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128145: AddedToken(\"<|reserved_special_token_140|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128146: AddedToken(\"<|reserved_special_token_141|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128147: AddedToken(\"<|reserved_special_token_142|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128148: AddedToken(\"<|reserved_special_token_143|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128149: AddedToken(\"<|reserved_special_token_144|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128150: AddedToken(\"<|reserved_special_token_145|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128151: AddedToken(\"<|reserved_special_token_146|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128152: AddedToken(\"<|reserved_special_token_147|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128153: AddedToken(\"<|reserved_special_token_148|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128154: AddedToken(\"<|reserved_special_token_149|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128155: AddedToken(\"<|reserved_special_token_150|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128156: AddedToken(\"<|reserved_special_token_151|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128157: AddedToken(\"<|reserved_special_token_152|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128158: AddedToken(\"<|reserved_special_token_153|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128159: AddedToken(\"<|reserved_special_token_154|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128160: AddedToken(\"<|reserved_special_token_155|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128161: AddedToken(\"<|reserved_special_token_156|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128162: AddedToken(\"<|reserved_special_token_157|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128163: AddedToken(\"<|reserved_special_token_158|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128164: AddedToken(\"<|reserved_special_token_159|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128165: AddedToken(\"<|reserved_special_token_160|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128166: AddedToken(\"<|reserved_special_token_161|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128167: AddedToken(\"<|reserved_special_token_162|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128168: AddedToken(\"<|reserved_special_token_163|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128169: AddedToken(\"<|reserved_special_token_164|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128170: AddedToken(\"<|reserved_special_token_165|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128171: AddedToken(\"<|reserved_special_token_166|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128172: AddedToken(\"<|reserved_special_token_167|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128173: AddedToken(\"<|reserved_special_token_168|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128174: AddedToken(\"<|reserved_special_token_169|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128175: AddedToken(\"<|reserved_special_token_170|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128176: AddedToken(\"<|reserved_special_token_171|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128177: AddedToken(\"<|reserved_special_token_172|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128178: AddedToken(\"<|reserved_special_token_173|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128179: AddedToken(\"<|reserved_special_token_174|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128180: AddedToken(\"<|reserved_special_token_175|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128181: AddedToken(\"<|reserved_special_token_176|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128182: AddedToken(\"<|reserved_special_token_177|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128183: AddedToken(\"<|reserved_special_token_178|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128184: AddedToken(\"<|reserved_special_token_179|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128185: AddedToken(\"<|reserved_special_token_180|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128186: AddedToken(\"<|reserved_special_token_181|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128187: AddedToken(\"<|reserved_special_token_182|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128188: AddedToken(\"<|reserved_special_token_183|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128189: AddedToken(\"<|reserved_special_token_184|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128190: AddedToken(\"<|reserved_special_token_185|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128191: AddedToken(\"<|reserved_special_token_186|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128192: AddedToken(\"<|reserved_special_token_187|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128193: AddedToken(\"<|reserved_special_token_188|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128194: AddedToken(\"<|reserved_special_token_189|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128195: AddedToken(\"<|reserved_special_token_190|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128196: AddedToken(\"<|reserved_special_token_191|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128197: AddedToken(\"<|reserved_special_token_192|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128198: AddedToken(\"<|reserved_special_token_193|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128199: AddedToken(\"<|reserved_special_token_194|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128200: AddedToken(\"<|reserved_special_token_195|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128201: AddedToken(\"<|reserved_special_token_196|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128202: AddedToken(\"<|reserved_special_token_197|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128203: AddedToken(\"<|reserved_special_token_198|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128204: AddedToken(\"<|reserved_special_token_199|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128205: AddedToken(\"<|reserved_special_token_200|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128206: AddedToken(\"<|reserved_special_token_201|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128207: AddedToken(\"<|reserved_special_token_202|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128208: AddedToken(\"<|reserved_special_token_203|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128209: AddedToken(\"<|reserved_special_token_204|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128210: AddedToken(\"<|reserved_special_token_205|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128211: AddedToken(\"<|reserved_special_token_206|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128212: AddedToken(\"<|reserved_special_token_207|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128213: AddedToken(\"<|reserved_special_token_208|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128214: AddedToken(\"<|reserved_special_token_209|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128215: AddedToken(\"<|reserved_special_token_210|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128216: AddedToken(\"<|reserved_special_token_211|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128217: AddedToken(\"<|reserved_special_token_212|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128218: AddedToken(\"<|reserved_special_token_213|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128219: AddedToken(\"<|reserved_special_token_214|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128220: AddedToken(\"<|reserved_special_token_215|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128221: AddedToken(\"<|reserved_special_token_216|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128222: AddedToken(\"<|reserved_special_token_217|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128223: AddedToken(\"<|reserved_special_token_218|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128224: AddedToken(\"<|reserved_special_token_219|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128225: AddedToken(\"<|reserved_special_token_220|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128226: AddedToken(\"<|reserved_special_token_221|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128227: AddedToken(\"<|reserved_special_token_222|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128228: AddedToken(\"<|reserved_special_token_223|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128229: AddedToken(\"<|reserved_special_token_224|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128230: AddedToken(\"<|reserved_special_token_225|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128231: AddedToken(\"<|reserved_special_token_226|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128232: AddedToken(\"<|reserved_special_token_227|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128233: AddedToken(\"<|reserved_special_token_228|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128234: AddedToken(\"<|reserved_special_token_229|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128235: AddedToken(\"<|reserved_special_token_230|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128236: AddedToken(\"<|reserved_special_token_231|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128237: AddedToken(\"<|reserved_special_token_232|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128238: AddedToken(\"<|reserved_special_token_233|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128239: AddedToken(\"<|reserved_special_token_234|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128240: AddedToken(\"<|reserved_special_token_235|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128241: AddedToken(\"<|reserved_special_token_236|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128242: AddedToken(\"<|reserved_special_token_237|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128243: AddedToken(\"<|reserved_special_token_238|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128244: AddedToken(\"<|reserved_special_token_239|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128245: AddedToken(\"<|reserved_special_token_240|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128246: AddedToken(\"<|reserved_special_token_241|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128247: AddedToken(\"<|reserved_special_token_242|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128248: AddedToken(\"<|reserved_special_token_243|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128249: AddedToken(\"<|reserved_special_token_244|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128250: AddedToken(\"<|reserved_special_token_245|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128251: AddedToken(\"<|reserved_special_token_246|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128252: AddedToken(\"<|reserved_special_token_247|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128253: AddedToken(\"<|reserved_special_token_248|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128254: AddedToken(\"<|reserved_special_token_249|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128255: AddedToken(\"<|reserved_special_token_250|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24d1986-12ed-45c3-8a18-bd1ada1e9440",
   "metadata": {},
   "source": [
    "# Dataset iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "880ea8d4-bae1-48bc-996e-d352db324265",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = iter(list(train_df.itertuples(index=False, name=None)))\n",
    "test_iter = iter(list(test_df.itertuples(index=False, name=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78c4e14f-9c36-4343-ba96-f05c6eb3196e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " 'The moduleServersApp (configured for PC-24) shall be capable of sending maintenance files, achievable through HTTP requests with URI in a determined format.')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "092203c5-49af-4337-abbd-38851caa6e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# function passed to the DataLoader to process a batch of data as indicated\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def collate_batch(batch):\n",
    "    # Get label and text\n",
    "    y, x = list(zip(*batch))\n",
    "\n",
    "    # Create list with indices from tokeniser\n",
    "    encoded_x = tokenizer(x, padding=True, truncation=True)\n",
    "    encoded_x.input_ids = torch.tensor(encoded_x.input_ids).to(device)\n",
    "    encoded_x.attention_mask = torch.tensor(encoded_x.attention_mask).to(device)  \n",
    "    \n",
    "    # Prepare the labels, by subtracting 1 to get them in the range 0-3\n",
    "    return encoded_x, torch.tensor(y, dtype=torch.long).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a81c8d9-de06-4aed-9ff3-0c5f31985d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'The FTP server shall set the data connection timeout specified in the Customization file')\n",
      "(0, 'The system shall be efficient.')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'input_ids': [[128000, 791, 48650, 3622, 4985, 743, 279, 828, 3717, 9829, 5300, 304, 279, 8572, 2065, 1052], [128000, 791, 1887, 4985, 387, 11297, 13, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]]},\n",
       " tensor([1, 0], device='cuda:0'))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_iter = iter(list(train_df.itertuples(index=False, name=None)))\n",
    "first = next(train_iter)\n",
    "second = next(train_iter)\n",
    "\n",
    "print(first)\n",
    "print(second)\n",
    "\n",
    "collate_batch([first, second])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d306ecb-d8ef-4389-ab6c-8fb803124ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-14 11:08:01,992] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-14 11:08:01,992] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-14 11:08:02,091] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=10.1.1.204, master_port=29500\n",
      "[2024-05-14 11:08:02,092] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "Using cache found in /home/it/.cache/torch/hub/huggingface_pytorch-transformers_main\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47768dc13f8143af8aaec423be13c308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Meta-Llama-3-8B and are newly initialized because the shapes did not match:\n",
      "- model.embed_tokens.weight: found shape torch.Size([128256, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.0.input_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.0.mlp.down_proj.weight: found shape torch.Size([4096, 14336]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.0.mlp.gate_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.0.mlp.up_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.0.post_attention_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.0.self_attn.k_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.0.self_attn.o_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.0.self_attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.0.self_attn.v_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.1.input_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.1.mlp.down_proj.weight: found shape torch.Size([4096, 14336]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.1.mlp.gate_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.1.mlp.up_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.1.post_attention_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.1.self_attn.k_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.1.self_attn.o_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.1.self_attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.1.self_attn.v_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.2.input_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.2.mlp.down_proj.weight: found shape torch.Size([4096, 14336]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.2.mlp.gate_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.2.mlp.up_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.2.post_attention_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.2.self_attn.k_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.2.self_attn.o_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.2.self_attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.2.self_attn.v_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.3.input_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.3.mlp.down_proj.weight: found shape torch.Size([4096, 14336]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.3.mlp.gate_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.3.mlp.up_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.3.post_attention_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.3.self_attn.k_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.3.self_attn.o_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.3.self_attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.3.self_attn.v_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.4.input_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.4.mlp.down_proj.weight: found shape torch.Size([4096, 14336]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.4.mlp.gate_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.4.mlp.up_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.4.post_attention_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.4.self_attn.k_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.4.self_attn.o_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.4.self_attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.4.self_attn.v_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.5.input_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.5.mlp.down_proj.weight: found shape torch.Size([4096, 14336]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.5.mlp.gate_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.5.mlp.up_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.5.post_attention_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.5.self_attn.k_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.5.self_attn.o_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.5.self_attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.5.self_attn.v_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.6.input_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.6.mlp.down_proj.weight: found shape torch.Size([4096, 14336]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.6.mlp.gate_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.6.mlp.up_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.6.post_attention_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.6.self_attn.k_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.6.self_attn.o_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.6.self_attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.6.self_attn.v_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.7.input_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.7.mlp.down_proj.weight: found shape torch.Size([4096, 14336]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.7.mlp.gate_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.7.mlp.up_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.7.post_attention_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.7.self_attn.k_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.7.self_attn.o_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.7.self_attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.7.self_attn.v_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.8.input_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.8.mlp.down_proj.weight: found shape torch.Size([4096, 14336]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.8.mlp.gate_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.8.mlp.up_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.8.post_attention_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.8.self_attn.k_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.8.self_attn.o_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.8.self_attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.8.self_attn.v_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.10.input_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.10.mlp.down_proj.weight: found shape torch.Size([4096, 14336]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.10.mlp.gate_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.10.mlp.up_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.10.post_attention_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.10.self_attn.k_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.10.self_attn.o_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.10.self_attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.10.self_attn.v_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.11.input_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.11.mlp.down_proj.weight: found shape torch.Size([4096, 14336]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.11.mlp.gate_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.11.mlp.up_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.11.post_attention_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.11.self_attn.k_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.11.self_attn.o_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.11.self_attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.11.self_attn.v_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.12.input_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.12.mlp.down_proj.weight: found shape torch.Size([4096, 14336]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.12.mlp.gate_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.12.mlp.up_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.12.post_attention_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.12.self_attn.k_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.12.self_attn.o_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.12.self_attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.12.self_attn.v_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.13.input_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.13.mlp.down_proj.weight: found shape torch.Size([4096, 14336]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.13.mlp.gate_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.13.mlp.up_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.13.post_attention_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.13.self_attn.k_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.13.self_attn.o_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.13.self_attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.13.self_attn.v_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.14.input_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.14.mlp.down_proj.weight: found shape torch.Size([4096, 14336]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.14.mlp.gate_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.14.mlp.up_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.14.post_attention_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.14.self_attn.k_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.14.self_attn.o_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.14.self_attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.14.self_attn.v_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.15.input_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.15.mlp.down_proj.weight: found shape torch.Size([4096, 14336]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.15.mlp.gate_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.15.mlp.up_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.15.post_attention_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.15.self_attn.k_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.15.self_attn.o_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.15.self_attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.15.self_attn.v_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.16.input_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.16.mlp.down_proj.weight: found shape torch.Size([4096, 14336]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.16.mlp.gate_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.16.mlp.up_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.16.post_attention_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.16.self_attn.k_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.16.self_attn.o_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.16.self_attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.16.self_attn.v_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.17.input_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.17.mlp.down_proj.weight: found shape torch.Size([4096, 14336]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.17.mlp.gate_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.17.mlp.up_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.17.post_attention_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.17.self_attn.k_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.17.self_attn.o_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.17.self_attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.17.self_attn.v_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.18.input_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.18.mlp.down_proj.weight: found shape torch.Size([4096, 14336]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.18.mlp.gate_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.18.mlp.up_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.18.post_attention_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.18.self_attn.k_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.18.self_attn.o_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.18.self_attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.18.self_attn.v_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.19.input_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.19.mlp.down_proj.weight: found shape torch.Size([4096, 14336]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.19.mlp.gate_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.19.mlp.up_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.19.post_attention_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.19.self_attn.k_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.19.self_attn.o_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.19.self_attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.19.self_attn.v_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.20.mlp.gate_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.20.self_attn.k_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.20.self_attn.o_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.20.self_attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.20.self_attn.v_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.9.input_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.9.mlp.down_proj.weight: found shape torch.Size([4096, 14336]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.9.mlp.gate_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.9.mlp.up_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.9.post_attention_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.9.self_attn.k_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.9.self_attn.o_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.9.self_attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.9.self_attn.v_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.20.input_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.20.mlp.down_proj.weight: found shape torch.Size([4096, 14336]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.20.mlp.up_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.20.post_attention_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.21.input_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.21.mlp.down_proj.weight: found shape torch.Size([4096, 14336]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.21.mlp.gate_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.21.mlp.up_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.21.post_attention_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.21.self_attn.k_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.21.self_attn.o_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.21.self_attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.21.self_attn.v_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.22.input_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.22.mlp.down_proj.weight: found shape torch.Size([4096, 14336]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.22.mlp.gate_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.22.mlp.up_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.22.post_attention_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.22.self_attn.k_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.22.self_attn.o_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.22.self_attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.22.self_attn.v_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.23.input_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.23.mlp.down_proj.weight: found shape torch.Size([4096, 14336]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.23.mlp.gate_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.23.mlp.up_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.23.post_attention_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.23.self_attn.k_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.23.self_attn.o_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.23.self_attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.23.self_attn.v_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.24.input_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.24.mlp.down_proj.weight: found shape torch.Size([4096, 14336]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.24.mlp.gate_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.24.mlp.up_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.24.post_attention_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.24.self_attn.k_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.24.self_attn.o_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.24.self_attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.24.self_attn.v_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.25.input_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.25.mlp.down_proj.weight: found shape torch.Size([4096, 14336]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.25.mlp.gate_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.25.mlp.up_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.25.post_attention_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.25.self_attn.k_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.25.self_attn.o_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.25.self_attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.25.self_attn.v_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.26.input_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.26.mlp.down_proj.weight: found shape torch.Size([4096, 14336]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.26.mlp.gate_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.26.mlp.up_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.26.post_attention_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.26.self_attn.k_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.26.self_attn.o_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.26.self_attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.26.self_attn.v_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.27.input_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.27.mlp.down_proj.weight: found shape torch.Size([4096, 14336]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.27.mlp.gate_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.27.mlp.up_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.27.post_attention_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.27.self_attn.k_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.27.self_attn.o_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.27.self_attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.27.self_attn.v_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.28.input_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.28.mlp.down_proj.weight: found shape torch.Size([4096, 14336]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.28.mlp.gate_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.28.mlp.up_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.28.post_attention_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.28.self_attn.k_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.28.self_attn.o_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.28.self_attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.28.self_attn.v_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.29.input_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.29.mlp.down_proj.weight: found shape torch.Size([4096, 14336]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.29.mlp.gate_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.29.mlp.up_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.29.post_attention_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.29.self_attn.k_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.29.self_attn.o_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.29.self_attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.29.self_attn.v_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.30.input_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.30.mlp.down_proj.weight: found shape torch.Size([4096, 14336]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.30.mlp.gate_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.30.mlp.up_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.30.post_attention_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.30.self_attn.k_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.30.self_attn.o_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.30.self_attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.30.self_attn.v_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.31.mlp.gate_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.31.mlp.up_proj.weight: found shape torch.Size([14336, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.31.self_attn.k_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.31.self_attn.o_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.31.self_attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.31.self_attn.v_proj.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.31.input_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.31.mlp.down_proj.weight: found shape torch.Size([4096, 14336]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.layers.31.post_attention_layernorm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "- model.norm.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-14 11:08:03,490] [INFO] [partition_parameters.py:345:__exit__] finished initializing model - num_params = 291, num_elems = 7.50B\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# DeepSpeed ZeRO-3\n",
    "import deepspeed\n",
    "from deepspeed.accelerator import get_accelerator\n",
    "\n",
    "\n",
    "with deepspeed.zero.Init():\n",
    "    model = torch.hub.load(\n",
    "        \"huggingface/pytorch-transformers\",\n",
    "        \"modelForSequenceClassification\",\n",
    "        # \"meta-llama/Llama-2-7b-hf\",\n",
    "        \"meta-llama/Meta-Llama-3-8B\",\n",
    "        ignore_mismatched_sizes=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ece1275-ff60-4b30-ac14-bc4febfcfdc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForSequenceClassification(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (score): Linear(in_features=4096, out_features=2, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e6724c0-3768-48ee-9176-2518cabbfe6b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_iter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m num_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m([label \u001b[38;5;28;01mfor\u001b[39;00m (label, text) \u001b[38;5;129;01min\u001b[39;00m train_iter]))\n\u001b[1;32m      2\u001b[0m num_class\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_iter' is not defined"
     ]
    }
   ],
   "source": [
    "num_class = len(set([label for (label, text) in train_iter]))\n",
    "num_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7e98c25-1d44-4a02-997c-8ec0c4e123c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, parameter in enumerate(model.parameters()):\n",
    "    parameter.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41954657-e0cf-40d1-9143-75e11701c2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score = nn.Linear(in_features=4096, out_features=2)\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8afdced-aa5f-4dae-9ef0-7183668838d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForSequenceClassification(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (score): Linear(in_features=4096, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1421e4-51bc-490c-b47d-01d83e0a28cf",
   "metadata": {},
   "source": [
    "# Train and eval functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a28ea92-68d0-44a7-9a5d-313ee209533f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, date\n",
    "import time\n",
    "\n",
    "def train(model, dataloader, epoch):\n",
    "    \n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 5\n",
    "    start_time = time.time()\n",
    "    total_loss = 0\n",
    "\n",
    "\n",
    "    for idx, (data, label) in enumerate(dataloader):         \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(input_ids=data.input_ids, attention_mask=data.attention_mask)\n",
    "        predicted_label = outputs.logits\n",
    "        loss = criterion(predicted_label, label)\n",
    "        \n",
    "        # Deepspeed model engine, backward pass \n",
    "        model.backward(loss)\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        \n",
    "        # Deepspeed model engine, optimizer step\n",
    "        model.step()\n",
    "        \n",
    "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Deepspeed model engine, empty cache\n",
    "        model.empty_partition_cache()\n",
    "        \n",
    "    return total_acc / total_count, total_loss / total_count\n",
    "        \n",
    "\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (data, label) in enumerate(dataloader):      \n",
    "            outputs = model(input_ids=data.input_ids, attention_mask=data.attention_mask)\n",
    "            predicted_label = outputs.logits\n",
    "            loss = criterion(predicted_label, label)\n",
    "            \n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "\n",
    "    return total_acc / total_count, loss.item() / total_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853f39a6",
   "metadata": {},
   "source": [
    "# Deepspeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "17ca1a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-14 07:58:59,624] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.2, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-14 07:58:59,635] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-14 07:59:00,695] [WARNING] [cpu_adam.py:84:__init__] FP16 params for CPUAdam may not work on AMD CPUs\n",
      "Installed CUDA version 12.3 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/it/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/it/.cache/torch_extensions/py311_cu121/cpu_adam/build.ninja...\n",
      "/home/it/anaconda3/envs/genety/lib/python3.11/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "Building extension module cpu_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n",
      "Time to load cpu_adam op: 2.182269334793091 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module cpu_adam...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-14 07:59:03,277] [INFO] [logging.py:96:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adam as basic optimizer\n",
      "[2024-05-14 07:59:03,277] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-14 07:59:03,282] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam\n",
      "[2024-05-14 07:59:03,282] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>\n",
      "[2024-05-14 07:59:03,282] [INFO] [logging.py:96:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer, MiCS is enabled False, Hierarchical params gather False\n",
      "[2024-05-14 07:59:03,283] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 3 optimizer\n",
      "[2024-05-14 07:59:03,372] [INFO] [utils.py:779:see_memory_usage] Stage 3 initialize beginning\n",
      "Adam Optimizer #0 is created with AVX512 arithmetic capability.\n",
      "Config: alpha=0.010000, betas=(0.800000, 0.999000), weight_decay=0.000000, adam_w=1\n",
      "[2024-05-14 07:59:03,372] [INFO] [utils.py:780:see_memory_usage] MA 14.1 GB         Max_MA 16.19 GB         CA 16.19 GB         Max_CA 16 GB \n",
      "[2024-05-14 07:59:03,373] [INFO] [utils.py:787:see_memory_usage] CPU Virtual Memory:  used = 2.92 GB, percent = 9.6%\n",
      "[2024-05-14 07:59:03,374] [INFO] [stage3.py:130:__init__] Reduce bucket size 200000000\n",
      "[2024-05-14 07:59:03,374] [INFO] [stage3.py:131:__init__] Prefetch bucket size 0\n",
      "[2024-05-14 07:59:03,453] [INFO] [utils.py:779:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]\n",
      "[2024-05-14 07:59:03,453] [INFO] [utils.py:780:see_memory_usage] MA 14.1 GB         Max_MA 14.1 GB         CA 16.19 GB         Max_CA 16 GB \n",
      "[2024-05-14 07:59:03,454] [INFO] [utils.py:787:see_memory_usage] CPU Virtual Memory:  used = 2.92 GB, percent = 9.6%\n",
      "Parameter Offload: Total persistent parameters: 274434 in 67 params\n",
      "[2024-05-14 07:59:03,544] [INFO] [utils.py:779:see_memory_usage] DeepSpeedZeRoOffload initialize [end]\n",
      "[2024-05-14 07:59:03,544] [INFO] [utils.py:780:see_memory_usage] MA 14.1 GB         Max_MA 14.1 GB         CA 16.19 GB         Max_CA 16 GB \n",
      "[2024-05-14 07:59:03,544] [INFO] [utils.py:787:see_memory_usage] CPU Virtual Memory:  used = 2.93 GB, percent = 9.6%\n",
      "[2024-05-14 07:59:03,627] [INFO] [utils.py:779:see_memory_usage] Before creating fp16 partitions\n",
      "[2024-05-14 07:59:03,628] [INFO] [utils.py:780:see_memory_usage] MA 14.1 GB         Max_MA 14.1 GB         CA 16.19 GB         Max_CA 16 GB \n",
      "[2024-05-14 07:59:03,628] [INFO] [utils.py:787:see_memory_usage] CPU Virtual Memory:  used = 2.93 GB, percent = 9.6%\n",
      "[2024-05-14 07:59:03,708] [INFO] [utils.py:779:see_memory_usage] After creating fp16 partitions: 1\n",
      "[2024-05-14 07:59:03,709] [INFO] [utils.py:780:see_memory_usage] MA 14.1 GB         Max_MA 14.1 GB         CA 16.19 GB         Max_CA 16 GB \n",
      "[2024-05-14 07:59:03,709] [INFO] [utils.py:787:see_memory_usage] CPU Virtual Memory:  used = 2.93 GB, percent = 9.6%\n",
      "[2024-05-14 07:59:03,799] [INFO] [utils.py:779:see_memory_usage] Before creating fp32 partitions\n",
      "[2024-05-14 07:59:03,800] [INFO] [utils.py:780:see_memory_usage] MA 14.1 GB         Max_MA 14.1 GB         CA 16.19 GB         Max_CA 16 GB \n",
      "[2024-05-14 07:59:03,800] [INFO] [utils.py:787:see_memory_usage] CPU Virtual Memory:  used = 2.93 GB, percent = 9.6%\n",
      "[2024-05-14 07:59:03,903] [INFO] [utils.py:779:see_memory_usage] After creating fp32 partitions\n",
      "[2024-05-14 07:59:03,904] [INFO] [utils.py:780:see_memory_usage] MA 14.1 GB         Max_MA 14.1 GB         CA 16.19 GB         Max_CA 16 GB \n",
      "[2024-05-14 07:59:03,904] [INFO] [utils.py:787:see_memory_usage] CPU Virtual Memory:  used = 2.93 GB, percent = 9.6%\n",
      "[2024-05-14 07:59:04,023] [INFO] [utils.py:779:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-14 07:59:04,023] [INFO] [utils.py:780:see_memory_usage] MA 14.1 GB         Max_MA 14.1 GB         CA 16.19 GB         Max_CA 16 GB \n",
      "[2024-05-14 07:59:04,024] [INFO] [utils.py:787:see_memory_usage] CPU Virtual Memory:  used = 2.93 GB, percent = 9.6%\n",
      "[2024-05-14 07:59:04,113] [INFO] [utils.py:779:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-14 07:59:04,113] [INFO] [utils.py:780:see_memory_usage] MA 14.1 GB         Max_MA 14.1 GB         CA 16.19 GB         Max_CA 16 GB \n",
      "[2024-05-14 07:59:04,114] [INFO] [utils.py:787:see_memory_usage] CPU Virtual Memory:  used = 2.93 GB, percent = 9.6%\n",
      "[2024-05-14 07:59:04,114] [INFO] [stage3.py:486:_setup_for_real_optimizer] optimizer state initialized\n",
      "[2024-05-14 07:59:04,196] [INFO] [utils.py:779:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-14 07:59:04,197] [INFO] [utils.py:780:see_memory_usage] MA 14.48 GB         Max_MA 14.48 GB         CA 16.19 GB         Max_CA 16 GB \n",
      "[2024-05-14 07:59:04,197] [INFO] [utils.py:787:see_memory_usage] CPU Virtual Memory:  used = 2.93 GB, percent = 9.6%\n",
      "[2024-05-14 07:59:04,197] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = adam\n",
      "[2024-05-14 07:59:04,197] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using configured LR scheduler = WarmupLR\n",
      "[2024-05-14 07:59:04,198] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7578f449a250>\n",
      "[2024-05-14 07:59:04,198] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 07:59:04,198] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-14 07:59:04,198] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-14 07:59:04,198] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-14 07:59:04,199] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-14 07:59:04,199] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-14 07:59:04,199] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-14 07:59:04,199] [INFO] [config.py:1000:print]   bfloat16_enabled ............. False\n",
      "[2024-05-14 07:59:04,199] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-14 07:59:04,199] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-14 07:59:04,199] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-14 07:59:04,199] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-14 07:59:04,199] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7578f06ab990>\n",
      "[2024-05-14 07:59:04,199] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-14 07:59:04,199] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-14 07:59:04,200] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-14 07:59:04,200] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-14 07:59:04,200] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-14 07:59:04,200] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-14 07:59:04,201] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-14 07:59:04,201] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-14 07:59:04,201] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-14 07:59:04,201] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-14 07:59:04,201] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-14 07:59:04,201] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-14 07:59:04,201] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-14 07:59:04,201] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-14 07:59:04,201] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-14 07:59:04,201] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-14 07:59:04,201] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-14 07:59:04,201] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-14 07:59:04,201] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-14 07:59:04,202] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-14 07:59:04,202] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-14 07:59:04,202] [INFO] [config.py:1000:print]   fp16_auto_cast ............... False\n",
      "[2024-05-14 07:59:04,202] [INFO] [config.py:1000:print]   fp16_enabled ................. True\n",
      "[2024-05-14 07:59:04,202] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-14 07:59:04,202] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-14 07:59:04,202] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-14 07:59:04,202] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-14 07:59:04,202] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-14 07:59:04,203] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-14 07:59:04,203] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-14 07:59:04,203] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-14 07:59:04,203] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 65536\n",
      "[2024-05-14 07:59:04,203] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-14 07:59:04,203] [INFO] [config.py:1000:print]   loss_scale ................... 0\n",
      "[2024-05-14 07:59:04,203] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-14 07:59:04,203] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-14 07:59:04,203] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-14 07:59:04,204] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-14 07:59:04,204] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-14 07:59:04,204] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-14 07:59:04,204] [INFO] [config.py:1000:print]   optimizer_name ............... adam\n",
      "[2024-05-14 07:59:04,204] [INFO] [config.py:1000:print]   optimizer_params ............. {'lr': 0.01, 'betas': [0.8, 0.999], 'eps': 1e-08, 'weight_decay': 3e-07}\n",
      "[2024-05-14 07:59:04,204] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-14 07:59:04,204] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-14 07:59:04,204] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-14 07:59:04,204] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-14 07:59:04,204] [INFO] [config.py:1000:print]   scheduler_name ............... WarmupLR\n",
      "[2024-05-14 07:59:04,204] [INFO] [config.py:1000:print]   scheduler_params ............. {'warmup_min_lr': 0, 'warmup_max_lr': 0.01, 'warmup_num_steps': 1000}\n",
      "[2024-05-14 07:59:04,204] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-14 07:59:04,205] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-14 07:59:04,205] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-14 07:59:04,205] [INFO] [config.py:1000:print]   steps_per_print .............. 10\n",
      "[2024-05-14 07:59:04,205] [INFO] [config.py:1000:print]   train_batch_size ............. 16\n",
      "[2024-05-14 07:59:04,205] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  16\n",
      "[2024-05-14 07:59:04,205] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-14 07:59:04,205] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-14 07:59:04,205] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-14 07:59:04,205] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-14 07:59:04,205] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-14 07:59:04,205] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  False\n",
      "[2024-05-14 07:59:04,205] [INFO] [config.py:1000:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='cpu', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=0 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=True stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-14 07:59:04,205] [INFO] [config.py:1000:print]   zero_enabled ................. True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-14 07:59:04,205] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-14 07:59:04,206] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 3\n",
      "[2024-05-14 07:59:04,206] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"optimizer\": {\n",
      "        \"type\": \"Adam\", \n",
      "        \"params\": {\n",
      "            \"lr\": 0.01, \n",
      "            \"betas\": [0.8, 0.999], \n",
      "            \"eps\": 1e-08, \n",
      "            \"weight_decay\": 3e-07\n",
      "        }\n",
      "    }, \n",
      "    \"scheduler\": {\n",
      "        \"type\": \"WarmupLR\", \n",
      "        \"params\": {\n",
      "            \"warmup_min_lr\": 0, \n",
      "            \"warmup_max_lr\": 0.01, \n",
      "            \"warmup_num_steps\": 1000\n",
      "        }\n",
      "    }, \n",
      "    \"train_batch_size\": 16, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 3, \n",
      "        \"offload_optimizer\": {\n",
      "            \"device\": \"cpu\"\n",
      "        }, \n",
      "        \"offload_param\": {\n",
      "            \"device\": \"cpu\"\n",
      "        }, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"load_from_fp32_weights\": true, \n",
      "        \"gather_16bit_weights_on_model_save\": true, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"stage3_prefetch_bucket_size\": 0\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeepSpeedEngine(\n",
       "  (module): LlamaForSequenceClassification(\n",
       "    (model): LlamaModel(\n",
       "      (embed_tokens): Embedding(128256, 4096)\n",
       "      (layers): ModuleList(\n",
       "        (0-31): 32 x LlamaDecoderLayer(\n",
       "          (self_attn): LlamaSdpaAttention(\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (rotary_emb): LlamaRotaryEmbedding()\n",
       "          )\n",
       "          (mlp): LlamaMLP(\n",
       "            (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "            (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): LlamaRMSNorm()\n",
       "          (post_attention_layernorm): LlamaRMSNorm()\n",
       "        )\n",
       "      )\n",
       "      (norm): LlamaRMSNorm()\n",
       "    )\n",
       "    (score): Linear(in_features=4096, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepspeed_config = {\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"Adam\",\n",
    "        \"params\": {\n",
    "            \"lr\": 0.01,\n",
    "            \"betas\": [\n",
    "                0.8,\n",
    "                0.999\n",
    "            ],\n",
    "            \"eps\": 1e-8,\n",
    "            \"weight_decay\": 3e-7,\n",
    "        },\n",
    "    },\n",
    "    \"scheduler\": {\n",
    "        \"type\": \"WarmupLR\",\n",
    "        \"params\": {\n",
    "            \"warmup_min_lr\": 0,\n",
    "            \"warmup_max_lr\": 0.01,\n",
    "            \"warmup_num_steps\": 1000,\n",
    "        },\n",
    "    },\n",
    "    \"train_batch_size\": 16,\n",
    "    # \"train_micro_batch_size_per_gpu\": \"auto\",\n",
    "    # \"gradient_accumulation_steps\": \"auto\",\n",
    "    \"fp16\": {\"enabled\": True},\n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 3,\n",
    "        \"offload_optimizer\": {\n",
    "            \"device\": \"cpu\",\n",
    "        },\n",
    "        \"offload_param\": {\n",
    "            \"device\": \"cpu\",\n",
    "        },\n",
    "        \"allgather_partitions\": True,\n",
    "        \"allgather_bucket_size\": 2e8,\n",
    "        \"reduce_scatter\": True,\n",
    "        \"reduce_bucket_size\": 2e8,\n",
    "        \"overlap_comm\": True,\n",
    "        \"load_from_fp32_weights\": True,\n",
    "        \"gather_16bit_weights_on_model_save\": True,\n",
    "        \"contiguous_gradients\": True,\n",
    "        \"stage3_prefetch_bucket_size\": 0,\n",
    "    },\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"train_batch_size\": 16,\n",
    "}\n",
    "\n",
    "# Initialize DeepSpeed Engine\n",
    "model_engine, optimizer, _, lr_scheduler = deepspeed.initialize(\n",
    "    model=model,\n",
    "    model_parameters=model.parameters(),\n",
    "    config=deepspeed_config,\n",
    ")\n",
    "model_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3df29fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = get_accelerator().device_name(model_engine.local_rank)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab0ddbc-f1e1-4662-a3d2-c09beafd25ed",
   "metadata": {},
   "source": [
    "# Split the dataset and run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ab8adb52-47f3-4740-952f-639d21a70d6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "\n",
    "BATCH_SIZE = 16  # batch size for training\n",
    "\n",
    "train_iter = iter(list(train_df.itertuples(index=False, name=None)))\n",
    "train_dataset = to_map_style_dataset(train_iter)\n",
    "test_dataset = to_map_style_dataset(test_iter)\n",
    "num_train = int(len(train_dataset) * 0.8)\n",
    "split_train_, split_valid_ = random_split(\n",
    "    train_dataset, [num_train, len(train_dataset) - num_train]\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    split_train_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
    ")\n",
    "valid_dataloader = DataLoader(\n",
    "    split_valid_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b2abb8af-8fe2-4382-8adf-7d2af9cd8e09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "today = date.today().isoformat()\n",
    "model_name = \"llama3_8b\"\n",
    "checkpoint_path = f\"./models/{model_name}\"\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "# EPOCHS = 20  # epoch\n",
    "# LR = 5 # learning rate\n",
    "    \n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "    \n",
    "def train_with_hist(model, epochs):\n",
    "    model = model.to(device)\n",
    "    \n",
    "    total_accu = None\n",
    "    best_accu_val = 0.85\n",
    "\n",
    "    loss_hist_train, loss_hist_valid, accuracy_hist_train, accuracy_hist_valid = [], [], [], []\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        accu_train, loss_train = train(model, train_dataloader, epoch)\n",
    "        accu_val, loss_val = evaluate(model, valid_dataloader)\n",
    "\n",
    "        print({\n",
    "            \"epoch\": epoch,\n",
    "            \"loss_train\": loss_train,\n",
    "            \"loss_val\": loss_val,\n",
    "            \"accuracy_train\": accu_train,\n",
    "            \"accuracy_val\": accu_val,\n",
    "        })\n",
    "        \n",
    "        loss_hist_train.append(loss_train)\n",
    "        loss_hist_valid.append(loss_val)\n",
    "        accuracy_hist_train.append(accu_train)\n",
    "        accuracy_hist_valid.append(accu_val)\n",
    "        \n",
    "        get_accelerator().empty_cache()\n",
    "        \n",
    "        if accu_val > best_accu_val:\n",
    "            best_accu_val = accu_val\n",
    "            model_engine.save_16bit_model(f\"./models/{model_name}/\", f\"{today}_{model_name}_checkpoint.pth\")\n",
    "    \n",
    "    return loss_hist_train, loss_hist_valid, accuracy_hist_train, accuracy_hist_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "00c4e1f4-9821-42a5-929f-e297c8cd9430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "97e7023b-7888-4afe-906a-76ac56aacab8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-14 08:07:40,352] [INFO] [logging.py:96:log_dist] [Rank 0] step=290, skipped=17, lr=[0.00812054215680252], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:07:40,352] [INFO] [timer.py:260:stop] epoch=0/micro_step=290/global_step=290, RunningAvgSamplesPerSec=71.25409471118829, CurrSamplesPerSec=75.93226966765067, MemAllocated=14.65GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:07:43,654] [INFO] [logging.py:96:log_dist] [Rank 0] step=300, skipped=17, lr=[0.008172621451747636], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:07:43,655] [INFO] [timer.py:260:stop] epoch=0/micro_step=300/global_step=300, RunningAvgSamplesPerSec=71.51964720213398, CurrSamplesPerSec=87.07916409853827, MemAllocated=14.61GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:07:46,904] [INFO] [logging.py:96:log_dist] [Rank 0] step=310, skipped=17, lr=[0.008222892067847033], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:07:46,905] [INFO] [timer.py:260:stop] epoch=0/micro_step=310/global_step=310, RunningAvgSamplesPerSec=71.79626323528812, CurrSamplesPerSec=75.99159786617507, MemAllocated=14.65GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:07:50,333] [INFO] [logging.py:96:log_dist] [Rank 0] step=320, skipped=17, lr=[0.008271475428341016], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:07:50,333] [INFO] [timer.py:260:stop] epoch=0/micro_step=320/global_step=320, RunningAvgSamplesPerSec=71.85898225713765, CurrSamplesPerSec=88.90086676831731, MemAllocated=14.6GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:07:53,891] [INFO] [logging.py:96:log_dist] [Rank 0] step=330, skipped=17, lr=[0.008318481125154828], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:07:53,892] [INFO] [timer.py:260:stop] epoch=0/micro_step=330/global_step=330, RunningAvgSamplesPerSec=71.77567553279997, CurrSamplesPerSec=65.42355326782094, MemAllocated=14.68GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:07:57,100] [INFO] [logging.py:96:log_dist] [Rank 0] step=340, skipped=17, lr=[0.008364008407770344], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:07:57,101] [INFO] [timer.py:260:stop] epoch=0/micro_step=340/global_step=340, RunningAvgSamplesPerSec=72.01251258103211, CurrSamplesPerSec=83.30750934758105, MemAllocated=14.63GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:08:00,453] [INFO] [logging.py:96:log_dist] [Rank 0] step=350, skipped=17, lr=[0.008408147445021066], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:08:00,454] [INFO] [timer.py:260:stop] epoch=0/micro_step=350/global_step=350, RunningAvgSamplesPerSec=72.10396523071212, CurrSamplesPerSec=60.152255635728054, MemAllocated=14.73GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:08:04,413] [INFO] [logging.py:96:log_dist] [Rank 0] step=360, skipped=17, lr=[0.008450980400142569], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:08:04,414] [INFO] [timer.py:260:stop] epoch=0/micro_step=360/global_step=360, RunningAvgSamplesPerSec=71.73432792942688, CurrSamplesPerSec=52.34002640833399, MemAllocated=14.77GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:08:07,856] [INFO] [logging.py:96:log_dist] [Rank 0] step=370, skipped=17, lr=[0.008492582351292742], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:08:07,857] [INFO] [timer.py:260:stop] epoch=0/micro_step=370/global_step=370, RunningAvgSamplesPerSec=71.76148476394407, CurrSamplesPerSec=60.98909611738896, MemAllocated=14.7GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:08:11,521] [INFO] [logging.py:96:log_dist] [Rank 0] step=380, skipped=17, lr=[0.008533022083453709], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:08:11,522] [INFO] [timer.py:260:stop] epoch=0/micro_step=380/global_step=380, RunningAvgSamplesPerSec=71.60300966378594, CurrSamplesPerSec=72.55883030287958, MemAllocated=14.66GB, MaxMemAllocated=16.29GB\n",
      "{'epoch': 1, 'loss_train': 0.008116155006866854, 'loss_val': 0.010234782963446475, 'accuracy_train': 0.9608355091383812, 'accuracy_val': 0.7049608355091384}\n",
      "[2024-05-14 08:08:20,952] [INFO] [logging.py:96:log_dist] [Rank 0] step=390, skipped=17, lr=[0.008572362772695626], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:08:20,952] [INFO] [timer.py:260:stop] epoch=0/micro_step=390/global_step=390, RunningAvgSamplesPerSec=71.37276221460361, CurrSamplesPerSec=74.99127154317463, MemAllocated=14.65GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:08:24,709] [INFO] [logging.py:96:log_dist] [Rank 0] step=400, skipped=17, lr=[0.00861066257989541], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:08:24,709] [INFO] [timer.py:260:stop] epoch=0/micro_step=400/global_step=400, RunningAvgSamplesPerSec=71.16480610511458, CurrSamplesPerSec=88.0460350405798, MemAllocated=14.61GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:08:28,002] [INFO] [logging.py:96:log_dist] [Rank 0] step=410, skipped=17, lr=[0.00864797516791809], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:08:28,003] [INFO] [timer.py:260:stop] epoch=0/micro_step=410/global_step=410, RunningAvgSamplesPerSec=71.30014424258076, CurrSamplesPerSec=87.7105906678325, MemAllocated=14.61GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:08:31,138] [INFO] [logging.py:96:log_dist] [Rank 0] step=420, skipped=17, lr=[0.008684350153803698], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:08:31,139] [INFO] [timer.py:260:stop] epoch=0/micro_step=420/global_step=420, RunningAvgSamplesPerSec=71.55620432647382, CurrSamplesPerSec=72.05547216406292, MemAllocated=14.65GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:08:34,376] [INFO] [logging.py:96:log_dist] [Rank 0] step=430, skipped=17, lr=[0.008719833505521338], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:08:34,377] [INFO] [timer.py:260:stop] epoch=0/micro_step=430/global_step=430, RunningAvgSamplesPerSec=71.72234323372949, CurrSamplesPerSec=86.49074890322048, MemAllocated=14.61GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:08:37,863] [INFO] [logging.py:96:log_dist] [Rank 0] step=440, skipped=17, lr=[0.008754467891250142], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:08:37,864] [INFO] [timer.py:260:stop] epoch=0/micro_step=440/global_step=440, RunningAvgSamplesPerSec=71.70665755571949, CurrSamplesPerSec=67.29068342661873, MemAllocated=14.67GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:08:41,229] [INFO] [logging.py:96:log_dist] [Rank 0] step=450, skipped=17, lr=[0.008788292987844552], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:08:41,230] [INFO] [timer.py:260:stop] epoch=0/micro_step=450/global_step=450, RunningAvgSamplesPerSec=71.79082011565681, CurrSamplesPerSec=83.5594669336232, MemAllocated=14.63GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:08:44,747] [INFO] [logging.py:96:log_dist] [Rank 0] step=460, skipped=17, lr=[0.0088213457540769], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:08:44,748] [INFO] [timer.py:260:stop] epoch=0/micro_step=460/global_step=460, RunningAvgSamplesPerSec=71.75653274586591, CurrSamplesPerSec=65.99448119061528, MemAllocated=14.68GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:08:48,458] [INFO] [logging.py:96:log_dist] [Rank 0] step=470, skipped=17, lr=[0.008853660673376108], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:08:48,458] [INFO] [timer.py:260:stop] epoch=0/micro_step=470/global_step=470, RunningAvgSamplesPerSec=71.6002143309103, CurrSamplesPerSec=65.22649264865254, MemAllocated=14.68GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:08:52,209] [INFO] [logging.py:96:log_dist] [Rank 0] step=480, skipped=17, lr=[0.008885269970059844], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:08:52,210] [INFO] [timer.py:260:stop] epoch=0/micro_step=480/global_step=480, RunningAvgSamplesPerSec=71.42450089387621, CurrSamplesPerSec=92.25270879213028, MemAllocated=14.59GB, MaxMemAllocated=16.29GB\n",
      "{'epoch': 2, 'loss_train': 0.003384163812308648, 'loss_val': 0.002725705776762402, 'accuracy_train': 0.9817232375979112, 'accuracy_val': 0.7023498694516971}\n",
      "[2024-05-14 08:09:01,946] [INFO] [logging.py:96:log_dist] [Rank 0] step=490, skipped=17, lr=[0.008916203802459373], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:09:01,947] [INFO] [timer.py:260:stop] epoch=0/micro_step=490/global_step=490, RunningAvgSamplesPerSec=71.31633329836744, CurrSamplesPerSec=101.71970600673292, MemAllocated=14.59GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:09:05,819] [INFO] [logging.py:96:log_dist] [Rank 0] step=500, skipped=17, lr=[0.008946490435838374], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:09:05,819] [INFO] [timer.py:260:stop] epoch=0/micro_step=500/global_step=500, RunningAvgSamplesPerSec=71.07978439831791, CurrSamplesPerSec=47.58326254692111, MemAllocated=14.78GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:09:09,037] [INFO] [logging.py:96:log_dist] [Rank 0] step=510, skipped=17, lr=[0.008976156397590767], mom=[[0.8, 0.999]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-14 08:09:09,037] [INFO] [timer.py:260:stop] epoch=0/micro_step=510/global_step=510, RunningAvgSamplesPerSec=71.24527013853147, CurrSamplesPerSec=101.3842393258461, MemAllocated=14.59GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:09:12,577] [INFO] [logging.py:96:log_dist] [Rank 0] step=520, skipped=17, lr=[0.009005226616853091], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:09:12,578] [INFO] [timer.py:260:stop] epoch=0/micro_step=520/global_step=520, RunningAvgSamplesPerSec=71.2090584932092, CurrSamplesPerSec=72.56039936466678, MemAllocated=14.65GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:09:15,933] [INFO] [logging.py:96:log_dist] [Rank 0] step=530, skipped=17, lr=[0.009033724550372721], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:09:15,934] [INFO] [timer.py:260:stop] epoch=0/micro_step=530/global_step=530, RunningAvgSamplesPerSec=71.2862274794714, CurrSamplesPerSec=88.31229207899945, MemAllocated=14.59GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:09:19,640] [INFO] [logging.py:96:log_dist] [Rank 0] step=540, skipped=17, lr=[0.009061672296224248], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:09:19,640] [INFO] [timer.py:260:stop] epoch=0/micro_step=540/global_step=540, RunningAvgSamplesPerSec=71.16327885073605, CurrSamplesPerSec=87.48738900933293, MemAllocated=14.62GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:09:22,914] [INFO] [logging.py:96:log_dist] [Rank 0] step=550, skipped=17, lr=[0.009089090696755241], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:09:22,915] [INFO] [timer.py:260:stop] epoch=0/micro_step=550/global_step=550, RunningAvgSamplesPerSec=71.27757802441565, CurrSamplesPerSec=71.8358035448588, MemAllocated=14.65GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:09:26,063] [INFO] [logging.py:96:log_dist] [Rank 0] step=560, skipped=17, lr=[0.009115999431962825], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:09:26,063] [INFO] [timer.py:260:stop] epoch=0/micro_step=560/global_step=560, RunningAvgSamplesPerSec=71.45751901838247, CurrSamplesPerSec=73.2655114589156, MemAllocated=14.66GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:09:29,768] [INFO] [logging.py:96:log_dist] [Rank 0] step=570, skipped=17, lr=[0.009142417104348995], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:09:29,768] [INFO] [timer.py:260:stop] epoch=0/micro_step=570/global_step=570, RunningAvgSamplesPerSec=71.341320872109, CurrSamplesPerSec=86.01230415880568, MemAllocated=14.62GB, MaxMemAllocated=16.29GB\n",
      "{'epoch': 3, 'loss_train': 0.0008521418113932597, 'loss_val': 0.008964996736292427, 'accuracy_train': 0.9947780678851175, 'accuracy_val': 0.7075718015665796}\n",
      "[2024-05-14 08:09:39,231] [INFO] [logging.py:96:log_dist] [Rank 0] step=580, skipped=17, lr=[0.009168361316171155], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:09:39,231] [INFO] [timer.py:260:stop] epoch=0/micro_step=580/global_step=580, RunningAvgSamplesPerSec=71.28884300497168, CurrSamplesPerSec=87.1412410597884, MemAllocated=14.61GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:09:42,498] [INFO] [logging.py:96:log_dist] [Rank 0] step=590, skipped=17, lr=[0.0091938487398913], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:09:42,498] [INFO] [timer.py:260:stop] epoch=0/micro_step=590/global_step=590, RunningAvgSamplesPerSec=71.3992090812022, CurrSamplesPerSec=66.01506046318548, MemAllocated=14.68GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:09:46,427] [INFO] [logging.py:96:log_dist] [Rank 0] step=600, skipped=17, lr=[0.009218895182530048], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:09:46,428] [INFO] [timer.py:260:stop] epoch=0/micro_step=600/global_step=600, RunningAvgSamplesPerSec=71.19398270414732, CurrSamplesPerSec=67.03592890934664, MemAllocated=14.68GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:09:49,975] [INFO] [logging.py:96:log_dist] [Rank 0] step=610, skipped=17, lr=[0.009243515644547543], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:09:49,975] [INFO] [timer.py:260:stop] epoch=0/micro_step=610/global_step=610, RunningAvgSamplesPerSec=71.16149647708625, CurrSamplesPerSec=88.53820954793427, MemAllocated=14.6GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:09:53,351] [INFO] [logging.py:96:log_dist] [Rank 0] step=620, skipped=17, lr=[0.009267724373800506], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:09:53,352] [INFO] [timer.py:260:stop] epoch=0/micro_step=620/global_step=620, RunningAvgSamplesPerSec=71.21147898614215, CurrSamplesPerSec=74.46570314190446, MemAllocated=14.65GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:09:56,557] [INFO] [logging.py:96:log_dist] [Rank 0] step=630, skipped=17, lr=[0.009291534915061385], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:09:56,557] [INFO] [timer.py:260:stop] epoch=0/micro_step=630/global_step=630, RunningAvgSamplesPerSec=71.34090002310197, CurrSamplesPerSec=60.08079306915003, MemAllocated=14.71GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:09:59,814] [INFO] [logging.py:96:log_dist] [Rank 0] step=640, skipped=17, lr=[0.009314960155530566], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:09:59,815] [INFO] [timer.py:260:stop] epoch=0/micro_step=640/global_step=640, RunningAvgSamplesPerSec=71.4485917745768, CurrSamplesPerSec=60.58686928236162, MemAllocated=14.71GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:10:03,533] [INFO] [logging.py:96:log_dist] [Rank 0] step=650, skipped=17, lr=[0.009338012366724517], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:10:03,534] [INFO] [timer.py:260:stop] epoch=0/micro_step=650/global_step=650, RunningAvgSamplesPerSec=71.32417888684671, CurrSamplesPerSec=60.15678498627602, MemAllocated=14.71GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:10:06,962] [INFO] [logging.py:96:log_dist] [Rank 0] step=660, skipped=17, lr=[0.009360703243080741], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:10:06,962] [INFO] [timer.py:260:stop] epoch=0/micro_step=660/global_step=660, RunningAvgSamplesPerSec=71.34344691899813, CurrSamplesPerSec=99.33797836168755, MemAllocated=14.58GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:10:10,401] [INFO] [logging.py:96:log_dist] [Rank 0] step=670, skipped=17, lr=[0.00938304393758358], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:10:10,402] [INFO] [timer.py:260:stop] epoch=0/micro_step=670/global_step=670, RunningAvgSamplesPerSec=71.35561591323062, CurrSamplesPerSec=86.47146882864031, MemAllocated=14.6GB, MaxMemAllocated=16.29GB\n",
      "{'epoch': 4, 'loss_train': 0.00014233379077662376, 'loss_val': 0.016277741514360313, 'accuracy_train': 0.9993472584856397, 'accuracy_val': 0.7049608355091384}\n",
      "[2024-05-14 08:10:19,862] [INFO] [logging.py:96:log_dist] [Rank 0] step=680, skipped=17, lr=[0.009405045094682577], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:10:19,863] [INFO] [timer.py:260:stop] epoch=0/micro_step=680/global_step=680, RunningAvgSamplesPerSec=71.29350817654091, CurrSamplesPerSec=73.83338742665771, MemAllocated=14.65GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:10:23,420] [INFO] [logging.py:96:log_dist] [Rank 0] step=690, skipped=17, lr=[0.00942671688074659], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:10:23,421] [INFO] [timer.py:260:stop] epoch=0/micro_step=690/global_step=690, RunningAvgSamplesPerSec=71.25757400181162, CurrSamplesPerSec=86.40889572171513, MemAllocated=14.61GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:10:26,438] [INFO] [logging.py:96:log_dist] [Rank 0] step=700, skipped=17, lr=[0.009448069012271776], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:10:26,438] [INFO] [timer.py:260:stop] epoch=0/micro_step=700/global_step=700, RunningAvgSamplesPerSec=71.4594850412558, CurrSamplesPerSec=75.44280425796457, MemAllocated=14.64GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:10:30,565] [INFO] [logging.py:96:log_dist] [Rank 0] step=710, skipped=17, lr=[0.009469110782039356], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:10:30,566] [INFO] [timer.py:260:stop] epoch=0/micro_step=710/global_step=710, RunningAvgSamplesPerSec=71.17250032826958, CurrSamplesPerSec=47.1036578774849, MemAllocated=14.8GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:10:33,515] [INFO] [logging.py:96:log_dist] [Rank 0] step=720, skipped=17, lr=[0.009489851083399415], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:10:33,515] [INFO] [timer.py:260:stop] epoch=0/micro_step=720/global_step=720, RunningAvgSamplesPerSec=71.40249385369981, CurrSamplesPerSec=74.39990598690468, MemAllocated=14.64GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:10:36,815] [INFO] [logging.py:96:log_dist] [Rank 0] step=730, skipped=17, lr=[0.009510298432839553], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:10:36,815] [INFO] [timer.py:260:stop] epoch=0/micro_step=730/global_step=730, RunningAvgSamplesPerSec=71.46988427983366, CurrSamplesPerSec=74.58512806719999, MemAllocated=14.65GB, MaxMemAllocated=16.29GB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-14 08:10:40,141] [INFO] [logging.py:96:log_dist] [Rank 0] step=740, skipped=17, lr=[0.00953046099098177], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:10:40,141] [INFO] [timer.py:260:stop] epoch=0/micro_step=740/global_step=740, RunningAvgSamplesPerSec=71.54322061314373, CurrSamplesPerSec=67.9626103107233, MemAllocated=14.68GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:10:43,500] [INFO] [logging.py:96:log_dist] [Rank 0] step=750, skipped=17, lr=[0.009550346582137093], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:10:43,500] [INFO] [timer.py:260:stop] epoch=0/micro_step=750/global_step=750, RunningAvgSamplesPerSec=71.58473557563757, CurrSamplesPerSec=67.75716455041841, MemAllocated=14.68GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:10:47,005] [INFO] [logging.py:96:log_dist] [Rank 0] step=760, skipped=17, lr=[0.009569962712535253], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:10:47,006] [INFO] [timer.py:260:stop] epoch=0/micro_step=760/global_step=760, RunningAvgSamplesPerSec=71.56471110875897, CurrSamplesPerSec=109.3917156908291, MemAllocated=14.56GB, MaxMemAllocated=16.29GB\n",
      "{'epoch': 5, 'loss_train': 1.5251474654394404e-05, 'loss_val': 0.012983436684073106, 'accuracy_train': 1.0, 'accuracy_val': 0.7049608355091384}\n",
      "[2024-05-14 08:10:56,474] [INFO] [logging.py:96:log_dist] [Rank 0] step=770, skipped=17, lr=[0.009589316587335668], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:10:56,475] [INFO] [timer.py:260:stop] epoch=0/micro_step=770/global_step=770, RunningAvgSamplesPerSec=71.4884526010619, CurrSamplesPerSec=85.8163031997197, MemAllocated=14.61GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:10:59,815] [INFO] [logging.py:96:log_dist] [Rank 0] step=780, skipped=17, lr=[0.009608415126516268], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:10:59,816] [INFO] [timer.py:260:stop] epoch=0/micro_step=780/global_step=780, RunningAvgSamplesPerSec=71.56423773695597, CurrSamplesPerSec=59.45825182160982, MemAllocated=14.73GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:11:03,837] [INFO] [logging.py:96:log_dist] [Rank 0] step=790, skipped=17, lr=[0.009627264979727752], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:11:03,837] [INFO] [timer.py:260:stop] epoch=0/micro_step=790/global_step=790, RunningAvgSamplesPerSec=71.34692263207637, CurrSamplesPerSec=47.5277933586026, MemAllocated=14.78GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:11:06,979] [INFO] [logging.py:96:log_dist] [Rank 0] step=800, skipped=17, lr=[0.009645872540193145], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:11:06,979] [INFO] [timer.py:260:stop] epoch=0/micro_step=800/global_step=800, RunningAvgSamplesPerSec=71.48260016525516, CurrSamplesPerSec=101.81785961915136, MemAllocated=14.59GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:11:10,293] [INFO] [logging.py:96:log_dist] [Rank 0] step=810, skipped=17, lr=[0.009664243957725346], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:11:10,293] [INFO] [timer.py:260:stop] epoch=0/micro_step=810/global_step=810, RunningAvgSamplesPerSec=71.5364645575344, CurrSamplesPerSec=59.437608496949686, MemAllocated=14.73GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:11:13,429] [INFO] [logging.py:96:log_dist] [Rank 0] step=820, skipped=17, lr=[0.009682385150928938], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:11:13,429] [INFO] [timer.py:260:stop] epoch=0/micro_step=820/global_step=820, RunningAvgSamplesPerSec=71.66071110770973, CurrSamplesPerSec=60.3557225586367, MemAllocated=14.7GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:11:17,341] [INFO] [logging.py:96:log_dist] [Rank 0] step=830, skipped=17, lr=[0.009700301818646893], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:11:17,342] [INFO] [timer.py:260:stop] epoch=0/micro_step=830/global_step=830, RunningAvgSamplesPerSec=71.49664965579248, CurrSamplesPerSec=106.53063025737003, MemAllocated=14.57GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:11:21,057] [INFO] [logging.py:96:log_dist] [Rank 0] step=840, skipped=17, lr=[0.009717999450707566], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:11:21,058] [INFO] [timer.py:260:stop] epoch=0/micro_step=840/global_step=840, RunningAvgSamplesPerSec=71.4101108243678, CurrSamplesPerSec=68.50569512356958, MemAllocated=14.67GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:11:24,431] [INFO] [logging.py:96:log_dist] [Rank 0] step=850, skipped=17, lr=[0.009735483338022625], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:11:24,432] [INFO] [timer.py:260:stop] epoch=0/micro_step=850/global_step=850, RunningAvgSamplesPerSec=71.4478460230198, CurrSamplesPerSec=87.95994484552027, MemAllocated=14.6GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:11:27,640] [INFO] [logging.py:96:log_dist] [Rank 0] step=860, skipped=17, lr=[0.009752758582082474], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:11:27,640] [INFO] [timer.py:260:stop] epoch=0/micro_step=860/global_step=860, RunningAvgSamplesPerSec=71.53786617754967, CurrSamplesPerSec=75.67582099112083, MemAllocated=14.64GB, MaxMemAllocated=16.29GB\n",
      "{'epoch': 6, 'loss_train': 1.1338694288587446e-05, 'loss_val': 0.006456021540469974, 'accuracy_train': 1.0, 'accuracy_val': 0.7049608355091384}\n",
      "[2024-05-14 08:11:37,051] [INFO] [logging.py:96:log_dist] [Rank 0] step=870, skipped=17, lr=[0.009769830103891744], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:11:37,051] [INFO] [timer.py:260:stop] epoch=0/micro_step=870/global_step=870, RunningAvgSamplesPerSec=71.55627221615309, CurrSamplesPerSec=75.00074208516992, MemAllocated=14.64GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:11:40,423] [INFO] [logging.py:96:log_dist] [Rank 0] step=880, skipped=17, lr=[0.009786702652384032], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:11:40,424] [INFO] [timer.py:260:stop] epoch=0/micro_step=880/global_step=880, RunningAvgSamplesPerSec=71.58493566254381, CurrSamplesPerSec=83.8819907529508, MemAllocated=14.63GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:11:44,052] [INFO] [logging.py:96:log_dist] [Rank 0] step=890, skipped=17, lr=[0.0098033808123519], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:11:44,052] [INFO] [timer.py:260:stop] epoch=0/micro_step=890/global_step=890, RunningAvgSamplesPerSec=71.52561803348499, CurrSamplesPerSec=74.62419172436952, MemAllocated=14.64GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:11:47,456] [INFO] [logging.py:96:log_dist] [Rank 0] step=900, skipped=17, lr=[0.009819869011925228], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:11:47,457] [INFO] [timer.py:260:stop] epoch=0/micro_step=900/global_step=900, RunningAvgSamplesPerSec=71.54558660124094, CurrSamplesPerSec=60.0448836616278, MemAllocated=14.72GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:11:50,941] [INFO] [logging.py:96:log_dist] [Rank 0] step=910, skipped=17, lr=[0.009836171529628488], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:11:50,942] [INFO] [timer.py:260:stop] epoch=0/micro_step=910/global_step=910, RunningAvgSamplesPerSec=71.54018267370542, CurrSamplesPerSec=85.96261440420149, MemAllocated=14.61GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:11:54,370] [INFO] [logging.py:96:log_dist] [Rank 0] step=920, skipped=17, lr=[0.00985229250104502], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:11:54,370] [INFO] [timer.py:260:stop] epoch=0/micro_step=920/global_step=920, RunningAvgSamplesPerSec=71.55178893475995, CurrSamplesPerSec=108.39692910549618, MemAllocated=14.57GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:11:58,620] [INFO] [logging.py:96:log_dist] [Rank 0] step=930, skipped=17, lr=[0.00986823592511433], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:11:58,621] [INFO] [timer.py:260:stop] epoch=0/micro_step=930/global_step=930, RunningAvgSamplesPerSec=71.29207622436606, CurrSamplesPerSec=27.312023272793574, MemAllocated=15.06GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:12:01,828] [INFO] [logging.py:96:log_dist] [Rank 0] step=940, skipped=17, lr=[0.009884005670086373], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:12:01,828] [INFO] [timer.py:260:stop] epoch=0/micro_step=940/global_step=940, RunningAvgSamplesPerSec=71.38245057296768, CurrSamplesPerSec=86.44362263003796, MemAllocated=14.61GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:12:05,306] [INFO] [logging.py:96:log_dist] [Rank 0] step=950, skipped=17, lr=[0.009899605479155001], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:12:05,306] [INFO] [timer.py:260:stop] epoch=0/micro_step=950/global_step=950, RunningAvgSamplesPerSec=71.38054908001897, CurrSamplesPerSec=92.6815600486134, MemAllocated=14.59GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:12:08,397] [INFO] [logging.py:96:log_dist] [Rank 0] step=960, skipped=17, lr=[0.009915038975791095], mom=[[0.8, 0.999]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-14 08:12:08,398] [INFO] [timer.py:260:stop] epoch=0/micro_step=960/global_step=960, RunningAvgSamplesPerSec=71.50248765913146, CurrSamplesPerSec=115.68080452181528, MemAllocated=14.55GB, MaxMemAllocated=16.29GB\n",
      "{'epoch': 7, 'loss_train': 9.461965013110606e-06, 'loss_val': 0.0016943231886422977, 'accuracy_train': 1.0, 'accuracy_val': 0.7049608355091384}\n",
      "[2024-05-14 08:12:17,720] [INFO] [logging.py:96:log_dist] [Rank 0] step=970, skipped=17, lr=[0.009930309668794421], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:12:17,720] [INFO] [timer.py:260:stop] epoch=0/micro_step=970/global_step=970, RunningAvgSamplesPerSec=71.55868257122411, CurrSamplesPerSec=82.84860830253155, MemAllocated=14.63GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:12:21,255] [INFO] [logging.py:96:log_dist] [Rank 0] step=980, skipped=17, lr=[0.009945420957081782], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:12:21,255] [INFO] [timer.py:260:stop] epoch=0/micro_step=980/global_step=980, RunningAvgSamplesPerSec=71.54263863540045, CurrSamplesPerSec=119.46201841002993, MemAllocated=14.55GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:12:24,616] [INFO] [logging.py:96:log_dist] [Rank 0] step=990, skipped=17, lr=[0.00996037613422784], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:12:24,617] [INFO] [timer.py:260:stop] epoch=0/micro_step=990/global_step=990, RunningAvgSamplesPerSec=71.57120018426944, CurrSamplesPerSec=73.31810062372243, MemAllocated=14.66GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:12:28,103] [INFO] [logging.py:96:log_dist] [Rank 0] step=1000, skipped=17, lr=[0.009975178392773785], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:12:28,103] [INFO] [timer.py:260:stop] epoch=0/micro_step=1000/global_step=1000, RunningAvgSamplesPerSec=71.561645638991, CurrSamplesPerSec=83.44019645021915, MemAllocated=14.63GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:12:31,308] [INFO] [logging.py:96:log_dist] [Rank 0] step=1010, skipped=17, lr=[0.009989830828317938], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:12:31,309] [INFO] [timer.py:260:stop] epoch=0/micro_step=1010/global_step=1010, RunningAvgSamplesPerSec=71.64085708557171, CurrSamplesPerSec=65.81100516709962, MemAllocated=14.68GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:12:33,941] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, reducing to 32768\n",
      "[2024-05-14 08:12:34,525] [INFO] [logging.py:96:log_dist] [Rank 0] step=1020, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:12:34,526] [INFO] [timer.py:260:stop] epoch=0/micro_step=1020/global_step=1020, RunningAvgSamplesPerSec=71.71832585162792, CurrSamplesPerSec=101.85850368220702, MemAllocated=14.57GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:12:38,287] [INFO] [logging.py:96:log_dist] [Rank 0] step=1030, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:12:38,288] [INFO] [timer.py:260:stop] epoch=0/micro_step=1030/global_step=1030, RunningAvgSamplesPerSec=71.62811914844656, CurrSamplesPerSec=74.36214790683243, MemAllocated=14.65GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:12:42,061] [INFO] [logging.py:96:log_dist] [Rank 0] step=1040, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:12:42,062] [INFO] [timer.py:260:stop] epoch=0/micro_step=1040/global_step=1040, RunningAvgSamplesPerSec=71.54832493200907, CurrSamplesPerSec=101.94546410201099, MemAllocated=14.59GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:12:45,432] [INFO] [logging.py:96:log_dist] [Rank 0] step=1050, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:12:45,433] [INFO] [timer.py:260:stop] epoch=0/micro_step=1050/global_step=1050, RunningAvgSamplesPerSec=71.58938141188504, CurrSamplesPerSec=87.50278902747824, MemAllocated=14.6GB, MaxMemAllocated=16.29GB\n",
      "{'epoch': 8, 'loss_train': 7.936249513850199e-06, 'loss_val': 0.008837508159268929, 'accuracy_train': 1.0, 'accuracy_val': 0.7023498694516971}\n",
      "[2024-05-14 08:12:55,347] [INFO] [logging.py:96:log_dist] [Rank 0] step=1060, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:12:55,347] [INFO] [timer.py:260:stop] epoch=0/micro_step=1060/global_step=1060, RunningAvgSamplesPerSec=71.48640315379889, CurrSamplesPerSec=99.06010722467585, MemAllocated=14.58GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:12:58,803] [INFO] [logging.py:96:log_dist] [Rank 0] step=1070, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:12:58,804] [INFO] [timer.py:260:stop] epoch=0/micro_step=1070/global_step=1070, RunningAvgSamplesPerSec=71.4906417026568, CurrSamplesPerSec=67.67708077014615, MemAllocated=14.68GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:13:02,305] [INFO] [logging.py:96:log_dist] [Rank 0] step=1080, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:13:02,306] [INFO] [timer.py:260:stop] epoch=0/micro_step=1080/global_step=1080, RunningAvgSamplesPerSec=71.48222694602026, CurrSamplesPerSec=75.57900284932371, MemAllocated=14.65GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:13:05,921] [INFO] [logging.py:96:log_dist] [Rank 0] step=1090, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:13:05,921] [INFO] [timer.py:260:stop] epoch=0/micro_step=1090/global_step=1090, RunningAvgSamplesPerSec=71.44322427825098, CurrSamplesPerSec=81.72237789232824, MemAllocated=14.63GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:13:09,155] [INFO] [logging.py:96:log_dist] [Rank 0] step=1100, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:13:09,156] [INFO] [timer.py:260:stop] epoch=0/micro_step=1100/global_step=1100, RunningAvgSamplesPerSec=71.50550494326156, CurrSamplesPerSec=59.39578655389743, MemAllocated=14.72GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:13:12,419] [INFO] [logging.py:96:log_dist] [Rank 0] step=1110, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:13:12,419] [INFO] [timer.py:260:stop] epoch=0/micro_step=1110/global_step=1110, RunningAvgSamplesPerSec=71.5603997646041, CurrSamplesPerSec=71.62541971648191, MemAllocated=14.65GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:13:16,208] [INFO] [logging.py:96:log_dist] [Rank 0] step=1120, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:13:16,208] [INFO] [timer.py:260:stop] epoch=0/micro_step=1120/global_step=1120, RunningAvgSamplesPerSec=71.46920063385694, CurrSamplesPerSec=117.31313925904949, MemAllocated=14.55GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:13:19,652] [INFO] [logging.py:96:log_dist] [Rank 0] step=1130, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:13:19,653] [INFO] [timer.py:260:stop] epoch=0/micro_step=1130/global_step=1130, RunningAvgSamplesPerSec=71.47819852773046, CurrSamplesPerSec=90.43638755026575, MemAllocated=14.6GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:13:22,963] [INFO] [logging.py:96:log_dist] [Rank 0] step=1140, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:13:22,964] [INFO] [timer.py:260:stop] epoch=0/micro_step=1140/global_step=1140, RunningAvgSamplesPerSec=71.52217560691233, CurrSamplesPerSec=88.24076158417924, MemAllocated=14.61GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:13:26,296] [INFO] [logging.py:96:log_dist] [Rank 0] step=1150, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:13:26,296] [INFO] [timer.py:260:stop] epoch=0/micro_step=1150/global_step=1150, RunningAvgSamplesPerSec=71.55798322784229, CurrSamplesPerSec=87.20680617046354, MemAllocated=14.61GB, MaxMemAllocated=16.29GB\n",
      "{'epoch': 9, 'loss_train': 7.026344926799246e-06, 'loss_val': 0.0047476746083550915, 'accuracy_train': 1.0, 'accuracy_val': 0.7075718015665796}\n",
      "[2024-05-14 08:13:35,503] [INFO] [logging.py:96:log_dist] [Rank 0] step=1160, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:13:35,504] [INFO] [timer.py:260:stop] epoch=0/micro_step=1160/global_step=1160, RunningAvgSamplesPerSec=71.55876166059836, CurrSamplesPerSec=87.79194356940273, MemAllocated=14.6GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:13:38,920] [INFO] [logging.py:96:log_dist] [Rank 0] step=1170, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:13:38,921] [INFO] [timer.py:260:stop] epoch=0/micro_step=1170/global_step=1170, RunningAvgSamplesPerSec=71.5695466586888, CurrSamplesPerSec=68.3339551478914, MemAllocated=14.67GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:13:42,708] [INFO] [logging.py:96:log_dist] [Rank 0] step=1180, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:13:42,708] [INFO] [timer.py:260:stop] epoch=0/micro_step=1180/global_step=1180, RunningAvgSamplesPerSec=71.48462006827789, CurrSamplesPerSec=59.51461995046129, MemAllocated=14.73GB, MaxMemAllocated=16.29GB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-14 08:13:45,980] [INFO] [logging.py:96:log_dist] [Rank 0] step=1190, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:13:45,981] [INFO] [timer.py:260:stop] epoch=0/micro_step=1190/global_step=1190, RunningAvgSamplesPerSec=71.53713020314703, CurrSamplesPerSec=100.40720741748171, MemAllocated=14.57GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:13:49,363] [INFO] [logging.py:96:log_dist] [Rank 0] step=1200, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:13:49,364] [INFO] [timer.py:260:stop] epoch=0/micro_step=1200/global_step=1200, RunningAvgSamplesPerSec=71.55667247838049, CurrSamplesPerSec=72.26979456981998, MemAllocated=14.66GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:13:52,778] [INFO] [logging.py:96:log_dist] [Rank 0] step=1210, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:13:52,779] [INFO] [timer.py:260:stop] epoch=0/micro_step=1210/global_step=1210, RunningAvgSamplesPerSec=71.57155990547602, CurrSamplesPerSec=46.764031711720754, MemAllocated=14.8GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:13:56,223] [INFO] [logging.py:96:log_dist] [Rank 0] step=1220, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:13:56,224] [INFO] [timer.py:260:stop] epoch=0/micro_step=1220/global_step=1220, RunningAvgSamplesPerSec=71.5817739760456, CurrSamplesPerSec=83.58475695119095, MemAllocated=14.63GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:13:59,701] [INFO] [logging.py:96:log_dist] [Rank 0] step=1230, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:13:59,702] [INFO] [timer.py:260:stop] epoch=0/micro_step=1230/global_step=1230, RunningAvgSamplesPerSec=71.57787583274926, CurrSamplesPerSec=88.14931125206716, MemAllocated=14.6GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:14:03,434] [INFO] [logging.py:96:log_dist] [Rank 0] step=1240, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:14:03,435] [INFO] [timer.py:260:stop] epoch=0/micro_step=1240/global_step=1240, RunningAvgSamplesPerSec=71.51170164567121, CurrSamplesPerSec=73.19032095878653, MemAllocated=14.66GB, MaxMemAllocated=16.29GB\n",
      "{'epoch': 10, 'loss_train': 6.155268952989703e-06, 'loss_val': 0.008016481723237597, 'accuracy_train': 1.0, 'accuracy_val': 0.7075718015665796}\n",
      "[2024-05-14 08:14:12,993] [INFO] [logging.py:96:log_dist] [Rank 0] step=1250, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:14:12,994] [INFO] [timer.py:260:stop] epoch=0/micro_step=1250/global_step=1250, RunningAvgSamplesPerSec=71.52103370519481, CurrSamplesPerSec=83.68815750749478, MemAllocated=14.63GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:14:16,770] [INFO] [logging.py:96:log_dist] [Rank 0] step=1260, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:14:16,770] [INFO] [timer.py:260:stop] epoch=0/micro_step=1260/global_step=1260, RunningAvgSamplesPerSec=71.44487359668707, CurrSamplesPerSec=72.43735590000432, MemAllocated=14.66GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:14:20,213] [INFO] [logging.py:96:log_dist] [Rank 0] step=1270, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:14:20,213] [INFO] [timer.py:260:stop] epoch=0/micro_step=1270/global_step=1270, RunningAvgSamplesPerSec=71.45038539821546, CurrSamplesPerSec=83.70339733531567, MemAllocated=14.63GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:14:23,608] [INFO] [logging.py:96:log_dist] [Rank 0] step=1280, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:14:23,609] [INFO] [timer.py:260:stop] epoch=0/micro_step=1280/global_step=1280, RunningAvgSamplesPerSec=71.4683787333062, CurrSamplesPerSec=72.28551916982806, MemAllocated=14.66GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:14:26,736] [INFO] [logging.py:96:log_dist] [Rank 0] step=1290, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:14:26,737] [INFO] [timer.py:260:stop] epoch=0/micro_step=1290/global_step=1290, RunningAvgSamplesPerSec=71.55412626141263, CurrSamplesPerSec=71.72976734193477, MemAllocated=14.66GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:14:30,183] [INFO] [logging.py:96:log_dist] [Rank 0] step=1300, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:14:30,184] [INFO] [timer.py:260:stop] epoch=0/micro_step=1300/global_step=1300, RunningAvgSamplesPerSec=71.55888608447403, CurrSamplesPerSec=65.7543249069175, MemAllocated=14.69GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:14:33,714] [INFO] [logging.py:96:log_dist] [Rank 0] step=1310, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:14:33,714] [INFO] [timer.py:260:stop] epoch=0/micro_step=1310/global_step=1310, RunningAvgSamplesPerSec=71.54535690283186, CurrSamplesPerSec=101.38362666747238, MemAllocated=14.58GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:14:37,317] [INFO] [logging.py:96:log_dist] [Rank 0] step=1320, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:14:37,317] [INFO] [timer.py:260:stop] epoch=0/micro_step=1320/global_step=1320, RunningAvgSamplesPerSec=71.51509541254985, CurrSamplesPerSec=46.7516845103077, MemAllocated=14.8GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:14:40,701] [INFO] [logging.py:96:log_dist] [Rank 0] step=1330, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:14:40,702] [INFO] [timer.py:260:stop] epoch=0/micro_step=1330/global_step=1330, RunningAvgSamplesPerSec=71.53789481878857, CurrSamplesPerSec=60.78321554178226, MemAllocated=14.7GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:14:44,524] [INFO] [logging.py:96:log_dist] [Rank 0] step=1340, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:14:44,524] [INFO] [timer.py:260:stop] epoch=0/micro_step=1340/global_step=1340, RunningAvgSamplesPerSec=71.46230175770734, CurrSamplesPerSec=90.90262648154419, MemAllocated=14.59GB, MaxMemAllocated=16.29GB\n",
      "{'epoch': 11, 'loss_train': 5.513818705984569e-06, 'loss_val': 0.01077023498694517, 'accuracy_train': 1.0, 'accuracy_val': 0.7049608355091384}\n",
      "[2024-05-14 08:14:53,637] [INFO] [logging.py:96:log_dist] [Rank 0] step=1350, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:14:53,638] [INFO] [timer.py:260:stop] epoch=0/micro_step=1350/global_step=1350, RunningAvgSamplesPerSec=71.50249335711553, CurrSamplesPerSec=93.12682170026282, MemAllocated=14.59GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:14:57,288] [INFO] [logging.py:96:log_dist] [Rank 0] step=1360, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:14:57,288] [INFO] [timer.py:260:stop] epoch=0/micro_step=1360/global_step=1360, RunningAvgSamplesPerSec=71.45769703918823, CurrSamplesPerSec=74.48157129808338, MemAllocated=14.64GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:15:00,646] [INFO] [logging.py:96:log_dist] [Rank 0] step=1370, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:15:00,647] [INFO] [timer.py:260:stop] epoch=0/micro_step=1370/global_step=1370, RunningAvgSamplesPerSec=71.4805627017035, CurrSamplesPerSec=72.93862986958644, MemAllocated=14.65GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:15:04,473] [INFO] [logging.py:96:log_dist] [Rank 0] step=1380, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:15:04,474] [INFO] [timer.py:260:stop] epoch=0/micro_step=1380/global_step=1380, RunningAvgSamplesPerSec=71.39832357170361, CurrSamplesPerSec=87.93885191402262, MemAllocated=14.61GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:15:07,805] [INFO] [logging.py:96:log_dist] [Rank 0] step=1390, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:15:07,805] [INFO] [timer.py:260:stop] epoch=0/micro_step=1390/global_step=1390, RunningAvgSamplesPerSec=71.42762736971294, CurrSamplesPerSec=87.90394978478821, MemAllocated=14.61GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:15:10,908] [INFO] [logging.py:96:log_dist] [Rank 0] step=1400, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:15:10,909] [INFO] [timer.py:260:stop] epoch=0/micro_step=1400/global_step=1400, RunningAvgSamplesPerSec=71.50556187792992, CurrSamplesPerSec=69.24750391078055, MemAllocated=14.67GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:15:14,148] [INFO] [logging.py:96:log_dist] [Rank 0] step=1410, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:15:14,148] [INFO] [timer.py:260:stop] epoch=0/micro_step=1410/global_step=1410, RunningAvgSamplesPerSec=71.55725430729805, CurrSamplesPerSec=106.97520766549079, MemAllocated=14.56GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:15:18,331] [INFO] [logging.py:96:log_dist] [Rank 0] step=1420, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-14 08:15:18,332] [INFO] [timer.py:260:stop] epoch=0/micro_step=1420/global_step=1420, RunningAvgSamplesPerSec=71.4071199030674, CurrSamplesPerSec=87.72641340481242, MemAllocated=14.61GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:15:22,115] [INFO] [logging.py:96:log_dist] [Rank 0] step=1430, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:15:22,116] [INFO] [timer.py:260:stop] epoch=0/micro_step=1430/global_step=1430, RunningAvgSamplesPerSec=71.33934134553141, CurrSamplesPerSec=65.75593562452539, MemAllocated=14.68GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:15:25,369] [INFO] [logging.py:96:log_dist] [Rank 0] step=1440, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:15:25,369] [INFO] [timer.py:260:stop] epoch=0/micro_step=1440/global_step=1440, RunningAvgSamplesPerSec=71.38711811531228, CurrSamplesPerSec=99.26891518288363, MemAllocated=14.58GB, MaxMemAllocated=16.29GB\n",
      "{'epoch': 12, 'loss_train': 4.983563024754935e-06, 'loss_val': 1.4282704644663837e-05, 'accuracy_train': 1.0, 'accuracy_val': 0.7101827676240209}\n",
      "[2024-05-14 08:15:34,685] [INFO] [logging.py:96:log_dist] [Rank 0] step=1450, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:15:34,686] [INFO] [timer.py:260:stop] epoch=0/micro_step=1450/global_step=1450, RunningAvgSamplesPerSec=71.42387863391166, CurrSamplesPerSec=68.59791902834836, MemAllocated=14.67GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:15:38,664] [INFO] [logging.py:96:log_dist] [Rank 0] step=1460, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:15:38,664] [INFO] [timer.py:260:stop] epoch=0/micro_step=1460/global_step=1460, RunningAvgSamplesPerSec=71.31824455094163, CurrSamplesPerSec=47.759557054813044, MemAllocated=14.79GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:15:42,230] [INFO] [logging.py:96:log_dist] [Rank 0] step=1470, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:15:42,230] [INFO] [timer.py:260:stop] epoch=0/micro_step=1470/global_step=1470, RunningAvgSamplesPerSec=71.30514151126013, CurrSamplesPerSec=88.47121110450485, MemAllocated=14.59GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:15:45,603] [INFO] [logging.py:96:log_dist] [Rank 0] step=1480, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:15:45,603] [INFO] [timer.py:260:stop] epoch=0/micro_step=1480/global_step=1480, RunningAvgSamplesPerSec=71.32548719208249, CurrSamplesPerSec=75.18989832217585, MemAllocated=14.64GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:15:48,994] [INFO] [logging.py:96:log_dist] [Rank 0] step=1490, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:15:48,995] [INFO] [timer.py:260:stop] epoch=0/micro_step=1490/global_step=1490, RunningAvgSamplesPerSec=71.34675453487648, CurrSamplesPerSec=93.09142562270077, MemAllocated=14.59GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:15:52,394] [INFO] [logging.py:96:log_dist] [Rank 0] step=1500, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:15:52,394] [INFO] [timer.py:260:stop] epoch=0/micro_step=1500/global_step=1500, RunningAvgSamplesPerSec=71.3586493200739, CurrSamplesPerSec=87.83882722513088, MemAllocated=14.61GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:15:55,595] [INFO] [logging.py:96:log_dist] [Rank 0] step=1510, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:15:55,596] [INFO] [timer.py:260:stop] epoch=0/micro_step=1510/global_step=1510, RunningAvgSamplesPerSec=71.40887357771011, CurrSamplesPerSec=60.5727602998452, MemAllocated=14.71GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:15:59,152] [INFO] [logging.py:96:log_dist] [Rank 0] step=1520, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:15:59,153] [INFO] [timer.py:260:stop] epoch=0/micro_step=1520/global_step=1520, RunningAvgSamplesPerSec=71.38963546567085, CurrSamplesPerSec=75.69033096329447, MemAllocated=14.64GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:16:03,108] [INFO] [logging.py:96:log_dist] [Rank 0] step=1530, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:16:03,108] [INFO] [timer.py:260:stop] epoch=0/micro_step=1530/global_step=1530, RunningAvgSamplesPerSec=71.29532263913387, CurrSamplesPerSec=72.76124885614041, MemAllocated=14.66GB, MaxMemAllocated=16.29GB\n",
      "{'epoch': 13, 'loss_train': 4.518164355823328e-06, 'loss_val': 0.005731886422976501, 'accuracy_train': 1.0, 'accuracy_val': 0.7101827676240209}\n",
      "[2024-05-14 08:16:12,763] [INFO] [logging.py:96:log_dist] [Rank 0] step=1540, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:16:12,764] [INFO] [timer.py:260:stop] epoch=0/micro_step=1540/global_step=1540, RunningAvgSamplesPerSec=71.28288427104825, CurrSamplesPerSec=46.845641313096266, MemAllocated=14.8GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:16:16,441] [INFO] [logging.py:96:log_dist] [Rank 0] step=1550, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:16:16,441] [INFO] [timer.py:260:stop] epoch=0/micro_step=1550/global_step=1550, RunningAvgSamplesPerSec=71.24192096847577, CurrSamplesPerSec=42.233979325075616, MemAllocated=14.84GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:16:19,822] [INFO] [logging.py:96:log_dist] [Rank 0] step=1560, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:16:19,823] [INFO] [timer.py:260:stop] epoch=0/micro_step=1560/global_step=1560, RunningAvgSamplesPerSec=71.26073477665, CurrSamplesPerSec=86.11892851918107, MemAllocated=14.61GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:16:23,265] [INFO] [logging.py:96:log_dist] [Rank 0] step=1570, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:16:23,266] [INFO] [timer.py:260:stop] epoch=0/micro_step=1570/global_step=1570, RunningAvgSamplesPerSec=71.2654947949085, CurrSamplesPerSec=52.74328181783886, MemAllocated=14.76GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:16:26,701] [INFO] [logging.py:96:log_dist] [Rank 0] step=1580, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:16:26,702] [INFO] [timer.py:260:stop] epoch=0/micro_step=1580/global_step=1580, RunningAvgSamplesPerSec=71.27136303850715, CurrSamplesPerSec=82.73553891200493, MemAllocated=14.62GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:16:30,188] [INFO] [logging.py:96:log_dist] [Rank 0] step=1590, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:16:30,188] [INFO] [timer.py:260:stop] epoch=0/micro_step=1590/global_step=1590, RunningAvgSamplesPerSec=71.26990922421709, CurrSamplesPerSec=68.75471435216205, MemAllocated=14.67GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:16:33,508] [INFO] [logging.py:96:log_dist] [Rank 0] step=1600, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:16:33,509] [INFO] [timer.py:260:stop] epoch=0/micro_step=1600/global_step=1600, RunningAvgSamplesPerSec=71.300043787576, CurrSamplesPerSec=84.24105072750302, MemAllocated=14.63GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:16:36,791] [INFO] [logging.py:96:log_dist] [Rank 0] step=1610, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:16:36,792] [INFO] [timer.py:260:stop] epoch=0/micro_step=1610/global_step=1610, RunningAvgSamplesPerSec=71.33559813945328, CurrSamplesPerSec=59.41040438888402, MemAllocated=14.73GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:16:39,974] [INFO] [logging.py:96:log_dist] [Rank 0] step=1620, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:16:39,974] [INFO] [timer.py:260:stop] epoch=0/micro_step=1620/global_step=1620, RunningAvgSamplesPerSec=71.39161457159558, CurrSamplesPerSec=99.77574089685206, MemAllocated=14.59GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:16:43,419] [INFO] [logging.py:96:log_dist] [Rank 0] step=1630, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:16:43,419] [INFO] [timer.py:260:stop] epoch=0/micro_step=1630/global_step=1630, RunningAvgSamplesPerSec=71.39545193352464, CurrSamplesPerSec=87.8590670102013, MemAllocated=14.6GB, MaxMemAllocated=16.29GB\n",
      "{'epoch': 14, 'loss_train': 4.12361428880816e-06, 'loss_val': 0.00777680319843342, 'accuracy_train': 1.0, 'accuracy_val': 0.7127937336814621}\n",
      "[2024-05-14 08:16:52,925] [INFO] [logging.py:96:log_dist] [Rank 0] step=1640, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:16:52,925] [INFO] [timer.py:260:stop] epoch=0/micro_step=1640/global_step=1640, RunningAvgSamplesPerSec=71.38978951260593, CurrSamplesPerSec=106.31814552413785, MemAllocated=14.57GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:16:56,529] [INFO] [logging.py:96:log_dist] [Rank 0] step=1650, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-14 08:16:56,529] [INFO] [timer.py:260:stop] epoch=0/micro_step=1650/global_step=1650, RunningAvgSamplesPerSec=71.36466339704769, CurrSamplesPerSec=92.28378948873832, MemAllocated=14.59GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:16:59,776] [INFO] [logging.py:96:log_dist] [Rank 0] step=1660, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:16:59,777] [INFO] [timer.py:260:stop] epoch=0/micro_step=1660/global_step=1660, RunningAvgSamplesPerSec=71.40440993287626, CurrSamplesPerSec=75.51802234182978, MemAllocated=14.65GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:17:03,266] [INFO] [logging.py:96:log_dist] [Rank 0] step=1670, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:17:03,267] [INFO] [timer.py:260:stop] epoch=0/micro_step=1670/global_step=1670, RunningAvgSamplesPerSec=71.39966350552986, CurrSamplesPerSec=43.75430411157895, MemAllocated=14.83GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:17:07,050] [INFO] [logging.py:96:log_dist] [Rank 0] step=1680, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:17:07,051] [INFO] [timer.py:260:stop] epoch=0/micro_step=1680/global_step=1680, RunningAvgSamplesPerSec=71.34316204446165, CurrSamplesPerSec=67.32605786266495, MemAllocated=14.67GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:17:10,562] [INFO] [logging.py:96:log_dist] [Rank 0] step=1690, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:17:10,562] [INFO] [timer.py:260:stop] epoch=0/micro_step=1690/global_step=1690, RunningAvgSamplesPerSec=71.34004597257173, CurrSamplesPerSec=101.31872684395354, MemAllocated=14.58GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:17:14,142] [INFO] [logging.py:96:log_dist] [Rank 0] step=1700, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:17:14,142] [INFO] [timer.py:260:stop] epoch=0/micro_step=1700/global_step=1700, RunningAvgSamplesPerSec=71.31992967455568, CurrSamplesPerSec=74.48330728796704, MemAllocated=14.64GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:17:17,590] [INFO] [logging.py:96:log_dist] [Rank 0] step=1710, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:17:17,591] [INFO] [timer.py:260:stop] epoch=0/micro_step=1710/global_step=1710, RunningAvgSamplesPerSec=71.32606103993452, CurrSamplesPerSec=86.77425252756431, MemAllocated=14.61GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:17:20,771] [INFO] [logging.py:96:log_dist] [Rank 0] step=1720, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:17:20,772] [INFO] [timer.py:260:stop] epoch=0/micro_step=1720/global_step=1720, RunningAvgSamplesPerSec=71.37556101070058, CurrSamplesPerSec=75.5316217344767, MemAllocated=14.64GB, MaxMemAllocated=16.29GB\n",
      "{'epoch': 15, 'loss_train': 3.825863409913862e-06, 'loss_val': 0.00587467362924282, 'accuracy_train': 1.0, 'accuracy_val': 0.7101827676240209}\n",
      "[2024-05-14 08:17:30,125] [INFO] [logging.py:96:log_dist] [Rank 0] step=1730, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:17:30,125] [INFO] [timer.py:260:stop] epoch=0/micro_step=1730/global_step=1730, RunningAvgSamplesPerSec=71.37525392148426, CurrSamplesPerSec=82.21475676344511, MemAllocated=14.63GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:17:33,548] [INFO] [logging.py:96:log_dist] [Rank 0] step=1740, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:17:33,549] [INFO] [timer.py:260:stop] epoch=0/micro_step=1740/global_step=1740, RunningAvgSamplesPerSec=71.38363874669514, CurrSamplesPerSec=65.7298517111011, MemAllocated=14.69GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:17:36,842] [INFO] [logging.py:96:log_dist] [Rank 0] step=1750, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:17:36,842] [INFO] [timer.py:260:stop] epoch=0/micro_step=1750/global_step=1750, RunningAvgSamplesPerSec=71.41500029775656, CurrSamplesPerSec=73.21331717252824, MemAllocated=14.66GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:17:40,400] [INFO] [logging.py:96:log_dist] [Rank 0] step=1760, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:17:40,400] [INFO] [timer.py:260:stop] epoch=0/micro_step=1760/global_step=1760, RunningAvgSamplesPerSec=71.39798258413038, CurrSamplesPerSec=89.89776852573738, MemAllocated=14.6GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:17:43,786] [INFO] [logging.py:96:log_dist] [Rank 0] step=1770, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:17:43,786] [INFO] [timer.py:260:stop] epoch=0/micro_step=1770/global_step=1770, RunningAvgSamplesPerSec=71.41041700506051, CurrSamplesPerSec=59.0440387474815, MemAllocated=14.73GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:17:47,423] [INFO] [logging.py:96:log_dist] [Rank 0] step=1780, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:17:47,424] [INFO] [timer.py:260:stop] epoch=0/micro_step=1780/global_step=1780, RunningAvgSamplesPerSec=71.38431842740691, CurrSamplesPerSec=86.27292840549863, MemAllocated=14.61GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:17:50,855] [INFO] [logging.py:96:log_dist] [Rank 0] step=1790, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:17:50,855] [INFO] [timer.py:260:stop] epoch=0/micro_step=1790/global_step=1790, RunningAvgSamplesPerSec=71.39674476945153, CurrSamplesPerSec=74.03139134156727, MemAllocated=14.64GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:17:54,230] [INFO] [logging.py:96:log_dist] [Rank 0] step=1800, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:17:54,231] [INFO] [timer.py:260:stop] epoch=0/micro_step=1800/global_step=1800, RunningAvgSamplesPerSec=71.41293189059334, CurrSamplesPerSec=87.84055184329536, MemAllocated=14.6GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:17:58,073] [INFO] [logging.py:96:log_dist] [Rank 0] step=1810, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:17:58,074] [INFO] [timer.py:260:stop] epoch=0/micro_step=1810/global_step=1810, RunningAvgSamplesPerSec=71.35409716444705, CurrSamplesPerSec=75.61161718759682, MemAllocated=14.65GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:18:01,337] [INFO] [logging.py:96:log_dist] [Rank 0] step=1820, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:18:01,338] [INFO] [timer.py:260:stop] epoch=0/micro_step=1820/global_step=1820, RunningAvgSamplesPerSec=71.39082843942136, CurrSamplesPerSec=74.20895410157654, MemAllocated=14.65GB, MaxMemAllocated=16.29GB\n",
      "{'epoch': 16, 'loss_train': 3.5345709977511015e-06, 'loss_val': 0.014237924281984334, 'accuracy_train': 1.0, 'accuracy_val': 0.7127937336814621}\n",
      "[2024-05-14 08:18:10,692] [INFO] [logging.py:96:log_dist] [Rank 0] step=1830, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:18:10,692] [INFO] [timer.py:260:stop] epoch=0/micro_step=1830/global_step=1830, RunningAvgSamplesPerSec=71.37825727016738, CurrSamplesPerSec=75.81757379656912, MemAllocated=14.65GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:18:14,310] [INFO] [logging.py:96:log_dist] [Rank 0] step=1840, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:18:14,310] [INFO] [timer.py:260:stop] epoch=0/micro_step=1840/global_step=1840, RunningAvgSamplesPerSec=71.35328025696667, CurrSamplesPerSec=83.03887586894707, MemAllocated=14.62GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:18:17,582] [INFO] [logging.py:96:log_dist] [Rank 0] step=1850, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:18:17,582] [INFO] [timer.py:260:stop] epoch=0/micro_step=1850/global_step=1850, RunningAvgSamplesPerSec=71.38646407686191, CurrSamplesPerSec=87.99592990627245, MemAllocated=14.6GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:18:21,106] [INFO] [logging.py:96:log_dist] [Rank 0] step=1860, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:18:21,107] [INFO] [timer.py:260:stop] epoch=0/micro_step=1860/global_step=1860, RunningAvgSamplesPerSec=71.37549428559312, CurrSamplesPerSec=53.32367965839212, MemAllocated=14.75GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:18:24,532] [INFO] [logging.py:96:log_dist] [Rank 0] step=1870, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:18:24,532] [INFO] [timer.py:260:stop] epoch=0/micro_step=1870/global_step=1870, RunningAvgSamplesPerSec=71.38294548959962, CurrSamplesPerSec=87.81894152240396, MemAllocated=14.61GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:18:28,393] [INFO] [logging.py:96:log_dist] [Rank 0] step=1880, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:18:28,394] [INFO] [timer.py:260:stop] epoch=0/micro_step=1880/global_step=1880, RunningAvgSamplesPerSec=71.31776402251126, CurrSamplesPerSec=60.48159340287948, MemAllocated=14.71GB, MaxMemAllocated=16.29GB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-14 08:18:31,913] [INFO] [logging.py:96:log_dist] [Rank 0] step=1890, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:18:31,914] [INFO] [timer.py:260:stop] epoch=0/micro_step=1890/global_step=1890, RunningAvgSamplesPerSec=71.31570257990259, CurrSamplesPerSec=98.63525649128273, MemAllocated=14.58GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:18:35,183] [INFO] [logging.py:96:log_dist] [Rank 0] step=1900, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:18:35,183] [INFO] [timer.py:260:stop] epoch=0/micro_step=1900/global_step=1900, RunningAvgSamplesPerSec=71.35153191179701, CurrSamplesPerSec=75.43279780498196, MemAllocated=14.65GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:18:38,539] [INFO] [logging.py:96:log_dist] [Rank 0] step=1910, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:18:38,540] [INFO] [timer.py:260:stop] epoch=0/micro_step=1910/global_step=1910, RunningAvgSamplesPerSec=71.37338436307287, CurrSamplesPerSec=82.76237386879642, MemAllocated=14.62GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:18:42,024] [INFO] [logging.py:96:log_dist] [Rank 0] step=1920, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:18:42,025] [INFO] [timer.py:260:stop] epoch=0/micro_step=1920/global_step=1920, RunningAvgSamplesPerSec=71.3803710606141, CurrSamplesPerSec=109.57479492136476, MemAllocated=14.56GB, MaxMemAllocated=16.29GB\n",
      "{'epoch': 17, 'loss_train': 3.2719915280454153e-06, 'loss_val': 0.008429544712793734, 'accuracy_train': 1.0, 'accuracy_val': 0.7127937336814621}\n",
      "[2024-05-14 08:18:51,197] [INFO] [logging.py:96:log_dist] [Rank 0] step=1930, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:18:51,198] [INFO] [timer.py:260:stop] epoch=0/micro_step=1930/global_step=1930, RunningAvgSamplesPerSec=71.42865155946951, CurrSamplesPerSec=72.36174801166261, MemAllocated=14.66GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:18:55,011] [INFO] [logging.py:96:log_dist] [Rank 0] step=1940, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:18:55,011] [INFO] [timer.py:260:stop] epoch=0/micro_step=1940/global_step=1940, RunningAvgSamplesPerSec=71.37550323766332, CurrSamplesPerSec=100.32599998804021, MemAllocated=14.57GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:18:58,369] [INFO] [logging.py:96:log_dist] [Rank 0] step=1950, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:18:58,369] [INFO] [timer.py:260:stop] epoch=0/micro_step=1950/global_step=1950, RunningAvgSamplesPerSec=71.39230055196806, CurrSamplesPerSec=85.89165002815747, MemAllocated=14.61GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:19:02,105] [INFO] [logging.py:96:log_dist] [Rank 0] step=1960, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:19:02,105] [INFO] [timer.py:260:stop] epoch=0/micro_step=1960/global_step=1960, RunningAvgSamplesPerSec=71.34684451905878, CurrSamplesPerSec=29.31949484508157, MemAllocated=15.01GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:19:05,704] [INFO] [logging.py:96:log_dist] [Rank 0] step=1970, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:19:05,705] [INFO] [timer.py:260:stop] epoch=0/micro_step=1970/global_step=1970, RunningAvgSamplesPerSec=71.3304608402322, CurrSamplesPerSec=73.4006181900114, MemAllocated=14.66GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:19:09,317] [INFO] [logging.py:96:log_dist] [Rank 0] step=1980, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:19:09,317] [INFO] [timer.py:260:stop] epoch=0/micro_step=1980/global_step=1980, RunningAvgSamplesPerSec=71.3085755256691, CurrSamplesPerSec=65.46280184754352, MemAllocated=14.68GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:19:12,454] [INFO] [logging.py:96:log_dist] [Rank 0] step=1990, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:19:12,454] [INFO] [timer.py:260:stop] epoch=0/micro_step=1990/global_step=1990, RunningAvgSamplesPerSec=71.36317837090895, CurrSamplesPerSec=83.36587692796947, MemAllocated=14.63GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:19:15,786] [INFO] [logging.py:96:log_dist] [Rank 0] step=2000, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:19:15,787] [INFO] [timer.py:260:stop] epoch=0/micro_step=2000/global_step=2000, RunningAvgSamplesPerSec=71.38449613225042, CurrSamplesPerSec=86.4441793782509, MemAllocated=14.61GB, MaxMemAllocated=16.29GB\n",
      "[2024-05-14 08:19:19,375] [INFO] [logging.py:96:log_dist] [Rank 0] step=2010, skipped=18, lr=[0.01], mom=[[0.8, 0.999]]\n",
      "[2024-05-14 08:19:19,376] [INFO] [timer.py:260:stop] epoch=0/micro_step=2010/global_step=2010, RunningAvgSamplesPerSec=71.36858269733787, CurrSamplesPerSec=59.59516517047205, MemAllocated=14.72GB, MaxMemAllocated=16.29GB\n",
      "{'epoch': 18, 'loss_train': 3.0525203784514347e-06, 'loss_val': 0.004831817069190601, 'accuracy_train': 1.0, 'accuracy_val': 0.7154046997389034}\n"
     ]
    }
   ],
   "source": [
    "hist = train_with_hist(model_engine, epochs=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0d3a2a32-9601-4458-82d3-b169d7e74ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_learning_curves(hist):\n",
    "    x_arr = np.arange(len(hist[0])) + 1\n",
    "    fig = plt.figure(figsize=(12, 4))\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    ax.plot(x_arr, hist[0], '-o', label='Train loss')\n",
    "    ax.plot(x_arr, hist[1], '--<', label='Validation loss')\n",
    "    ax.legend(fontsize=15)\n",
    "    ax = fig.add_subplot(1, 2, 2)\n",
    "    ax.plot(x_arr, hist[2], '-o', label='Train acc.')\n",
    "    ax.plot(x_arr, hist[3], '--<', label='Validation acc.')\n",
    "    ax.legend(fontsize=15)\n",
    "    ax.set_xlabel('Epoch', size=15)\n",
    "    ax.set_ylabel('Accuracy', size=15)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ad6a0c1b-3a25-4cff-96c6-3266913e208e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learning_curves(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3a230c-2886-4676-9a87-6bac8b503bb4",
   "metadata": {},
   "source": [
    "### Evaluate the model with test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29c316c-7bce-4176-b1fa-00dd769a6a1a",
   "metadata": {},
   "source": [
    "Checking the results of the test dataset…\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ebc0b680-b1de-4aee-bad4-baf7f50b9f0e",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the results of test dataset.\n",
      "test accuracy    0.709\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking the results of test dataset.\")\n",
    "accu_test, _ = evaluate(model, test_dataloader)\n",
    "print(\"test accuracy {:8.3f}\".format(accu_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ef9b09f4-0640-4e59-aefc-9d2d136d9f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create confusion matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_confusion_matrix(model, dataloader):\n",
    "    model.eval()\n",
    "    y_test = np.asarray([])\n",
    "    y_predict = np.asarray([])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (data, label) in enumerate(dataloader):\n",
    "            outputs = model(input_ids=data.input_ids, attention_mask=data.attention_mask)\n",
    "            predicted_label = outputs.logits\n",
    "                  \n",
    "            y_test = np.concatenate((y_test, np.asarray(label.to(device='cpu', dtype=torch.long))), axis=None)\n",
    "            y_predict = np.concatenate((y_predict, np.asarray((predicted_label.argmax(1).to(device='cpu', dtype=torch.long)))), axis=None)\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_predict)\n",
    "    sns.heatmap(cm, annot=True, fmt = \"d\")\n",
    "    print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2efeb419-1df7-4e6c-8814-ddf3294b9b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.76      0.73       111\n",
      "         1.0       0.71      0.66      0.68       102\n",
      "\n",
      "    accuracy                           0.71       213\n",
      "   macro avg       0.71      0.71      0.71       213\n",
      "weighted avg       0.71      0.71      0.71       213\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a457def5-9ac2-48c9-a2ef-69ead17b1834",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    with torch.no_grad():\n",
    "        encoded_text = tokenizer(text)\n",
    "        encoded_text.input_ids = torch.tensor(encoded_text.input_ids).to(device).unsqueeze(0)\n",
    "        encoded_text.attention_mask = torch.tensor(encoded_text.attention_mask).to(device).unsqueeze(0)\n",
    "\n",
    "        outputs = model(input_ids=encoded_text.input_ids, attention_mask=encoded_text.attention_mask)\n",
    "        predicted_label = outputs.logits\n",
    "        return predicted_label.argmax(1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "40c741cb-e91b-406f-a1f7-3c0ff292ab24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a 1\n"
     ]
    }
   ],
   "source": [
    "ex_text_str = 'The ePump Software shall define Fault ID 1 as follows:'\n",
    "\n",
    "print(\"This is a %s\" % predict(ex_text_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "61cc330f-c045-4453-a430-d19c5cac6bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_text = \"The IO Service shall select the XLR-PW DEV_INFO_DATA file if HPP_XLR_WIRING is grounded (logical 1) and bits AC_TYPE_BIT1 - AC_TYPE_BIT6 do not indicate a CFM engine configuration. NOTE: HPP_XLR_WIRING and bits AC_TYPE_BIT[1-6] are discrete inputs which are received on constant pins between hardware configurations. See 282100-ICD-x for more details.\"\n",
    "predict(pred_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "587df1de-6144-420e-a789-7771209aeca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_text = \"I shall like waffles\"\n",
    "predict(pred_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e3f924b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_text = \"Bumblebe is red\"\n",
    "predict(pred_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0c0e6726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_text = \"Bumblebee is red\"\n",
    "predict(pred_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec05f29a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7f226528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-14 08:33:30,325] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step2016 is about to be saved!\n",
      "[2024-05-14 08:33:30,325] [INFO] [engine.py:3596:save_16bit_model] Saving model weights to ./models/llama3_8b/2024-05-14_llama3_8b.pth, tag: global_step2016\n",
      "[2024-05-14 08:33:30,326] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./models/llama3_8b/2024-05-14_llama3_8b.pth...\n",
      "[2024-05-14 08:33:43,369] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./models/llama3_8b/2024-05-14_llama3_8b.pth.\n",
      "[2024-05-14 08:33:43,369] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2016 is ready now!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_engine.save_16bit_model(f\"./models/{model_name}/\", f\"{today}_{model_name}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f3e4a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/it/.cache/torch/hub/huggingface_pytorch-transformers_main\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1873157f8e5841cdb6e20ad3eb0bff62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Meta-Llama-3-8B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load(\n",
    "    \"huggingface/pytorch-transformers\",\n",
    "    \"modelForSequenceClassification\",\n",
    "    # \"meta-llama/Llama-2-7b-hf\",\n",
    "    \"meta-llama/Meta-Llama-3-8B\",\n",
    "    ignore_mismatched_sizes=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81e70d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score = nn.Linear(in_features=4096, out_features=2)\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df13cd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ecbf8ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('model.embed_tokens.weight',\n",
       "              tensor([[ 0.0317,  0.0227, -0.0164,  ...,  0.0066,  0.0151,  0.0326],\n",
       "                      [ 0.0275, -0.0381, -0.0169,  ...,  0.0117,  0.0117, -0.0174],\n",
       "                      [-0.0287, -0.0098,  0.0023,  ...,  0.0095,  0.0181, -0.0123],\n",
       "                      ...,\n",
       "                      [ 0.0146, -0.0074, -0.0189,  ..., -0.0002, -0.0100,  0.0220],\n",
       "                      [ 0.0168,  0.0191,  0.0102,  ..., -0.0082, -0.0141, -0.0043],\n",
       "                      [ 0.0033, -0.0194, -0.0119,  ..., -0.0374,  0.0095, -0.0008]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.0.self_attn.q_proj.weight',\n",
       "              tensor([[ 7.6523e-03,  6.2180e-03, -1.5793e-02,  ...,  9.3689e-03,\n",
       "                       -3.7994e-02,  6.8703e-03],\n",
       "                      [-2.9449e-02,  1.4744e-03, -2.0203e-02,  ..., -1.5823e-02,\n",
       "                        2.4994e-02, -1.5396e-02],\n",
       "                      [ 2.5597e-03, -3.0334e-02,  1.9806e-02,  ...,  3.1173e-05,\n",
       "                        2.3937e-03,  4.8920e-02],\n",
       "                      ...,\n",
       "                      [ 1.0292e-02, -1.9350e-03,  4.2009e-04,  ..., -6.2370e-04,\n",
       "                        1.1940e-02, -1.7822e-02],\n",
       "                      [ 1.4172e-03, -8.6441e-03, -1.1726e-02,  ...,  4.7821e-02,\n",
       "                        2.1696e-04, -2.0767e-02],\n",
       "                      [ 6.5002e-03, -5.0598e-02,  2.3766e-03,  ...,  4.0497e-02,\n",
       "                       -9.4681e-03, -1.4488e-02]], dtype=torch.float16)),\n",
       "             ('model.layers.0.self_attn.k_proj.weight',\n",
       "              tensor([[-1.5541e-02, -1.5831e-03,  7.8058e-04,  ..., -4.7722e-03,\n",
       "                       -1.6113e-02, -3.5343e-03],\n",
       "                      [-1.6159e-02, -5.0697e-03, -1.1017e-02,  ..., -2.4261e-03,\n",
       "                        3.7766e-03,  2.1988e-02],\n",
       "                      [-2.2797e-02,  2.0752e-02,  2.7924e-02,  ...,  1.2100e-02,\n",
       "                        1.9180e-02,  1.3718e-02],\n",
       "                      ...,\n",
       "                      [-1.6708e-02, -4.9706e-03,  2.9556e-02,  ..., -7.6523e-03,\n",
       "                        8.7023e-05, -1.2283e-02],\n",
       "                      [ 8.5526e-03, -3.0231e-03,  4.6387e-03,  ..., -7.7553e-03,\n",
       "                       -3.1090e-03,  1.4043e-04],\n",
       "                      [-1.9073e-02,  2.9175e-02, -2.4200e-02,  ..., -1.5205e-02,\n",
       "                       -8.6670e-03,  9.6054e-03]], dtype=torch.float16)),\n",
       "             ('model.layers.0.self_attn.v_proj.weight',\n",
       "              tensor([[-0.0214, -0.0279,  0.0101,  ..., -0.0310, -0.0258, -0.0061],\n",
       "                      [ 0.0297,  0.0060, -0.0395,  ...,  0.0468, -0.0072,  0.0200],\n",
       "                      [ 0.0141, -0.0075,  0.0120,  ...,  0.0055, -0.0130,  0.0072],\n",
       "                      ...,\n",
       "                      [ 0.0074,  0.0048, -0.0259,  ...,  0.0297,  0.0204,  0.0268],\n",
       "                      [-0.0260, -0.0316,  0.0090,  ..., -0.0088,  0.0136, -0.0067],\n",
       "                      [ 0.0040,  0.0101, -0.0108,  ...,  0.0184,  0.0090, -0.0384]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.0.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0085, -0.0004, -0.0041,  ..., -0.0285, -0.0273,  0.0038],\n",
       "                      [ 0.0331,  0.0058,  0.0106,  ...,  0.0093, -0.0022,  0.0005],\n",
       "                      [ 0.0022,  0.0325,  0.0287,  ..., -0.0029,  0.0023,  0.0201],\n",
       "                      ...,\n",
       "                      [ 0.0338, -0.0147,  0.0111,  ..., -0.0286, -0.0030, -0.0295],\n",
       "                      [-0.0236, -0.0255,  0.0027,  ..., -0.0213, -0.0237,  0.0036],\n",
       "                      [-0.0055, -0.0176, -0.0067,  ..., -0.0248,  0.0122,  0.0005]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.0.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0088, -0.0169,  0.0095,  ...,  0.0172,  0.0084, -0.0294],\n",
       "                      [ 0.0022,  0.0168,  0.0084,  ..., -0.0266, -0.0155,  0.0148],\n",
       "                      [ 0.0057,  0.0374,  0.0203,  ..., -0.0193, -0.0264,  0.0041],\n",
       "                      ...,\n",
       "                      [-0.0241, -0.0367, -0.0110,  ..., -0.0272, -0.0074, -0.0194],\n",
       "                      [ 0.0023,  0.0035,  0.0319,  ...,  0.0165,  0.0059,  0.0211],\n",
       "                      [ 0.0008, -0.0198,  0.0161,  ...,  0.0051,  0.0004, -0.0145]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.0.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0118, -0.0102, -0.0240,  ...,  0.0027,  0.0482,  0.0048],\n",
       "                      [-0.0097,  0.0036,  0.0006,  ..., -0.0146,  0.0509,  0.0365],\n",
       "                      [ 0.0193,  0.0145,  0.0181,  ..., -0.0020,  0.0287, -0.0145],\n",
       "                      ...,\n",
       "                      [-0.0264, -0.0449,  0.0234,  ..., -0.0121, -0.0298,  0.0102],\n",
       "                      [ 0.0249, -0.0170,  0.0009,  ..., -0.0383, -0.0185,  0.0004],\n",
       "                      [ 0.0210, -0.0046,  0.0032,  ..., -0.0103, -0.0060, -0.0102]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.0.mlp.down_proj.weight',\n",
       "              tensor([[-4.7455e-03,  1.8692e-02,  1.1307e-02,  ..., -1.9119e-02,\n",
       "                        1.6281e-02, -2.5162e-02],\n",
       "                      [-1.3252e-02, -1.2543e-02,  2.3178e-02,  ..., -1.2009e-02,\n",
       "                       -1.3680e-02,  1.1810e-02],\n",
       "                      [-1.1307e-02,  3.9185e-02,  1.6525e-02,  ...,  3.7994e-02,\n",
       "                       -4.1443e-02,  1.2131e-02],\n",
       "                      ...,\n",
       "                      [ 3.2379e-02, -6.4278e-03,  2.8061e-02,  ..., -3.9558e-03,\n",
       "                       -2.1458e-06,  2.6321e-02],\n",
       "                      [ 7.7896e-03, -2.0111e-02, -1.7075e-02,  ..., -2.0218e-02,\n",
       "                        3.6255e-02,  3.7903e-02],\n",
       "                      [ 2.2385e-02, -4.7607e-03, -2.0584e-02,  ...,  9.7275e-03,\n",
       "                        8.8196e-03,  9.8991e-04]], dtype=torch.float16)),\n",
       "             ('model.layers.0.input_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.0.post_attention_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.1.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0116,  0.0076, -0.0257,  ..., -0.0188, -0.0034, -0.0145],\n",
       "                      [ 0.0239,  0.0047,  0.0213,  ..., -0.0181, -0.0254, -0.0056],\n",
       "                      [-0.0091,  0.0056,  0.0129,  ..., -0.0205, -0.0108, -0.0083],\n",
       "                      ...,\n",
       "                      [-0.0018,  0.0240,  0.0039,  ...,  0.0105,  0.0223, -0.0532],\n",
       "                      [ 0.0056,  0.0508, -0.0019,  ...,  0.0068, -0.0224, -0.0183],\n",
       "                      [-0.0110, -0.0063, -0.0144,  ..., -0.0226, -0.0050, -0.0060]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.1.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0372,  0.0090, -0.0479,  ..., -0.0059, -0.0091,  0.0391],\n",
       "                      [ 0.0004, -0.0117, -0.0148,  ..., -0.0130,  0.0013,  0.0105],\n",
       "                      [-0.0075,  0.0154, -0.0050,  ...,  0.0273, -0.0410,  0.0311],\n",
       "                      ...,\n",
       "                      [-0.0086, -0.0088,  0.0321,  ...,  0.0075, -0.0042,  0.0042],\n",
       "                      [ 0.0133, -0.0578,  0.0554,  ..., -0.0198, -0.0073, -0.0342],\n",
       "                      [ 0.0414, -0.0049,  0.0172,  ...,  0.0340, -0.0040,  0.0078]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.1.self_attn.v_proj.weight',\n",
       "              tensor([[-0.0133,  0.0090,  0.0276,  ..., -0.0084,  0.0120, -0.0156],\n",
       "                      [-0.0242, -0.0204,  0.0047,  ..., -0.0089, -0.0236, -0.0107],\n",
       "                      [ 0.0117, -0.0065, -0.0168,  ...,  0.0081, -0.0230, -0.0105],\n",
       "                      ...,\n",
       "                      [ 0.0222,  0.0170, -0.0065,  ...,  0.0059, -0.0025, -0.0383],\n",
       "                      [-0.0392,  0.0015, -0.0387,  ..., -0.0143,  0.0160,  0.0025],\n",
       "                      [ 0.0087, -0.0097, -0.0137,  ...,  0.0215,  0.0060,  0.0018]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.1.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0046,  0.0221, -0.0115,  ...,  0.0298,  0.0169, -0.0209],\n",
       "                      [ 0.0162,  0.0057, -0.0208,  ..., -0.0007, -0.0222, -0.0031],\n",
       "                      [-0.0029, -0.0111,  0.0061,  ..., -0.0075,  0.0133, -0.0126],\n",
       "                      ...,\n",
       "                      [ 0.0050, -0.0149,  0.0031,  ..., -0.0063, -0.0092,  0.0017],\n",
       "                      [-0.0413,  0.0274,  0.0060,  ..., -0.0111, -0.0031,  0.0094],\n",
       "                      [-0.0073,  0.0142,  0.0248,  ...,  0.0173, -0.0046, -0.0171]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.1.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0216,  0.0182,  0.0064,  ...,  0.0321, -0.0194, -0.0122],\n",
       "                      [ 0.0046, -0.0039,  0.0165,  ..., -0.0018,  0.0209,  0.0061],\n",
       "                      [ 0.0009, -0.0100, -0.0041,  ...,  0.0248, -0.0291,  0.0010],\n",
       "                      ...,\n",
       "                      [ 0.0162,  0.0089,  0.0145,  ..., -0.0218,  0.0169, -0.0226],\n",
       "                      [-0.0156, -0.0066,  0.0193,  ..., -0.0110, -0.0079, -0.0015],\n",
       "                      [-0.0294, -0.0016, -0.0123,  ...,  0.0294, -0.0004, -0.0041]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.1.mlp.up_proj.weight',\n",
       "              tensor([[-0.0029, -0.0225,  0.0039,  ...,  0.0022, -0.0416, -0.0107],\n",
       "                      [-0.0068, -0.0131, -0.0110,  ..., -0.0034,  0.0473,  0.0047],\n",
       "                      [-0.0251, -0.0258, -0.0183,  ...,  0.0056,  0.0036,  0.0120],\n",
       "                      ...,\n",
       "                      [ 0.0053,  0.0114,  0.0039,  ..., -0.0094, -0.0157, -0.0132],\n",
       "                      [ 0.0008, -0.0049, -0.0118,  ..., -0.0049, -0.0345,  0.0273],\n",
       "                      [-0.0163, -0.0084,  0.0086,  ...,  0.0132, -0.0136,  0.0123]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.1.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0193, -0.0187,  0.0103,  ..., -0.0100, -0.0056, -0.0051],\n",
       "                      [ 0.0140, -0.0165,  0.0365,  ..., -0.0427,  0.0003,  0.0246],\n",
       "                      [-0.0256,  0.0320,  0.0280,  ...,  0.0080,  0.0024, -0.0324],\n",
       "                      ...,\n",
       "                      [-0.0434,  0.0336, -0.0066,  ..., -0.0322, -0.0029, -0.0023],\n",
       "                      [ 0.0307, -0.0213,  0.0067,  ...,  0.0345,  0.0133,  0.0246],\n",
       "                      [ 0.0050, -0.0114, -0.0178,  ...,  0.0109,  0.0053, -0.0175]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.1.input_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.1.post_attention_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.2.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0290, -0.0378,  0.0053,  ..., -0.0040,  0.0002,  0.0257],\n",
       "                      [ 0.0223,  0.0076,  0.0007,  ...,  0.0218,  0.0313,  0.0213],\n",
       "                      [ 0.0046, -0.0062, -0.0031,  ..., -0.0576, -0.0021, -0.0181],\n",
       "                      ...,\n",
       "                      [ 0.0239, -0.0317, -0.0191,  ..., -0.0210,  0.0057, -0.0100],\n",
       "                      [-0.0431,  0.0027, -0.0020,  ..., -0.0460, -0.0412,  0.0189],\n",
       "                      [-0.0280, -0.0112,  0.0081,  ..., -0.0131, -0.0208,  0.0199]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.2.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0345, -0.0239,  0.0136,  ..., -0.0157, -0.0108,  0.0124],\n",
       "                      [-0.0331,  0.0165,  0.0051,  ...,  0.0140,  0.0255, -0.0287],\n",
       "                      [-0.0066, -0.0295,  0.0065,  ..., -0.0160, -0.0113, -0.0238],\n",
       "                      ...,\n",
       "                      [ 0.0182, -0.0289, -0.0210,  ...,  0.0085, -0.0079,  0.0118],\n",
       "                      [ 0.0187,  0.0185,  0.0155,  ...,  0.0250,  0.0374, -0.0068],\n",
       "                      [-0.0305, -0.0417,  0.0314,  ..., -0.0014, -0.0010, -0.0036]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.2.self_attn.v_proj.weight',\n",
       "              tensor([[-3.8624e-05, -1.2291e-02,  1.3023e-02,  ..., -1.0017e-02,\n",
       "                       -3.1860e-02, -3.0575e-03],\n",
       "                      [-2.5368e-03,  2.3788e-02, -1.8112e-02,  ...,  5.6038e-03,\n",
       "                       -8.7128e-03, -4.5929e-03],\n",
       "                      [-6.3896e-03, -1.5656e-02,  1.4481e-02,  ..., -2.4612e-02,\n",
       "                        7.1182e-03,  3.3498e-04],\n",
       "                      ...,\n",
       "                      [ 1.3130e-02, -9.2545e-03,  1.3062e-02,  ..., -2.3102e-02,\n",
       "                       -1.4221e-02, -5.4474e-03],\n",
       "                      [ 8.0643e-03, -2.7832e-02, -1.0422e-02,  ..., -4.7226e-03,\n",
       "                       -3.3478e-02,  6.5079e-03],\n",
       "                      [-1.9547e-02, -1.9135e-02, -2.8320e-02,  ..., -1.7578e-02,\n",
       "                        6.4545e-03,  9.8877e-03]], dtype=torch.float16)),\n",
       "             ('model.layers.2.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0112,  0.0151, -0.0056,  ..., -0.0083, -0.0166,  0.0035],\n",
       "                      [ 0.0127, -0.0002,  0.0038,  ..., -0.0028,  0.0201,  0.0121],\n",
       "                      [-0.0679, -0.0265,  0.0249,  ...,  0.0046, -0.0117, -0.0153],\n",
       "                      ...,\n",
       "                      [-0.0208, -0.0156,  0.0196,  ...,  0.0069,  0.0090, -0.0086],\n",
       "                      [ 0.0083, -0.0070, -0.0192,  ..., -0.0051, -0.0119, -0.0222],\n",
       "                      [ 0.0063, -0.0236, -0.0301,  ..., -0.0182, -0.0213,  0.0141]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.2.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0179,  0.0011,  0.0158,  ...,  0.0037,  0.0111,  0.0050],\n",
       "                      [-0.0011, -0.0046, -0.0145,  ..., -0.0278, -0.0086,  0.0421],\n",
       "                      [-0.0069,  0.0224, -0.0311,  ..., -0.0174, -0.0207, -0.0450],\n",
       "                      ...,\n",
       "                      [ 0.0020, -0.0053, -0.0182,  ...,  0.0041, -0.0135, -0.0203],\n",
       "                      [ 0.0127, -0.0250, -0.0179,  ..., -0.0183, -0.0020, -0.0052],\n",
       "                      [ 0.0082,  0.0212, -0.0045,  ..., -0.0117,  0.0109, -0.0024]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.2.mlp.up_proj.weight',\n",
       "              tensor([[ 1.4328e-02, -1.0071e-02,  5.5733e-03,  ...,  2.3556e-03,\n",
       "                       -1.6022e-02,  8.5220e-03],\n",
       "                      [-1.7578e-02,  4.8462e-02, -4.8431e-02,  ...,  9.7809e-03,\n",
       "                        1.7500e-03, -5.5313e-03],\n",
       "                      [-1.9394e-02,  9.1171e-03,  1.9569e-03,  ...,  2.2690e-02,\n",
       "                        1.5106e-02, -3.7170e-02],\n",
       "                      ...,\n",
       "                      [-1.2039e-02,  3.6865e-02, -8.4534e-03,  ..., -2.2507e-02,\n",
       "                       -1.0967e-05,  1.0117e-02],\n",
       "                      [-2.5482e-02, -5.4665e-03,  1.5762e-02,  ...,  1.4153e-02,\n",
       "                       -2.3788e-02, -8.0261e-03],\n",
       "                      [ 2.0508e-02,  2.2079e-02, -6.0005e-03,  ..., -1.0971e-02,\n",
       "                       -3.8600e-04,  1.7593e-02]], dtype=torch.float16)),\n",
       "             ('model.layers.2.mlp.down_proj.weight',\n",
       "              tensor([[-0.0146,  0.0067,  0.0354,  ..., -0.0164, -0.0216, -0.0042],\n",
       "                      [ 0.0399, -0.0056,  0.0061,  ..., -0.0042,  0.0106, -0.0485],\n",
       "                      [ 0.0355, -0.0061, -0.0035,  ..., -0.0006, -0.0028, -0.0220],\n",
       "                      ...,\n",
       "                      [ 0.0098, -0.0240,  0.0096,  ...,  0.0059, -0.0426, -0.0076],\n",
       "                      [-0.0072,  0.0105,  0.0253,  ..., -0.0196, -0.0084,  0.0027],\n",
       "                      [-0.0193, -0.0230,  0.0086,  ..., -0.0130,  0.0173, -0.0109]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.2.input_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.2.post_attention_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.3.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0264, -0.0029, -0.0461,  ..., -0.0162, -0.0320, -0.0119],\n",
       "                      [ 0.0212, -0.0128,  0.0155,  ..., -0.0001,  0.0007,  0.0047],\n",
       "                      [-0.0013, -0.0007,  0.0193,  ...,  0.0286,  0.0207,  0.0427],\n",
       "                      ...,\n",
       "                      [-0.0028, -0.0051, -0.0154,  ..., -0.0079,  0.0368, -0.0146],\n",
       "                      [-0.0203, -0.0053,  0.0084,  ...,  0.0129, -0.0109, -0.0046],\n",
       "                      [-0.0298,  0.0146,  0.0125,  ...,  0.0114, -0.0139, -0.0099]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.3.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0032, -0.0108,  0.0070,  ...,  0.0245,  0.0050,  0.0083],\n",
       "                      [ 0.0108,  0.0054, -0.0018,  ...,  0.0109,  0.0006,  0.0161],\n",
       "                      [-0.0155,  0.0135, -0.0094,  ..., -0.0072, -0.0062, -0.0083],\n",
       "                      ...,\n",
       "                      [ 0.0202,  0.0032,  0.0298,  ...,  0.0040,  0.0198, -0.0138],\n",
       "                      [ 0.0086, -0.0205,  0.0056,  ...,  0.0140,  0.0053,  0.0176],\n",
       "                      [-0.0014,  0.0237,  0.0010,  ...,  0.0072,  0.0003, -0.0219]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.3.self_attn.v_proj.weight',\n",
       "              tensor([[ 0.0112,  0.0080,  0.0106,  ...,  0.0154, -0.0010,  0.0222],\n",
       "                      [-0.0187,  0.0075, -0.0155,  ..., -0.0122, -0.0049, -0.0326],\n",
       "                      [ 0.0015,  0.0021, -0.0080,  ...,  0.0210, -0.0142, -0.0265],\n",
       "                      ...,\n",
       "                      [-0.0108, -0.0056,  0.0037,  ...,  0.0424,  0.0267,  0.0332],\n",
       "                      [ 0.0063, -0.0068, -0.0194,  ..., -0.0375, -0.0040,  0.0059],\n",
       "                      [-0.0213,  0.0007, -0.0029,  ..., -0.0130,  0.0197, -0.0036]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.3.self_attn.o_proj.weight',\n",
       "              tensor([[-2.0660e-02, -4.9042e-02,  1.5762e-02,  ..., -1.1101e-03,\n",
       "                       -9.3842e-03, -1.0025e-02],\n",
       "                      [ 4.1107e-02,  2.0386e-02,  3.9124e-02,  ...,  9.4986e-03,\n",
       "                        2.0950e-02,  5.4896e-05],\n",
       "                      [-2.5711e-02, -8.2550e-03, -1.3075e-03,  ...,  1.9562e-02,\n",
       "                        3.3356e-02, -3.0991e-02],\n",
       "                      ...,\n",
       "                      [-9.5901e-03, -3.7048e-02, -2.8610e-03,  ..., -3.7518e-03,\n",
       "                       -3.5248e-02, -1.8616e-03],\n",
       "                      [-1.4198e-02, -2.0157e-02, -1.2466e-02,  ...,  8.7204e-03,\n",
       "                        3.3173e-02, -5.2032e-03],\n",
       "                      [-7.5340e-04, -2.2827e-02,  2.1698e-02,  ..., -8.9884e-04,\n",
       "                        1.6117e-03, -4.9553e-03]], dtype=torch.float16)),\n",
       "             ('model.layers.3.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0367, -0.0051,  0.0069,  ..., -0.0018, -0.0088, -0.0046],\n",
       "                      [ 0.0065, -0.0207,  0.0017,  ...,  0.0128,  0.0213,  0.0042],\n",
       "                      [ 0.0305, -0.0059, -0.0113,  ...,  0.0329,  0.0385, -0.0452],\n",
       "                      ...,\n",
       "                      [ 0.0360,  0.0163,  0.0238,  ...,  0.0225,  0.0101, -0.0211],\n",
       "                      [ 0.0092, -0.0106,  0.0215,  ...,  0.0130, -0.0164,  0.0068],\n",
       "                      [-0.0168, -0.0108,  0.0072,  ...,  0.0051, -0.0084,  0.0076]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.3.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0292,  0.0222,  0.0040,  ..., -0.0164,  0.0078, -0.0202],\n",
       "                      [ 0.0302, -0.0102, -0.0115,  ..., -0.0028,  0.0026, -0.0067],\n",
       "                      [-0.0146, -0.0242,  0.0125,  ..., -0.0175,  0.0066, -0.0068],\n",
       "                      ...,\n",
       "                      [ 0.0038, -0.0075, -0.0161,  ..., -0.0175, -0.0128,  0.0130],\n",
       "                      [ 0.0245, -0.0305,  0.0173,  ..., -0.0020, -0.0207, -0.0289],\n",
       "                      [-0.0388,  0.0002,  0.0106,  ...,  0.0210, -0.0082, -0.0085]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.3.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0232,  0.0097, -0.0180,  ...,  0.0610, -0.0248, -0.0134],\n",
       "                      [ 0.0068,  0.0163, -0.0150,  ..., -0.0176,  0.0192,  0.0122],\n",
       "                      [-0.0269,  0.0222, -0.0318,  ..., -0.0102, -0.0065,  0.0036],\n",
       "                      ...,\n",
       "                      [-0.0124, -0.0206, -0.0158,  ...,  0.0041,  0.0195,  0.0019],\n",
       "                      [ 0.0065,  0.0126, -0.0204,  ..., -0.0181, -0.0272, -0.0109],\n",
       "                      [ 0.0160, -0.0121,  0.0243,  ...,  0.0015,  0.0297,  0.0311]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.3.input_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.3.post_attention_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.4.self_attn.q_proj.weight',\n",
       "              tensor([[ 0.0011, -0.0177, -0.0293,  ..., -0.0045, -0.0625, -0.0145],\n",
       "                      [-0.0160,  0.0240,  0.0316,  ...,  0.0219,  0.0181,  0.0072],\n",
       "                      [ 0.0128, -0.0081,  0.0211,  ...,  0.0083, -0.0264,  0.0172],\n",
       "                      ...,\n",
       "                      [ 0.0006,  0.0080, -0.0018,  ...,  0.0421,  0.0128, -0.0130],\n",
       "                      [-0.0043, -0.0049, -0.0106,  ..., -0.0120,  0.0048,  0.0198],\n",
       "                      [-0.0257, -0.0011,  0.0087,  ..., -0.0196, -0.0369, -0.0015]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.4.self_attn.k_proj.weight',\n",
       "              tensor([[-1.4404e-02, -1.3695e-03, -3.9520e-02,  ...,  1.7761e-02,\n",
       "                       -1.4160e-02,  9.9640e-03],\n",
       "                      [-2.5986e-02, -4.8409e-03, -2.5009e-02,  ..., -3.1219e-02,\n",
       "                       -1.4458e-02,  8.1024e-03],\n",
       "                      [ 2.0020e-02,  3.5431e-02, -2.0187e-02,  ...,  2.5864e-02,\n",
       "                       -2.1271e-02, -5.3787e-03],\n",
       "                      ...,\n",
       "                      [-6.1989e-03, -1.0460e-02,  9.4223e-03,  ..., -1.0834e-03,\n",
       "                        3.7567e-02, -1.5020e-03],\n",
       "                      [ 3.4750e-05, -6.7635e-03, -2.9068e-02,  ..., -1.3170e-03,\n",
       "                       -4.7272e-02, -3.6011e-02],\n",
       "                      [ 4.2915e-03, -1.3657e-02,  1.1635e-03,  ..., -3.3646e-03,\n",
       "                       -7.4272e-03,  8.7585e-03]], dtype=torch.float16)),\n",
       "             ('model.layers.4.self_attn.v_proj.weight',\n",
       "              tensor([[-0.0292, -0.0140, -0.0044,  ...,  0.0187,  0.0248, -0.0018],\n",
       "                      [-0.0152,  0.0185, -0.0204,  ...,  0.0008, -0.0055,  0.0418],\n",
       "                      [ 0.0509, -0.0149, -0.0232,  ...,  0.0033, -0.0016,  0.0147],\n",
       "                      ...,\n",
       "                      [-0.0211, -0.0157, -0.0124,  ..., -0.0008,  0.0343,  0.0220],\n",
       "                      [-0.0014, -0.0126,  0.0236,  ..., -0.0006, -0.0201,  0.0255],\n",
       "                      [-0.0092, -0.0249, -0.0172,  ..., -0.0137, -0.0222, -0.0106]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.4.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0224,  0.0096, -0.0080,  ...,  0.0106, -0.0035, -0.0183],\n",
       "                      [ 0.0123, -0.0213,  0.0024,  ...,  0.0320,  0.0033, -0.0042],\n",
       "                      [-0.0249,  0.0073, -0.0024,  ..., -0.0323,  0.0086, -0.0534],\n",
       "                      ...,\n",
       "                      [ 0.0150,  0.0029, -0.0179,  ...,  0.0337,  0.0130, -0.0247],\n",
       "                      [-0.0306,  0.0150, -0.0003,  ..., -0.0117, -0.0018, -0.0046],\n",
       "                      [-0.0119, -0.0064, -0.0401,  ...,  0.0243, -0.0151,  0.0022]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.4.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0204, -0.0269, -0.0156,  ...,  0.0268, -0.0124,  0.0136],\n",
       "                      [ 0.0209,  0.0048,  0.0411,  ..., -0.0179, -0.0162,  0.0282],\n",
       "                      [ 0.0642, -0.0140,  0.0024,  ...,  0.0247, -0.0169,  0.0131],\n",
       "                      ...,\n",
       "                      [-0.0331,  0.0252,  0.0171,  ...,  0.0147,  0.0089,  0.0174],\n",
       "                      [-0.0198, -0.0117, -0.0011,  ..., -0.0312,  0.0072, -0.0080],\n",
       "                      [ 0.0250, -0.0148,  0.0147,  ...,  0.0181, -0.0120, -0.0056]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.4.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0550,  0.0073,  0.0323,  ..., -0.0167,  0.0235, -0.0109],\n",
       "                      [ 0.0132,  0.0342, -0.0026,  ...,  0.0129, -0.0278, -0.0238],\n",
       "                      [-0.0098,  0.0002, -0.0248,  ..., -0.0172, -0.0257,  0.0060],\n",
       "                      ...,\n",
       "                      [-0.0179, -0.0047,  0.0241,  ...,  0.0073, -0.0239,  0.0302],\n",
       "                      [-0.0081, -0.0067,  0.0221,  ...,  0.0001, -0.0118,  0.0008],\n",
       "                      [ 0.0036, -0.0580,  0.0045,  ..., -0.0222,  0.0163,  0.0126]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.4.mlp.down_proj.weight',\n",
       "              tensor([[-0.0050,  0.0159,  0.0060,  ..., -0.0174,  0.0073, -0.0035],\n",
       "                      [ 0.0092,  0.0071,  0.0129,  ..., -0.0040,  0.0125,  0.0057],\n",
       "                      [-0.0061,  0.0226, -0.0128,  ...,  0.0163,  0.0160, -0.0116],\n",
       "                      ...,\n",
       "                      [-0.0152, -0.0119,  0.0199,  ...,  0.0141, -0.0214, -0.0165],\n",
       "                      [-0.0255,  0.0334, -0.0007,  ...,  0.0015, -0.0149, -0.0022],\n",
       "                      [ 0.0158,  0.0143,  0.0180,  ..., -0.0258, -0.0036,  0.0011]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.4.input_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.4.post_attention_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.5.self_attn.q_proj.weight',\n",
       "              tensor([[-4.0092e-03,  2.9716e-03,  8.3590e-04,  ..., -1.3481e-02,\n",
       "                        1.1642e-02,  2.0554e-02],\n",
       "                      [-3.0258e-02,  7.9269e-03, -1.4946e-02,  ..., -2.3605e-02,\n",
       "                       -1.5701e-02, -2.8000e-02],\n",
       "                      [ 2.3819e-02,  1.4252e-02,  3.1872e-03,  ...,  4.0558e-02,\n",
       "                        2.0752e-03, -1.4908e-02],\n",
       "                      ...,\n",
       "                      [-2.2781e-02,  2.8442e-02, -1.6159e-02,  ..., -4.2000e-03,\n",
       "                        1.2543e-02,  5.6458e-03],\n",
       "                      [-2.0508e-02, -8.7619e-06, -1.2428e-02,  ..., -5.4512e-03,\n",
       "                        1.9592e-02, -3.4882e-02],\n",
       "                      [-1.2695e-02, -1.4900e-02,  1.0633e-03,  ..., -2.3365e-03,\n",
       "                       -7.2718e-04,  3.3966e-02]], dtype=torch.float16)),\n",
       "             ('model.layers.5.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0181, -0.0059, -0.0152,  ...,  0.0025, -0.0250,  0.0013],\n",
       "                      [-0.0209,  0.0102,  0.0304,  ..., -0.0046,  0.0157,  0.0209],\n",
       "                      [ 0.0333, -0.0193,  0.0109,  ...,  0.0138,  0.0166, -0.0169],\n",
       "                      ...,\n",
       "                      [ 0.0278,  0.0235, -0.0063,  ...,  0.0059,  0.0099,  0.0030],\n",
       "                      [-0.0220, -0.0023, -0.0100,  ...,  0.0125, -0.0216, -0.0185],\n",
       "                      [-0.0175,  0.0106,  0.0327,  ...,  0.0079, -0.0450,  0.0389]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.5.self_attn.v_proj.weight',\n",
       "              tensor([[-0.0165,  0.0048,  0.0086,  ...,  0.0088, -0.0025, -0.0061],\n",
       "                      [-0.0108,  0.0017,  0.0158,  ..., -0.0047,  0.0334, -0.0086],\n",
       "                      [-0.0022,  0.0100, -0.0074,  ..., -0.0278,  0.0059,  0.0125],\n",
       "                      ...,\n",
       "                      [-0.0234, -0.0012,  0.0277,  ...,  0.0009,  0.0084, -0.0108],\n",
       "                      [-0.0045,  0.0434,  0.0130,  ..., -0.0278, -0.0105,  0.0187],\n",
       "                      [ 0.0080, -0.0360, -0.0138,  ...,  0.0195,  0.0199, -0.0012]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.5.self_attn.o_proj.weight',\n",
       "              tensor([[-0.0275, -0.0108, -0.0006,  ..., -0.0004, -0.0020,  0.0013],\n",
       "                      [-0.0148, -0.0008, -0.0010,  ...,  0.0383, -0.0318,  0.0079],\n",
       "                      [ 0.0084,  0.0199,  0.0021,  ..., -0.0148,  0.0039,  0.0146],\n",
       "                      ...,\n",
       "                      [-0.0378,  0.0261,  0.0314,  ..., -0.0101, -0.0073, -0.0182],\n",
       "                      [ 0.0289,  0.0422,  0.0078,  ...,  0.0061, -0.0027, -0.0138],\n",
       "                      [ 0.0173, -0.0030,  0.0242,  ..., -0.0023,  0.0075,  0.0069]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.5.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0208, -0.0030, -0.0216,  ...,  0.0311, -0.0413, -0.0029],\n",
       "                      [-0.0209,  0.0330,  0.0224,  ...,  0.0123,  0.0245,  0.0161],\n",
       "                      [ 0.0269,  0.0159,  0.0104,  ...,  0.0031, -0.0028,  0.0127],\n",
       "                      ...,\n",
       "                      [-0.0371,  0.0695, -0.0022,  ..., -0.0131,  0.0199,  0.0212],\n",
       "                      [ 0.0055,  0.0080, -0.0027,  ..., -0.0223,  0.0075, -0.0054],\n",
       "                      [ 0.0241, -0.0078,  0.0196,  ...,  0.0042,  0.0071,  0.0077]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.5.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0080,  0.0340, -0.0186,  ...,  0.0023, -0.0050, -0.0231],\n",
       "                      [ 0.0346, -0.0053, -0.0134,  ...,  0.0113, -0.0096, -0.0383],\n",
       "                      [-0.0069, -0.0376, -0.0074,  ...,  0.0120,  0.0198,  0.0056],\n",
       "                      ...,\n",
       "                      [-0.0087, -0.0151, -0.0042,  ...,  0.0111, -0.0181,  0.0340],\n",
       "                      [ 0.0278, -0.0126,  0.0216,  ..., -0.0276, -0.0018, -0.0236],\n",
       "                      [ 0.0111, -0.0047, -0.0114,  ..., -0.0055, -0.0074, -0.0120]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.5.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0149, -0.0201, -0.0035,  ...,  0.0022,  0.0245,  0.0069],\n",
       "                      [-0.0110,  0.0279, -0.0039,  ..., -0.0266, -0.0086, -0.0011],\n",
       "                      [ 0.0331, -0.0002,  0.0088,  ...,  0.0512, -0.0139, -0.0212],\n",
       "                      ...,\n",
       "                      [-0.0121,  0.0142, -0.0168,  ...,  0.0287, -0.0001, -0.0373],\n",
       "                      [ 0.0055,  0.0129, -0.0361,  ..., -0.0148,  0.0144,  0.0403],\n",
       "                      [ 0.0101,  0.0193,  0.0095,  ..., -0.0151,  0.0024,  0.0271]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.5.input_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.5.post_attention_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.6.self_attn.q_proj.weight',\n",
       "              tensor([[ 1.9577e-02,  3.9734e-02, -8.7280e-03,  ...,  3.6835e-02,\n",
       "                        4.9248e-03,  3.6087e-03],\n",
       "                      [-6.0272e-03,  7.5226e-03, -1.1612e-02,  ..., -9.4833e-03,\n",
       "                       -1.0841e-02,  4.1084e-03],\n",
       "                      [ 1.0231e-02,  2.1500e-02, -2.8885e-02,  ..., -2.1866e-02,\n",
       "                       -3.7994e-02, -2.0615e-02],\n",
       "                      ...,\n",
       "                      [-2.9831e-02,  1.4084e-02,  2.5833e-02,  ...,  3.0563e-02,\n",
       "                       -2.2018e-02, -3.7498e-03],\n",
       "                      [-4.0665e-03,  2.3422e-02,  2.7786e-02,  ...,  1.5930e-02,\n",
       "                       -6.4163e-03, -5.1384e-03],\n",
       "                      [ 1.9989e-02,  1.1854e-03, -2.3178e-02,  ...,  9.8114e-03,\n",
       "                        6.5842e-03, -3.3438e-05]], dtype=torch.float16)),\n",
       "             ('model.layers.6.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0078,  0.0040,  0.0190,  ..., -0.0184,  0.0085,  0.0053],\n",
       "                      [ 0.0141,  0.0396,  0.0272,  ..., -0.0165,  0.0098, -0.0117],\n",
       "                      [ 0.0275, -0.0162, -0.0200,  ...,  0.0161, -0.0032,  0.0205],\n",
       "                      ...,\n",
       "                      [-0.0119,  0.0139,  0.0079,  ..., -0.0442, -0.0280,  0.0341],\n",
       "                      [-0.0003, -0.0229, -0.0042,  ..., -0.0148,  0.0225, -0.0135],\n",
       "                      [-0.0079, -0.0095, -0.0171,  ...,  0.0113, -0.0140,  0.0213]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.6.self_attn.v_proj.weight',\n",
       "              tensor([[ 0.0024, -0.0363,  0.0221,  ...,  0.0155,  0.0158, -0.0173],\n",
       "                      [ 0.0030,  0.0052,  0.0159,  ..., -0.0004, -0.0017,  0.0352],\n",
       "                      [ 0.0121, -0.0336, -0.0078,  ..., -0.0207, -0.0175,  0.0383],\n",
       "                      ...,\n",
       "                      [-0.0133, -0.0069,  0.0361,  ..., -0.0137, -0.0027,  0.0237],\n",
       "                      [-0.0209,  0.0065,  0.0184,  ..., -0.0110,  0.0054,  0.0040],\n",
       "                      [-0.0224, -0.0204,  0.0082,  ..., -0.0157, -0.0034, -0.0074]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.6.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0022, -0.0517, -0.0251,  ...,  0.0181, -0.0149, -0.0171],\n",
       "                      [ 0.0123, -0.0002,  0.0322,  ..., -0.0304,  0.0193, -0.0017],\n",
       "                      [-0.0114,  0.0126, -0.0347,  ...,  0.0233,  0.0073,  0.0157],\n",
       "                      ...,\n",
       "                      [ 0.0227,  0.0220,  0.0079,  ...,  0.0193, -0.0017,  0.0071],\n",
       "                      [ 0.0102,  0.0210, -0.0325,  ...,  0.0111, -0.0213,  0.0066],\n",
       "                      [ 0.0003,  0.0182, -0.0063,  ..., -0.0133, -0.0346, -0.0055]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.6.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0207, -0.0320,  0.0061,  ...,  0.0019, -0.0306, -0.0288],\n",
       "                      [-0.0100, -0.0095,  0.0034,  ..., -0.0030,  0.0294, -0.0301],\n",
       "                      [-0.0064, -0.0005, -0.0175,  ...,  0.0241, -0.0029,  0.0053],\n",
       "                      ...,\n",
       "                      [-0.0168,  0.0059,  0.0023,  ...,  0.0327, -0.0011,  0.0120],\n",
       "                      [-0.0124,  0.0022,  0.0075,  ...,  0.0101, -0.0277, -0.0076],\n",
       "                      [-0.0093,  0.0461,  0.0390,  ...,  0.0086, -0.0108, -0.0021]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.6.mlp.up_proj.weight',\n",
       "              tensor([[-1.7883e-02, -1.9257e-02,  1.5930e-02,  ..., -7.0457e-03,\n",
       "                        1.5068e-02, -3.0518e-02],\n",
       "                      [-2.2144e-03, -4.1847e-03, -2.1194e-02,  ..., -6.0692e-03,\n",
       "                        2.4612e-02, -1.7212e-02],\n",
       "                      [ 7.1640e-03,  2.4529e-03, -1.1002e-02,  ...,  2.1622e-02,\n",
       "                       -1.3672e-02,  2.2858e-02],\n",
       "                      ...,\n",
       "                      [ 5.9357e-03,  2.7466e-03,  2.3682e-02,  ..., -3.4454e-02,\n",
       "                        4.9820e-03, -7.1182e-03],\n",
       "                      [ 1.5914e-05,  1.4526e-02,  2.1164e-02,  ...,  7.3509e-03,\n",
       "                       -1.8234e-02, -1.6464e-02],\n",
       "                      [-8.8806e-03,  4.3607e-04,  2.6321e-03,  ..., -1.3336e-02,\n",
       "                        2.5238e-02,  8.7509e-03]], dtype=torch.float16)),\n",
       "             ('model.layers.6.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0350, -0.0386,  0.0115,  ..., -0.0082, -0.0061, -0.0246],\n",
       "                      [-0.0280,  0.0483,  0.0122,  ...,  0.0237,  0.0144, -0.0131],\n",
       "                      [ 0.0216,  0.0175, -0.0063,  ...,  0.0063,  0.0264,  0.0119],\n",
       "                      ...,\n",
       "                      [-0.0089,  0.0258, -0.0144,  ...,  0.0239, -0.0246,  0.0034],\n",
       "                      [ 0.0024,  0.0081,  0.0324,  ...,  0.0029,  0.0245, -0.0009],\n",
       "                      [-0.0075, -0.0315,  0.0356,  ...,  0.0392,  0.0012, -0.0284]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.6.input_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.6.post_attention_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.7.self_attn.q_proj.weight',\n",
       "              tensor([[-1.5297e-02,  1.2062e-02,  1.2375e-02,  ..., -1.8448e-02,\n",
       "                        8.9874e-03, -1.2871e-02],\n",
       "                      [-2.2125e-02,  3.6263e-04,  4.4785e-03,  ...,  3.9482e-03,\n",
       "                       -1.8997e-02,  2.4170e-02],\n",
       "                      [ 4.9257e-04, -5.3101e-03,  2.9862e-05,  ..., -2.1667e-02,\n",
       "                       -5.3329e-03,  1.4572e-03],\n",
       "                      ...,\n",
       "                      [-1.0429e-02,  5.5733e-03, -5.1155e-03,  ...,  1.3931e-02,\n",
       "                        1.6663e-02,  1.3878e-02],\n",
       "                      [ 2.4887e-02, -1.9150e-02,  3.2177e-03,  ...,  3.6102e-02,\n",
       "                       -8.9188e-03, -7.8354e-03],\n",
       "                      [ 2.4506e-02,  6.8951e-04,  1.2878e-02,  ...,  4.6158e-03,\n",
       "                       -1.0597e-02, -4.9973e-03]], dtype=torch.float16)),\n",
       "             ('model.layers.7.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0305,  0.0076, -0.0153,  ..., -0.0248, -0.0196,  0.0129],\n",
       "                      [-0.0706,  0.0150,  0.0168,  ...,  0.0144, -0.0103, -0.0110],\n",
       "                      [ 0.0003, -0.0558, -0.0156,  ..., -0.0210, -0.0347,  0.0323],\n",
       "                      ...,\n",
       "                      [ 0.0213, -0.0001, -0.0076,  ...,  0.0360, -0.0543,  0.0044],\n",
       "                      [ 0.0032,  0.0053,  0.0240,  ..., -0.0024, -0.0197,  0.0153],\n",
       "                      [-0.0253, -0.0036, -0.0210,  ..., -0.0092,  0.0068,  0.0134]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.7.self_attn.v_proj.weight',\n",
       "              tensor([[ 0.0008,  0.0104,  0.0137,  ...,  0.0177,  0.0233, -0.0211],\n",
       "                      [-0.0213,  0.0070, -0.0168,  ..., -0.0223, -0.0057, -0.0556],\n",
       "                      [ 0.0532, -0.0116,  0.0117,  ...,  0.0103,  0.0038, -0.0468],\n",
       "                      ...,\n",
       "                      [ 0.0005, -0.0061, -0.0245,  ..., -0.0187, -0.0015,  0.0128],\n",
       "                      [-0.0265,  0.0065, -0.0068,  ..., -0.0066, -0.0049,  0.0346],\n",
       "                      [ 0.0123,  0.0030,  0.0330,  ...,  0.0200,  0.0172, -0.0050]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.7.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0284,  0.0239, -0.0354,  ..., -0.0210, -0.0178,  0.0218],\n",
       "                      [ 0.0226, -0.0168,  0.0249,  ...,  0.0168, -0.0067, -0.0040],\n",
       "                      [ 0.0282, -0.0037, -0.0293,  ..., -0.0466, -0.0332, -0.0163],\n",
       "                      ...,\n",
       "                      [-0.0054, -0.0098, -0.0125,  ...,  0.0109, -0.0046,  0.0129],\n",
       "                      [ 0.0179,  0.0321,  0.0174,  ..., -0.0114,  0.0027,  0.0645],\n",
       "                      [-0.0347, -0.0330, -0.0120,  ..., -0.0161,  0.0059,  0.0011]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.7.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0197, -0.0242, -0.0180,  ..., -0.0092,  0.0129, -0.0065],\n",
       "                      [-0.0186,  0.0107, -0.0070,  ..., -0.0164, -0.0089, -0.0444],\n",
       "                      [ 0.0320, -0.0121, -0.0148,  ...,  0.0297,  0.0091, -0.0226],\n",
       "                      ...,\n",
       "                      [ 0.0007,  0.0052, -0.0049,  ..., -0.0088, -0.0078, -0.0136],\n",
       "                      [-0.0225,  0.0299,  0.0093,  ...,  0.0003,  0.0128, -0.0273],\n",
       "                      [ 0.0091,  0.0029,  0.0186,  ..., -0.0152, -0.0089,  0.0248]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.7.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0151,  0.0221, -0.0126,  ...,  0.0088,  0.0142,  0.0002],\n",
       "                      [ 0.0020,  0.0073,  0.0100,  ...,  0.0013,  0.0164, -0.0166],\n",
       "                      [ 0.0160,  0.0160,  0.0226,  ..., -0.0069,  0.0170,  0.0073],\n",
       "                      ...,\n",
       "                      [ 0.0332, -0.0064, -0.0107,  ..., -0.0157,  0.0308, -0.0094],\n",
       "                      [ 0.0012, -0.0204, -0.0134,  ...,  0.0018, -0.0537,  0.0233],\n",
       "                      [ 0.0144, -0.0078, -0.0160,  ..., -0.0174,  0.0251, -0.0312]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.7.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0065,  0.0093,  0.0187,  ...,  0.0063,  0.0130,  0.0133],\n",
       "                      [-0.0151, -0.0250,  0.0179,  ..., -0.0440, -0.0308,  0.0118],\n",
       "                      [-0.0095,  0.0138, -0.0112,  ...,  0.0067,  0.0202,  0.0203],\n",
       "                      ...,\n",
       "                      [-0.0162, -0.0184,  0.0049,  ..., -0.0145,  0.0063, -0.0035],\n",
       "                      [ 0.0200,  0.0387,  0.0128,  ...,  0.0077, -0.0366,  0.0136],\n",
       "                      [ 0.0425, -0.0113,  0.0245,  ...,  0.0416,  0.0436, -0.0093]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.7.input_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.7.post_attention_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.8.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0031,  0.0031, -0.0067,  ...,  0.0077, -0.0020,  0.0205],\n",
       "                      [ 0.0286, -0.0051, -0.0343,  ..., -0.0037,  0.0062,  0.0113],\n",
       "                      [-0.0045, -0.0367, -0.0092,  ...,  0.0018,  0.0462, -0.0018],\n",
       "                      ...,\n",
       "                      [-0.0349,  0.0017,  0.0038,  ...,  0.0157, -0.0123, -0.0142],\n",
       "                      [ 0.0043,  0.0024,  0.0076,  ..., -0.0242, -0.0187,  0.0032],\n",
       "                      [ 0.0281,  0.0206,  0.0081,  ...,  0.0209,  0.0002, -0.0119]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.8.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0172,  0.0065, -0.0157,  ..., -0.0240,  0.0072,  0.0116],\n",
       "                      [ 0.0041,  0.0096,  0.0195,  ...,  0.0305, -0.0099, -0.0133],\n",
       "                      [ 0.0033,  0.0074, -0.0166,  ..., -0.0012,  0.0056, -0.0157],\n",
       "                      ...,\n",
       "                      [ 0.0003, -0.0207, -0.0052,  ..., -0.0122,  0.0023,  0.0196],\n",
       "                      [-0.0404, -0.0089,  0.0214,  ...,  0.0030, -0.0016, -0.0184],\n",
       "                      [ 0.0064,  0.0305,  0.0066,  ...,  0.0216,  0.0048,  0.0031]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.8.self_attn.v_proj.weight',\n",
       "              tensor([[-0.0273,  0.0341,  0.0134,  ..., -0.0074,  0.0036, -0.0179],\n",
       "                      [ 0.0431,  0.0055, -0.0057,  ..., -0.0307,  0.0016,  0.0053],\n",
       "                      [-0.0148,  0.0167, -0.0353,  ..., -0.0104,  0.0058,  0.0155],\n",
       "                      ...,\n",
       "                      [ 0.0272, -0.0154,  0.0031,  ..., -0.0091,  0.0079, -0.0013],\n",
       "                      [ 0.0020, -0.0251, -0.0419,  ...,  0.0103, -0.0116, -0.0369],\n",
       "                      [ 0.0290, -0.0077,  0.0042,  ..., -0.0249, -0.0009,  0.0174]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.8.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0091,  0.0015,  0.0095,  ..., -0.0161,  0.0184, -0.0053],\n",
       "                      [ 0.0084,  0.0262, -0.0077,  ...,  0.0062,  0.0272, -0.0237],\n",
       "                      [ 0.0487, -0.0163, -0.0208,  ..., -0.0007, -0.0112,  0.0331],\n",
       "                      ...,\n",
       "                      [ 0.0054,  0.0311,  0.0030,  ..., -0.0138, -0.0083,  0.0268],\n",
       "                      [-0.0151, -0.0003, -0.0067,  ...,  0.0040, -0.0003, -0.0166],\n",
       "                      [-0.0064, -0.0276,  0.0152,  ..., -0.0051,  0.0008, -0.0063]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.8.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0043, -0.0017, -0.0115,  ...,  0.0125,  0.0048,  0.0074],\n",
       "                      [ 0.0133,  0.0105,  0.0084,  ..., -0.0120,  0.0082,  0.0288],\n",
       "                      [ 0.0081,  0.0056,  0.0273,  ...,  0.0222, -0.0180, -0.0107],\n",
       "                      ...,\n",
       "                      [ 0.0078,  0.0050, -0.0123,  ...,  0.0035, -0.0096,  0.0170],\n",
       "                      [-0.0201, -0.0179,  0.0185,  ..., -0.0014, -0.0130, -0.0289],\n",
       "                      [-0.0212,  0.0104, -0.0192,  ..., -0.0289,  0.0003,  0.0030]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.8.mlp.up_proj.weight',\n",
       "              tensor([[-0.0244, -0.0139, -0.0058,  ..., -0.0175,  0.0012,  0.0238],\n",
       "                      [ 0.0074, -0.0507,  0.0073,  ..., -0.0237,  0.0164,  0.0216],\n",
       "                      [-0.0102,  0.0148, -0.0557,  ..., -0.0118,  0.0031,  0.0253],\n",
       "                      ...,\n",
       "                      [-0.0095,  0.0118,  0.0019,  ..., -0.0077,  0.0075, -0.0063],\n",
       "                      [-0.0009,  0.0004,  0.0077,  ...,  0.0027, -0.0034,  0.0098],\n",
       "                      [ 0.0364,  0.0158,  0.0015,  ..., -0.0156, -0.0118,  0.0297]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.8.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0037, -0.0388,  0.0242,  ...,  0.0161, -0.0033, -0.0121],\n",
       "                      [-0.0286,  0.0094,  0.0167,  ...,  0.0013, -0.0149, -0.0188],\n",
       "                      [ 0.0065,  0.0127,  0.0121,  ..., -0.0065, -0.0093, -0.0410],\n",
       "                      ...,\n",
       "                      [-0.0104, -0.0052,  0.0086,  ..., -0.0117, -0.0426,  0.0142],\n",
       "                      [ 0.0054, -0.0153,  0.0044,  ...,  0.0104,  0.0144,  0.0122],\n",
       "                      [-0.0010,  0.0140,  0.0221,  ...,  0.0049,  0.0238, -0.0248]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.8.input_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.8.post_attention_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.9.self_attn.q_proj.weight',\n",
       "              tensor([[ 0.0105,  0.0001,  0.0270,  ...,  0.0178,  0.0134,  0.0308],\n",
       "                      [-0.0184, -0.0427, -0.0231,  ..., -0.0489, -0.0300, -0.0236],\n",
       "                      [ 0.0059,  0.0029,  0.0077,  ..., -0.0184, -0.0298, -0.0158],\n",
       "                      ...,\n",
       "                      [-0.0048, -0.0024, -0.0007,  ..., -0.0166,  0.0088, -0.0402],\n",
       "                      [ 0.0118, -0.0414, -0.0020,  ...,  0.0063,  0.0095,  0.0051],\n",
       "                      [-0.0163,  0.0374,  0.0039,  ..., -0.0070, -0.0036, -0.0079]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.9.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0026,  0.0168, -0.0164,  ...,  0.0106, -0.0022,  0.0416],\n",
       "                      [ 0.0208,  0.0144, -0.0187,  ...,  0.0037, -0.0011,  0.0228],\n",
       "                      [ 0.0226, -0.0151,  0.0328,  ..., -0.0101,  0.0154, -0.0329],\n",
       "                      ...,\n",
       "                      [ 0.0053,  0.0215, -0.0012,  ...,  0.0331,  0.0217,  0.0297],\n",
       "                      [ 0.0177, -0.0286,  0.0258,  ...,  0.0116, -0.0034, -0.0318],\n",
       "                      [ 0.0105,  0.0028, -0.0139,  ..., -0.0020,  0.0029, -0.0284]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.9.self_attn.v_proj.weight',\n",
       "              tensor([[ 0.0066,  0.0217, -0.0143,  ..., -0.0173,  0.0595,  0.0030],\n",
       "                      [-0.0035, -0.0038,  0.0129,  ...,  0.0021,  0.0057,  0.0027],\n",
       "                      [-0.0292, -0.0183,  0.0023,  ...,  0.0031, -0.0394,  0.0070],\n",
       "                      ...,\n",
       "                      [-0.0386,  0.0017,  0.0150,  ..., -0.0304, -0.0351,  0.0094],\n",
       "                      [ 0.0367, -0.0200,  0.0146,  ...,  0.0080, -0.0025, -0.0033],\n",
       "                      [ 0.0146,  0.0088, -0.0143,  ..., -0.0091, -0.0256, -0.0176]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.9.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0064,  0.0072, -0.0068,  ..., -0.0013, -0.0050, -0.0128],\n",
       "                      [-0.0127, -0.0320,  0.0042,  ..., -0.0364,  0.0282, -0.0193],\n",
       "                      [ 0.0118,  0.0329, -0.0036,  ...,  0.0036, -0.0242,  0.0060],\n",
       "                      ...,\n",
       "                      [ 0.0120, -0.0364, -0.0162,  ...,  0.0149,  0.0053, -0.0249],\n",
       "                      [ 0.0301,  0.0133,  0.0132,  ...,  0.0117, -0.0144,  0.0246],\n",
       "                      [-0.0020,  0.0056,  0.0154,  ...,  0.0464, -0.0114,  0.0003]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.9.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0127,  0.0142,  0.0073,  ..., -0.0050, -0.0179,  0.0040],\n",
       "                      [-0.0009, -0.0184, -0.0214,  ..., -0.0191, -0.0028,  0.0083],\n",
       "                      [-0.0253, -0.0273,  0.0096,  ...,  0.0251,  0.0646,  0.0147],\n",
       "                      ...,\n",
       "                      [ 0.0007, -0.0223,  0.0083,  ..., -0.0078,  0.0099,  0.0131],\n",
       "                      [-0.0232,  0.0096, -0.0092,  ..., -0.0146, -0.0279,  0.0245],\n",
       "                      [ 0.0166,  0.0083, -0.0213,  ...,  0.0388,  0.0049, -0.0440]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.9.mlp.up_proj.weight',\n",
       "              tensor([[-0.0252,  0.0123,  0.0015,  ...,  0.0018, -0.0188,  0.0111],\n",
       "                      [ 0.0052,  0.0171, -0.0190,  ..., -0.0041, -0.0262,  0.0133],\n",
       "                      [-0.0418,  0.0004,  0.0389,  ...,  0.0058, -0.0237,  0.0137],\n",
       "                      ...,\n",
       "                      [ 0.0082, -0.0326, -0.0240,  ...,  0.0007,  0.0107,  0.0185],\n",
       "                      [ 0.0090,  0.0073, -0.0150,  ..., -0.0032,  0.0155,  0.0172],\n",
       "                      [ 0.0205, -0.0215, -0.0078,  ...,  0.0058, -0.0137, -0.0045]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.9.mlp.down_proj.weight',\n",
       "              tensor([[-0.0013,  0.0063,  0.0212,  ...,  0.0021,  0.0011,  0.0188],\n",
       "                      [ 0.0065, -0.0174,  0.0139,  ..., -0.0083,  0.0141, -0.0310],\n",
       "                      [ 0.0006, -0.0435,  0.0018,  ...,  0.0129,  0.0014,  0.0277],\n",
       "                      ...,\n",
       "                      [-0.0185, -0.0074, -0.0437,  ..., -0.0197, -0.0120,  0.0022],\n",
       "                      [-0.0279, -0.0220,  0.0221,  ..., -0.0027, -0.0033,  0.0085],\n",
       "                      [ 0.0307,  0.0393,  0.0143,  ...,  0.0128,  0.0471,  0.0185]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.9.input_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.9.post_attention_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.10.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0037, -0.0142, -0.0126,  ...,  0.0062,  0.0193,  0.0032],\n",
       "                      [-0.0068,  0.0100,  0.0196,  ...,  0.0226, -0.0395, -0.0276],\n",
       "                      [ 0.0243, -0.0080, -0.0338,  ...,  0.0003,  0.0098, -0.0049],\n",
       "                      ...,\n",
       "                      [-0.0213,  0.0001, -0.0186,  ...,  0.0563, -0.0319, -0.0248],\n",
       "                      [ 0.0280,  0.0010,  0.0126,  ...,  0.0037, -0.0018,  0.0127],\n",
       "                      [-0.0100,  0.0234,  0.0003,  ...,  0.0027, -0.0374,  0.0043]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.10.self_attn.k_proj.weight',\n",
       "              tensor([[ 3.8204e-03,  2.0096e-02, -2.6131e-03,  ..., -1.1177e-02,\n",
       "                       -4.3213e-02,  1.0529e-02],\n",
       "                      [-2.4017e-02,  1.2611e-02,  4.9782e-03,  ...,  4.3335e-03,\n",
       "                       -3.3722e-02, -3.2883e-03],\n",
       "                      [-2.8253e-05,  3.3142e-02, -2.2339e-02,  ..., -2.7420e-02,\n",
       "                       -9.3689e-03, -1.8417e-02],\n",
       "                      ...,\n",
       "                      [-4.1412e-02,  8.0109e-04,  1.7288e-02,  ..., -2.8172e-03,\n",
       "                       -8.4534e-03,  5.8746e-03],\n",
       "                      [-7.6523e-03, -2.2125e-02, -1.7273e-02,  ...,  1.8387e-02,\n",
       "                       -5.9891e-03, -2.3132e-02],\n",
       "                      [ 2.9419e-02,  1.2527e-02,  2.4338e-02,  ..., -2.6367e-02,\n",
       "                        1.6785e-02,  2.6871e-02]], dtype=torch.float16)),\n",
       "             ('model.layers.10.self_attn.v_proj.weight',\n",
       "              tensor([[ 0.0171, -0.0210,  0.0021,  ..., -0.0233, -0.0301, -0.0434],\n",
       "                      [ 0.0180, -0.0088, -0.0135,  ..., -0.0105,  0.0121,  0.0098],\n",
       "                      [ 0.0049,  0.0137,  0.0215,  ...,  0.0020,  0.0026,  0.0205],\n",
       "                      ...,\n",
       "                      [-0.0043,  0.0205, -0.0002,  ...,  0.0128,  0.0067, -0.0133],\n",
       "                      [-0.0119, -0.0171, -0.0090,  ..., -0.0258, -0.0004, -0.0215],\n",
       "                      [ 0.0134,  0.0004,  0.0079,  ..., -0.0026, -0.0302, -0.0326]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.10.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0111, -0.0321, -0.0003,  ..., -0.0308,  0.0065,  0.0179],\n",
       "                      [ 0.0089, -0.0289, -0.0241,  ...,  0.0064,  0.0055,  0.0098],\n",
       "                      [ 0.0093,  0.0102, -0.0058,  ...,  0.0502,  0.0127,  0.0319],\n",
       "                      ...,\n",
       "                      [ 0.0253, -0.0126,  0.0120,  ..., -0.0402, -0.0226, -0.0162],\n",
       "                      [ 0.0041,  0.0389,  0.0066,  ...,  0.0374,  0.0104, -0.0081],\n",
       "                      [ 0.0009,  0.0108,  0.0257,  ..., -0.0274, -0.0021,  0.0030]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.10.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0172, -0.0087, -0.0288,  ..., -0.0116,  0.0298, -0.0182],\n",
       "                      [ 0.0134,  0.0151,  0.0194,  ...,  0.0192,  0.0012,  0.0095],\n",
       "                      [-0.0100, -0.0005,  0.0108,  ..., -0.0472,  0.0183,  0.0024],\n",
       "                      ...,\n",
       "                      [-0.0096,  0.0233,  0.0070,  ..., -0.0056, -0.0170, -0.0053],\n",
       "                      [-0.0116,  0.0121, -0.0237,  ..., -0.0039,  0.0294, -0.0143],\n",
       "                      [-0.0388, -0.0252, -0.0006,  ...,  0.0078, -0.0060, -0.0358]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.10.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0193, -0.0281, -0.0095,  ...,  0.0131, -0.0129, -0.0324],\n",
       "                      [ 0.0073,  0.0365, -0.0280,  ...,  0.0061,  0.0070, -0.0168],\n",
       "                      [-0.0166, -0.0122,  0.0205,  ..., -0.0292,  0.0062,  0.0067],\n",
       "                      ...,\n",
       "                      [-0.0205,  0.0327,  0.0005,  ...,  0.0158,  0.0132, -0.0186],\n",
       "                      [ 0.0183, -0.0159,  0.0176,  ..., -0.0025,  0.0032, -0.0032],\n",
       "                      [ 0.0268, -0.0255,  0.0028,  ..., -0.0161, -0.0194, -0.0065]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.10.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0157, -0.0215, -0.0107,  ...,  0.0368, -0.0227, -0.0112],\n",
       "                      [ 0.0424, -0.0316, -0.0219,  ..., -0.0156,  0.0339,  0.0485],\n",
       "                      [-0.0113,  0.0196,  0.0189,  ..., -0.0042,  0.0289, -0.0197],\n",
       "                      ...,\n",
       "                      [ 0.0033, -0.0146,  0.0073,  ...,  0.0096, -0.0260,  0.0159],\n",
       "                      [ 0.0091,  0.0278,  0.0172,  ..., -0.0131,  0.0388,  0.0122],\n",
       "                      [ 0.0336, -0.0147, -0.0322,  ..., -0.0089,  0.0105,  0.0221]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.10.input_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.10.post_attention_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.11.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0132, -0.0078, -0.0206,  ..., -0.0020,  0.0232,  0.0037],\n",
       "                      [-0.0319, -0.0094,  0.0026,  ..., -0.0257, -0.0031, -0.0199],\n",
       "                      [ 0.0113, -0.0316,  0.0185,  ...,  0.0150,  0.0109,  0.0179],\n",
       "                      ...,\n",
       "                      [ 0.0400,  0.0161, -0.0081,  ...,  0.0154, -0.0070, -0.0236],\n",
       "                      [-0.0068, -0.0181,  0.0100,  ..., -0.0211,  0.0233, -0.0014],\n",
       "                      [-0.0123,  0.0226, -0.0030,  ..., -0.0081, -0.0092, -0.0129]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.11.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0303,  0.0144, -0.0003,  ..., -0.0291, -0.0183, -0.0319],\n",
       "                      [-0.0376,  0.0350, -0.0135,  ..., -0.0073, -0.0061, -0.0071],\n",
       "                      [ 0.0160, -0.0179, -0.0108,  ..., -0.0191, -0.0188, -0.0111],\n",
       "                      ...,\n",
       "                      [-0.0053,  0.0122, -0.0075,  ..., -0.0108,  0.0258, -0.0087],\n",
       "                      [-0.0306, -0.0038, -0.0093,  ..., -0.0244, -0.0263, -0.0007],\n",
       "                      [ 0.0179, -0.0089,  0.0265,  ...,  0.0269,  0.0220,  0.0254]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.11.self_attn.v_proj.weight',\n",
       "              tensor([[-0.0257,  0.0022,  0.0104,  ...,  0.0087, -0.0094, -0.0063],\n",
       "                      [ 0.0281,  0.0075,  0.0143,  ..., -0.0166,  0.0110,  0.0089],\n",
       "                      [ 0.0233,  0.0145,  0.0493,  ..., -0.0181, -0.0495, -0.0005],\n",
       "                      ...,\n",
       "                      [-0.0021, -0.0455, -0.0026,  ..., -0.0009, -0.0178,  0.0293],\n",
       "                      [-0.0103, -0.0304,  0.0069,  ..., -0.0128,  0.0128,  0.0040],\n",
       "                      [-0.0083,  0.0268, -0.0298,  ..., -0.0017, -0.0153,  0.0244]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.11.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0084,  0.0238, -0.0147,  ...,  0.0061, -0.0087, -0.0052],\n",
       "                      [-0.0095,  0.0005, -0.0069,  ...,  0.0070,  0.0081, -0.0213],\n",
       "                      [ 0.0145,  0.0215, -0.0102,  ...,  0.0200,  0.0003, -0.0207],\n",
       "                      ...,\n",
       "                      [-0.0004,  0.0359, -0.0121,  ..., -0.0084, -0.0039, -0.0280],\n",
       "                      [-0.0201,  0.0194, -0.0095,  ...,  0.0051,  0.0317, -0.0084],\n",
       "                      [-0.0085,  0.0176, -0.0299,  ..., -0.0389,  0.0374,  0.0112]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.11.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0209, -0.0099,  0.0207,  ..., -0.0026, -0.0062,  0.0182],\n",
       "                      [-0.0340, -0.0446,  0.0082,  ..., -0.0399,  0.0145, -0.0151],\n",
       "                      [-0.0041, -0.0125,  0.0512,  ..., -0.0061, -0.0235, -0.0158],\n",
       "                      ...,\n",
       "                      [-0.0368, -0.0103,  0.0420,  ..., -0.0127, -0.0323,  0.0200],\n",
       "                      [-0.0008,  0.0325, -0.0033,  ..., -0.0020, -0.0136,  0.0166],\n",
       "                      [-0.0272,  0.0284, -0.0077,  ..., -0.0063,  0.0246, -0.0183]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.11.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0105, -0.0066,  0.0086,  ..., -0.0421,  0.0141,  0.0157],\n",
       "                      [ 0.0172,  0.0323, -0.0144,  ..., -0.0030,  0.0059,  0.0041],\n",
       "                      [-0.0123,  0.0122, -0.0112,  ..., -0.0126,  0.0330,  0.0208],\n",
       "                      ...,\n",
       "                      [ 0.0511,  0.0143,  0.0212,  ..., -0.0087,  0.0355, -0.0101],\n",
       "                      [-0.0055, -0.0241,  0.0232,  ..., -0.0209,  0.0177,  0.0040],\n",
       "                      [-0.0192, -0.0486, -0.0284,  ...,  0.0096,  0.0032, -0.0184]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.11.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0160,  0.0207,  0.0045,  ...,  0.0209,  0.0162, -0.0232],\n",
       "                      [-0.0171,  0.0064, -0.0105,  ...,  0.0061,  0.0355, -0.0067],\n",
       "                      [-0.0017, -0.0150,  0.0145,  ...,  0.0330, -0.0150, -0.0071],\n",
       "                      ...,\n",
       "                      [ 0.0268,  0.0071,  0.0142,  ...,  0.0278, -0.0121, -0.0135],\n",
       "                      [ 0.0150, -0.0255,  0.0172,  ..., -0.0149, -0.0104, -0.0202],\n",
       "                      [-0.0170, -0.0155, -0.0014,  ..., -0.0048,  0.0170,  0.0065]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.11.input_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.11.post_attention_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.12.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0226,  0.0017,  0.0304,  ...,  0.0089,  0.0291, -0.0052],\n",
       "                      [-0.0359, -0.0104, -0.0142,  ...,  0.0155, -0.0031,  0.0067],\n",
       "                      [ 0.0034, -0.0507,  0.0265,  ...,  0.0375, -0.0042,  0.0293],\n",
       "                      ...,\n",
       "                      [-0.0099, -0.0263, -0.0098,  ..., -0.0188, -0.0229, -0.0051],\n",
       "                      [ 0.0044,  0.0067, -0.0253,  ...,  0.0086,  0.0053, -0.0152],\n",
       "                      [-0.0205,  0.0112,  0.0202,  ...,  0.0155,  0.0254, -0.0162]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.12.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0073, -0.0169,  0.0121,  ...,  0.0156, -0.0332,  0.0170],\n",
       "                      [-0.0291, -0.0069,  0.0033,  ..., -0.0323,  0.0093,  0.0240],\n",
       "                      [ 0.0190, -0.0332,  0.0243,  ...,  0.0029,  0.0068, -0.0049],\n",
       "                      ...,\n",
       "                      [ 0.0345, -0.0027,  0.0042,  ...,  0.0242, -0.0201, -0.0014],\n",
       "                      [-0.0164, -0.0235, -0.0461,  ...,  0.0311,  0.0037, -0.0053],\n",
       "                      [-0.0163,  0.0151, -0.0086,  ..., -0.0403,  0.0185,  0.0005]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.12.self_attn.v_proj.weight',\n",
       "              tensor([[ 0.0101,  0.0018, -0.0381,  ...,  0.0017,  0.0163,  0.0169],\n",
       "                      [ 0.0089, -0.0434, -0.0070,  ..., -0.0288,  0.0040, -0.0253],\n",
       "                      [ 0.0093, -0.0133,  0.0026,  ..., -0.0265, -0.0078, -0.0155],\n",
       "                      ...,\n",
       "                      [-0.0109,  0.0113,  0.0138,  ...,  0.0123,  0.0179,  0.0190],\n",
       "                      [-0.0172,  0.0087, -0.0339,  ..., -0.0145, -0.0048,  0.0150],\n",
       "                      [-0.0107, -0.0247,  0.0147,  ...,  0.0093, -0.0201, -0.0218]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.12.self_attn.o_proj.weight',\n",
       "              tensor([[-0.0269,  0.0006,  0.0269,  ..., -0.0208, -0.0056, -0.0477],\n",
       "                      [-0.0159, -0.0265,  0.0053,  ..., -0.0024,  0.0536,  0.0243],\n",
       "                      [ 0.0210,  0.0272,  0.0273,  ..., -0.0138, -0.0098, -0.0250],\n",
       "                      ...,\n",
       "                      [-0.0166, -0.0148, -0.0461,  ..., -0.0178, -0.0144, -0.0293],\n",
       "                      [-0.0267,  0.0028, -0.0043,  ...,  0.0126, -0.0031, -0.0066],\n",
       "                      [-0.0217, -0.0106, -0.0244,  ..., -0.0496, -0.0177, -0.0138]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.12.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0310,  0.0019, -0.0122,  ..., -0.0194, -0.0062, -0.0147],\n",
       "                      [-0.0178, -0.0284,  0.0336,  ..., -0.0105,  0.0116, -0.0191],\n",
       "                      [ 0.0023,  0.0123,  0.0518,  ..., -0.0062, -0.0054, -0.0529],\n",
       "                      ...,\n",
       "                      [ 0.0244, -0.0103, -0.0314,  ..., -0.0071,  0.0320,  0.0210],\n",
       "                      [-0.0209,  0.0026,  0.0063,  ...,  0.0109, -0.0093, -0.0194],\n",
       "                      [-0.0048,  0.0451,  0.0152,  ...,  0.0007, -0.0057,  0.0222]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.12.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0729,  0.0152, -0.0304,  ..., -0.0219, -0.0233, -0.0210],\n",
       "                      [-0.0175, -0.0083, -0.0336,  ...,  0.0080,  0.0155,  0.0170],\n",
       "                      [ 0.0294,  0.0145, -0.0035,  ...,  0.0017,  0.0016, -0.0181],\n",
       "                      ...,\n",
       "                      [-0.0143, -0.0294,  0.0224,  ..., -0.0088,  0.0130, -0.0291],\n",
       "                      [ 0.0330,  0.0032, -0.0107,  ..., -0.0409,  0.0242,  0.0215],\n",
       "                      [-0.0133, -0.0154,  0.0174,  ..., -0.0136,  0.0041, -0.0017]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.12.mlp.down_proj.weight',\n",
       "              tensor([[-0.0205, -0.0099,  0.0115,  ...,  0.0071, -0.0190,  0.0016],\n",
       "                      [-0.0285,  0.0107, -0.0328,  ...,  0.0206, -0.0086,  0.0257],\n",
       "                      [-0.0246,  0.0153, -0.0111,  ..., -0.0119,  0.0166,  0.0308],\n",
       "                      ...,\n",
       "                      [-0.0280,  0.0008,  0.0690,  ..., -0.0037, -0.0431,  0.0180],\n",
       "                      [ 0.0007,  0.0355,  0.0400,  ..., -0.0106,  0.0146,  0.0193],\n",
       "                      [-0.0578, -0.0030, -0.0238,  ..., -0.0226,  0.0170,  0.0016]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.12.input_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.12.post_attention_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.13.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0015, -0.0033, -0.0155,  ..., -0.0230, -0.0189, -0.0125],\n",
       "                      [-0.0128,  0.0038, -0.0029,  ..., -0.0244,  0.0175,  0.0203],\n",
       "                      [ 0.0002,  0.0164,  0.0284,  ...,  0.0077,  0.0193, -0.0186],\n",
       "                      ...,\n",
       "                      [ 0.0367,  0.0168, -0.0212,  ..., -0.0008, -0.0019,  0.0054],\n",
       "                      [ 0.0269, -0.0126,  0.0235,  ..., -0.0271,  0.0492,  0.0100],\n",
       "                      [-0.0017, -0.0142, -0.0048,  ...,  0.0196,  0.0142,  0.0101]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.13.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0175,  0.0079, -0.0201,  ..., -0.0233,  0.0123,  0.0212],\n",
       "                      [ 0.0025, -0.0106, -0.0088,  ..., -0.0149,  0.0254, -0.0063],\n",
       "                      [-0.0119, -0.0125, -0.0268,  ..., -0.0313, -0.0036,  0.0262],\n",
       "                      ...,\n",
       "                      [ 0.0123,  0.0079, -0.0265,  ..., -0.0070,  0.0069,  0.0079],\n",
       "                      [-0.0065,  0.0164, -0.0208,  ..., -0.0135, -0.0444, -0.0296],\n",
       "                      [-0.0069,  0.0117,  0.0064,  ..., -0.0165,  0.0023,  0.0020]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.13.self_attn.v_proj.weight',\n",
       "              tensor([[ 0.0101, -0.0065,  0.0068,  ..., -0.0141,  0.0409, -0.0110],\n",
       "                      [ 0.0141, -0.0007,  0.0191,  ..., -0.0154,  0.0407, -0.0105],\n",
       "                      [-0.0080, -0.0007,  0.0062,  ..., -0.0052,  0.0054, -0.0265],\n",
       "                      ...,\n",
       "                      [ 0.0051, -0.0292,  0.0116,  ...,  0.0240,  0.0210,  0.0183],\n",
       "                      [ 0.0128,  0.0288,  0.0096,  ...,  0.0123, -0.0430, -0.0292],\n",
       "                      [ 0.0084,  0.0360, -0.0039,  ...,  0.0265, -0.0160, -0.0131]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.13.self_attn.o_proj.weight',\n",
       "              tensor([[ 2.8702e-02, -9.3746e-04, -2.8351e-02,  ...,  2.4536e-02,\n",
       "                       -5.9547e-03,  4.2267e-03],\n",
       "                      [ 9.7961e-03,  9.2268e-05,  9.5825e-03,  ...,  2.9678e-02,\n",
       "                       -3.9005e-03, -6.0043e-03],\n",
       "                      [ 8.6823e-03,  1.3916e-02,  2.0966e-02,  ..., -1.6190e-02,\n",
       "                        7.7152e-04, -3.2928e-02],\n",
       "                      ...,\n",
       "                      [ 1.2283e-02, -3.0804e-04,  3.0155e-03,  ...,  1.1009e-02,\n",
       "                       -3.1342e-02,  3.3092e-03],\n",
       "                      [-2.6077e-02,  1.6373e-02,  2.6428e-02,  ...,  4.7874e-03,\n",
       "                        1.2299e-02, -4.0174e-04],\n",
       "                      [ 2.3666e-02, -3.1006e-02, -9.6741e-03,  ..., -3.1799e-02,\n",
       "                        8.8310e-04,  2.7603e-02]], dtype=torch.float16)),\n",
       "             ('model.layers.13.mlp.gate_proj.weight',\n",
       "              tensor([[ 2.9602e-02,  4.3335e-03,  1.6464e-02,  ..., -5.2643e-02,\n",
       "                        5.9814e-03,  2.4452e-03],\n",
       "                      [ 1.1703e-02,  4.0405e-02, -2.1378e-02,  ..., -1.1436e-02,\n",
       "                       -3.1372e-02, -4.4632e-03],\n",
       "                      [-9.5596e-03, -1.2451e-02,  2.5665e-02,  ...,  3.1052e-02,\n",
       "                        3.7432e-05,  6.9313e-03],\n",
       "                      ...,\n",
       "                      [ 2.0355e-02, -1.5579e-02,  2.6566e-02,  ...,  1.7731e-02,\n",
       "                       -2.6199e-02, -4.9019e-03],\n",
       "                      [ 5.1056e-02,  1.5839e-02, -5.2605e-03,  ..., -9.6893e-03,\n",
       "                       -1.2375e-02, -9.4147e-03],\n",
       "                      [-1.4221e-02, -2.0771e-03,  7.4692e-03,  ..., -4.0253e-02,\n",
       "                       -1.5383e-03,  1.9104e-02]], dtype=torch.float16)),\n",
       "             ('model.layers.13.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0124, -0.0201,  0.0169,  ...,  0.0137, -0.0255, -0.0132],\n",
       "                      [-0.0414,  0.0074,  0.0580,  ..., -0.0083,  0.0139,  0.0164],\n",
       "                      [-0.0097,  0.0054, -0.0226,  ...,  0.0338,  0.0081,  0.0349],\n",
       "                      ...,\n",
       "                      [-0.0299, -0.0378, -0.0251,  ...,  0.0216,  0.0419,  0.0090],\n",
       "                      [ 0.0477,  0.0210,  0.0201,  ...,  0.0097, -0.0247,  0.0183],\n",
       "                      [ 0.0166, -0.0400,  0.0139,  ...,  0.0153,  0.0070, -0.0282]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.13.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0205,  0.0334, -0.0112,  ..., -0.0266, -0.0115, -0.0072],\n",
       "                      [-0.0167, -0.0205, -0.0255,  ...,  0.0022,  0.0085, -0.0048],\n",
       "                      [-0.0267,  0.0004, -0.0090,  ...,  0.0272,  0.0295,  0.0217],\n",
       "                      ...,\n",
       "                      [ 0.0424,  0.0210,  0.0078,  ..., -0.0062,  0.0029, -0.0047],\n",
       "                      [ 0.0144, -0.0294,  0.0067,  ...,  0.0002, -0.0116,  0.0312],\n",
       "                      [-0.0078,  0.0024, -0.0238,  ...,  0.0144,  0.0164, -0.0199]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.13.input_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.13.post_attention_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.14.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0070, -0.0097,  0.0037,  ..., -0.0253, -0.0356,  0.0142],\n",
       "                      [-0.0250, -0.0017,  0.0040,  ..., -0.0185, -0.0117, -0.0344],\n",
       "                      [ 0.0008, -0.0064,  0.0291,  ...,  0.0063,  0.0176, -0.0354],\n",
       "                      ...,\n",
       "                      [ 0.0120,  0.0341,  0.0143,  ..., -0.0159, -0.0007,  0.0287],\n",
       "                      [-0.0259,  0.0159,  0.0010,  ..., -0.0179,  0.0025,  0.0144],\n",
       "                      [-0.0065, -0.0181, -0.0080,  ...,  0.0067, -0.0063,  0.0012]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.14.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0132,  0.0030, -0.0351,  ...,  0.0034,  0.0044,  0.0071],\n",
       "                      [ 0.0363,  0.0287, -0.0118,  ..., -0.0224,  0.0177, -0.0016],\n",
       "                      [ 0.0076, -0.0342,  0.0186,  ..., -0.0111, -0.0181,  0.0240],\n",
       "                      ...,\n",
       "                      [-0.0074, -0.0099, -0.0143,  ..., -0.0274, -0.0122, -0.0002],\n",
       "                      [-0.0078,  0.0145,  0.0196,  ...,  0.0211,  0.0182,  0.0173],\n",
       "                      [-0.0070, -0.0204, -0.0153,  ..., -0.0339, -0.0306,  0.0234]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.14.self_attn.v_proj.weight',\n",
       "              tensor([[-0.0074, -0.0089,  0.0152,  ...,  0.0007, -0.0003, -0.0113],\n",
       "                      [-0.0008,  0.0094,  0.0263,  ..., -0.0093,  0.0312,  0.0030],\n",
       "                      [-0.0091,  0.0306, -0.0330,  ...,  0.0112,  0.0223, -0.0018],\n",
       "                      ...,\n",
       "                      [-0.0073, -0.0036, -0.0414,  ..., -0.0142,  0.0137,  0.0181],\n",
       "                      [-0.0102, -0.0222, -0.0008,  ...,  0.0132, -0.0158, -0.0242],\n",
       "                      [ 0.0429,  0.0290, -0.0235,  ...,  0.0309,  0.0048, -0.0002]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.14.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0128, -0.0350, -0.0063,  ...,  0.0412, -0.0292, -0.0198],\n",
       "                      [ 0.0078,  0.0174, -0.0010,  ..., -0.0038, -0.0086, -0.0262],\n",
       "                      [ 0.0212,  0.0172,  0.0211,  ..., -0.0176,  0.0221,  0.0092],\n",
       "                      ...,\n",
       "                      [-0.0045, -0.0198,  0.0168,  ..., -0.0056, -0.0180, -0.0107],\n",
       "                      [ 0.0150, -0.0117, -0.0284,  ..., -0.0211, -0.0131, -0.0264],\n",
       "                      [-0.0048, -0.0275, -0.0007,  ...,  0.0129, -0.0089, -0.0036]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.14.mlp.gate_proj.weight',\n",
       "              tensor([[-5.6229e-03, -9.7198e-03,  1.7960e-02,  ..., -1.2444e-02,\n",
       "                        2.1687e-03, -2.9846e-02],\n",
       "                      [-2.3331e-02, -2.8748e-02,  6.3629e-03,  ..., -1.7691e-03,\n",
       "                       -1.0231e-02,  2.2202e-02],\n",
       "                      [-1.1505e-02, -1.6052e-02,  3.9764e-02,  ..., -1.1406e-02,\n",
       "                       -1.1749e-02,  1.4244e-02],\n",
       "                      ...,\n",
       "                      [-1.2505e-02,  5.9891e-03, -2.2461e-02,  ...,  2.1484e-02,\n",
       "                        6.5041e-03,  1.4587e-02],\n",
       "                      [-4.5090e-03, -1.0941e-02, -1.8415e-03,  ...,  3.4698e-02,\n",
       "                       -1.1627e-02, -7.6830e-05],\n",
       "                      [ 3.1921e-02, -2.9449e-02,  1.8814e-02,  ..., -1.8473e-03,\n",
       "                       -4.8180e-03, -3.3142e-02]], dtype=torch.float16)),\n",
       "             ('model.layers.14.mlp.up_proj.weight',\n",
       "              tensor([[-0.0125, -0.0190, -0.0010,  ...,  0.0176,  0.0101,  0.0221],\n",
       "                      [ 0.0072,  0.0242, -0.0404,  ..., -0.0105, -0.0015,  0.0276],\n",
       "                      [ 0.0185,  0.0308,  0.0229,  ..., -0.0261, -0.0121,  0.0142],\n",
       "                      ...,\n",
       "                      [-0.0113, -0.0435, -0.0565,  ...,  0.0244,  0.0039, -0.0274],\n",
       "                      [ 0.0496,  0.0079, -0.0104,  ..., -0.0041, -0.0017,  0.0137],\n",
       "                      [ 0.0093, -0.0400, -0.0055,  ...,  0.0195, -0.0166,  0.0023]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.14.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0052,  0.0074,  0.0121,  ...,  0.0065, -0.0264, -0.0083],\n",
       "                      [ 0.0283, -0.0120, -0.0077,  ...,  0.0109,  0.0160, -0.0137],\n",
       "                      [ 0.0183, -0.0023,  0.0526,  ...,  0.0077, -0.0146, -0.0389],\n",
       "                      ...,\n",
       "                      [ 0.0247,  0.0192,  0.0128,  ...,  0.0274, -0.0053,  0.0047],\n",
       "                      [ 0.0235, -0.0096, -0.0194,  ..., -0.0134,  0.0371, -0.0199],\n",
       "                      [-0.0131,  0.0223,  0.0283,  ..., -0.0169,  0.0004,  0.0019]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.14.input_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.14.post_attention_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.15.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0046,  0.0390,  0.0245,  ...,  0.0061, -0.0390, -0.0128],\n",
       "                      [-0.0292, -0.0221,  0.0099,  ...,  0.0060, -0.0059,  0.0222],\n",
       "                      [-0.0106,  0.0092, -0.0131,  ..., -0.0168,  0.0285, -0.0226],\n",
       "                      ...,\n",
       "                      [-0.0173, -0.0043, -0.0113,  ...,  0.0414,  0.0228,  0.0175],\n",
       "                      [ 0.0047,  0.0149,  0.0047,  ...,  0.0065,  0.0134,  0.0109],\n",
       "                      [-0.0108, -0.0213,  0.0177,  ..., -0.0323, -0.0312, -0.0019]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.15.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0044, -0.0027,  0.0211,  ..., -0.0303, -0.0075, -0.0010],\n",
       "                      [-0.0088,  0.0138, -0.0130,  ...,  0.0373, -0.0232,  0.0129],\n",
       "                      [-0.0095, -0.0086, -0.0368,  ..., -0.0089,  0.0038, -0.0058],\n",
       "                      ...,\n",
       "                      [ 0.0137, -0.0124,  0.0056,  ...,  0.0304, -0.0240,  0.0043],\n",
       "                      [-0.0036,  0.0155, -0.0315,  ...,  0.0125, -0.0005, -0.0201],\n",
       "                      [ 0.0194, -0.0043,  0.0093,  ...,  0.0223, -0.0508, -0.0214]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.15.self_attn.v_proj.weight',\n",
       "              tensor([[ 0.0315, -0.0129,  0.0002,  ..., -0.0057,  0.0100, -0.0082],\n",
       "                      [ 0.0229,  0.0159, -0.0030,  ..., -0.0183, -0.0167, -0.0179],\n",
       "                      [-0.0310, -0.0041,  0.0098,  ..., -0.0155,  0.0178, -0.0066],\n",
       "                      ...,\n",
       "                      [ 0.0095, -0.0212, -0.0102,  ...,  0.0017, -0.0172, -0.0046],\n",
       "                      [-0.0056,  0.0379, -0.0282,  ...,  0.0198,  0.0036,  0.0166],\n",
       "                      [ 0.0035, -0.0080,  0.0252,  ...,  0.0155, -0.0002,  0.0019]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.15.self_attn.o_proj.weight',\n",
       "              tensor([[ 8.5983e-03, -7.2441e-03, -2.8839e-02,  ..., -2.2766e-02,\n",
       "                       -1.1559e-02, -2.4567e-02],\n",
       "                      [-1.8356e-02, -8.0643e-03,  9.0256e-03,  ...,  3.5828e-02,\n",
       "                        1.7471e-02, -1.6464e-02],\n",
       "                      [ 1.5297e-02,  1.2848e-02,  1.5602e-02,  ..., -1.8021e-02,\n",
       "                        8.2474e-03,  5.3048e-05],\n",
       "                      ...,\n",
       "                      [ 1.5717e-02,  1.8509e-02, -1.2039e-02,  ...,  4.5624e-03,\n",
       "                       -9.6817e-03, -6.2714e-03],\n",
       "                      [ 3.6011e-02,  3.1281e-02,  8.5297e-03,  ...,  2.5635e-02,\n",
       "                        2.6428e-02,  1.4374e-02],\n",
       "                      [-1.6602e-02,  1.5068e-03,  2.3346e-03,  ..., -9.2850e-03,\n",
       "                        2.8305e-02,  5.7678e-03]], dtype=torch.float16)),\n",
       "             ('model.layers.15.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0107, -0.0083, -0.0144,  ...,  0.0033,  0.0021, -0.0052],\n",
       "                      [-0.0169, -0.0045, -0.0200,  ...,  0.0004,  0.0278,  0.0263],\n",
       "                      [ 0.0232,  0.0111,  0.0215,  ..., -0.0155, -0.0085,  0.0185],\n",
       "                      ...,\n",
       "                      [-0.0015, -0.0215, -0.0109,  ...,  0.0150, -0.0063,  0.0353],\n",
       "                      [ 0.0035, -0.0090,  0.0276,  ..., -0.0107, -0.0194, -0.0223],\n",
       "                      [ 0.0255,  0.0033,  0.0126,  ..., -0.0120, -0.0059,  0.0078]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.15.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0346,  0.0066,  0.0004,  ..., -0.0007,  0.0077, -0.0223],\n",
       "                      [ 0.0094,  0.0119, -0.0104,  ..., -0.0106, -0.0224,  0.0034],\n",
       "                      [-0.0068,  0.0056,  0.0002,  ..., -0.0082, -0.0349,  0.0001],\n",
       "                      ...,\n",
       "                      [ 0.0086, -0.0163,  0.0022,  ...,  0.0114,  0.0186, -0.0109],\n",
       "                      [ 0.0317, -0.0289, -0.0017,  ..., -0.0183, -0.0068,  0.0259],\n",
       "                      [-0.0292, -0.0367,  0.0253,  ..., -0.0105, -0.0076,  0.0010]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.15.mlp.down_proj.weight',\n",
       "              tensor([[-0.0010, -0.0148, -0.0264,  ...,  0.0206,  0.0125, -0.0157],\n",
       "                      [-0.0153, -0.0302, -0.0218,  ...,  0.0205,  0.0040, -0.0213],\n",
       "                      [ 0.0076, -0.0035,  0.0261,  ..., -0.0225,  0.0225,  0.0006],\n",
       "                      ...,\n",
       "                      [-0.0092, -0.0085, -0.0004,  ...,  0.0105,  0.0227,  0.0160],\n",
       "                      [-0.0009,  0.0255,  0.0022,  ..., -0.0163, -0.0079, -0.0253],\n",
       "                      [ 0.0253,  0.0105,  0.0077,  ...,  0.0023, -0.0161,  0.0046]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.15.input_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.15.post_attention_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.16.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0027,  0.0032,  0.0251,  ..., -0.0173, -0.0023, -0.0053],\n",
       "                      [-0.0435, -0.0141,  0.0237,  ..., -0.0106,  0.0026, -0.0088],\n",
       "                      [ 0.0265,  0.0144, -0.0087,  ..., -0.0013, -0.0167, -0.0108],\n",
       "                      ...,\n",
       "                      [ 0.0136,  0.0475, -0.0222,  ...,  0.0015,  0.0244,  0.0423],\n",
       "                      [ 0.0235, -0.0014, -0.0220,  ...,  0.0341, -0.0036, -0.0268],\n",
       "                      [-0.0090,  0.0181, -0.0013,  ...,  0.0062, -0.0207, -0.0110]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.16.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0014, -0.0040, -0.0122,  ..., -0.0119,  0.0206,  0.0165],\n",
       "                      [ 0.0022,  0.0039, -0.0115,  ..., -0.0260,  0.0185, -0.0245],\n",
       "                      [ 0.0110, -0.0216,  0.0076,  ...,  0.0041,  0.0080, -0.0064],\n",
       "                      ...,\n",
       "                      [ 0.0065,  0.0017,  0.0224,  ..., -0.0015,  0.0152, -0.0062],\n",
       "                      [ 0.0116,  0.0244,  0.0352,  ..., -0.0002,  0.0364,  0.0034],\n",
       "                      [ 0.0148, -0.0278,  0.0005,  ..., -0.0025,  0.0166,  0.0316]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.16.self_attn.v_proj.weight',\n",
       "              tensor([[ 0.0326,  0.0114,  0.0139,  ...,  0.0411,  0.0215,  0.0110],\n",
       "                      [-0.0113, -0.0023, -0.0200,  ...,  0.0098, -0.0058,  0.0173],\n",
       "                      [ 0.0223, -0.0219,  0.0127,  ...,  0.0187,  0.0016,  0.0180],\n",
       "                      ...,\n",
       "                      [ 0.0363,  0.0077, -0.0021,  ..., -0.0055, -0.0181, -0.0116],\n",
       "                      [-0.0006,  0.0068, -0.0049,  ...,  0.0184,  0.0247,  0.0117],\n",
       "                      [-0.0270, -0.0305, -0.0085,  ...,  0.0713,  0.0219,  0.0229]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.16.self_attn.o_proj.weight',\n",
       "              tensor([[-0.0083, -0.0034,  0.0083,  ...,  0.0019,  0.0182,  0.0348],\n",
       "                      [ 0.0201,  0.0276,  0.0077,  ..., -0.0099,  0.0043,  0.0031],\n",
       "                      [ 0.0048, -0.0174,  0.0003,  ...,  0.0280, -0.0090, -0.0052],\n",
       "                      ...,\n",
       "                      [-0.0220,  0.0374,  0.0003,  ..., -0.0104, -0.0270, -0.0059],\n",
       "                      [-0.0225,  0.0033, -0.0017,  ..., -0.0296,  0.0162, -0.0125],\n",
       "                      [ 0.0483,  0.0171, -0.0128,  ...,  0.0091,  0.0123,  0.0127]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.16.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0257, -0.0236,  0.0041,  ...,  0.0180, -0.0023,  0.0172],\n",
       "                      [-0.0226, -0.0091,  0.0081,  ..., -0.0165, -0.0182, -0.0094],\n",
       "                      [-0.0233, -0.0209, -0.0242,  ...,  0.0191,  0.0189,  0.0088],\n",
       "                      ...,\n",
       "                      [ 0.0020, -0.0315, -0.0264,  ..., -0.0085,  0.0106, -0.0281],\n",
       "                      [ 0.0192, -0.0107,  0.0270,  ..., -0.0130, -0.0087,  0.0268],\n",
       "                      [-0.0307,  0.0232,  0.0140,  ...,  0.0196,  0.0210,  0.0151]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.16.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0011,  0.0625,  0.0502,  ...,  0.0186, -0.0025,  0.0083],\n",
       "                      [ 0.0005, -0.0285, -0.0077,  ...,  0.0383, -0.0141,  0.0231],\n",
       "                      [ 0.0356,  0.0134,  0.0041,  ..., -0.0046,  0.0244,  0.0081],\n",
       "                      ...,\n",
       "                      [-0.0304, -0.0347,  0.0137,  ...,  0.0079, -0.0210,  0.0307],\n",
       "                      [ 0.0099, -0.0215, -0.0127,  ..., -0.0016,  0.0444, -0.0164],\n",
       "                      [ 0.0097,  0.0128,  0.0032,  ...,  0.0063, -0.0370, -0.0140]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.16.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0030, -0.0082,  0.0322,  ...,  0.0060,  0.0200,  0.0196],\n",
       "                      [-0.0200,  0.0161, -0.0106,  ...,  0.0030, -0.0235, -0.0292],\n",
       "                      [ 0.0232,  0.0248,  0.0258,  ...,  0.0057, -0.0168, -0.0298],\n",
       "                      ...,\n",
       "                      [ 0.0452,  0.0002, -0.0061,  ...,  0.0064, -0.0023, -0.0162],\n",
       "                      [-0.0027, -0.0034, -0.0127,  ..., -0.0248, -0.0012, -0.0051],\n",
       "                      [-0.0212, -0.0099,  0.0090,  ..., -0.0223, -0.0133, -0.0113]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.16.input_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.16.post_attention_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.17.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0065, -0.0220,  0.0065,  ..., -0.0334,  0.0558,  0.0344],\n",
       "                      [-0.0328,  0.0320, -0.0299,  ..., -0.0051,  0.0191, -0.0006],\n",
       "                      [-0.0036,  0.0082, -0.0334,  ..., -0.0026,  0.0142,  0.0038],\n",
       "                      ...,\n",
       "                      [-0.0054, -0.0164, -0.0219,  ...,  0.0150, -0.0052, -0.0028],\n",
       "                      [ 0.0163, -0.0190,  0.0083,  ..., -0.0066,  0.0230, -0.0172],\n",
       "                      [ 0.0144,  0.0003, -0.0090,  ...,  0.0237, -0.0066, -0.0163]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.17.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0034,  0.0324, -0.0120,  ...,  0.0291,  0.0046,  0.0097],\n",
       "                      [ 0.0286,  0.0171,  0.0284,  ..., -0.0034,  0.0078,  0.0034],\n",
       "                      [ 0.0339,  0.0039, -0.0005,  ...,  0.0213, -0.0208,  0.0194],\n",
       "                      ...,\n",
       "                      [ 0.0028,  0.0225,  0.0228,  ...,  0.0169,  0.0259,  0.0121],\n",
       "                      [ 0.0110, -0.0053,  0.0260,  ...,  0.0114,  0.0136,  0.0313],\n",
       "                      [-0.0096,  0.0236,  0.0121,  ..., -0.0154, -0.0170, -0.0033]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.17.self_attn.v_proj.weight',\n",
       "              tensor([[ 0.0121, -0.0387, -0.0122,  ..., -0.0003, -0.0177, -0.0211],\n",
       "                      [-0.0087,  0.0101,  0.0154,  ...,  0.0085,  0.0208,  0.0287],\n",
       "                      [ 0.0060,  0.0080, -0.0138,  ...,  0.0365,  0.0102, -0.0050],\n",
       "                      ...,\n",
       "                      [ 0.0049,  0.0146,  0.0205,  ..., -0.0042,  0.0280,  0.0162],\n",
       "                      [ 0.0066,  0.0236,  0.0169,  ..., -0.0186,  0.0091,  0.0435],\n",
       "                      [-0.0358, -0.0056, -0.0267,  ..., -0.0024, -0.0151,  0.0021]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.17.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0076, -0.0008,  0.0117,  ..., -0.0035,  0.0076, -0.0299],\n",
       "                      [ 0.0117, -0.0084,  0.0356,  ..., -0.0357,  0.0088,  0.0048],\n",
       "                      [-0.0276,  0.0130, -0.0146,  ...,  0.0126,  0.0172,  0.0086],\n",
       "                      ...,\n",
       "                      [-0.0102,  0.0014, -0.0036,  ...,  0.0075,  0.0179,  0.0487],\n",
       "                      [ 0.0226,  0.0055, -0.0057,  ...,  0.0173, -0.0025, -0.0175],\n",
       "                      [-0.0276, -0.0316,  0.0095,  ...,  0.0071,  0.0332, -0.0040]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.17.mlp.gate_proj.weight',\n",
       "              tensor([[ 1.4870e-02,  7.3929e-03,  6.6147e-03,  ..., -1.7517e-02,\n",
       "                        1.6968e-02, -1.8494e-02],\n",
       "                      [ 3.3844e-02, -1.3496e-02,  3.8940e-02,  ..., -5.8784e-03,\n",
       "                       -1.1688e-02, -5.8624e-02],\n",
       "                      [ 1.1940e-02,  8.2855e-03, -2.0370e-02,  ...,  6.4659e-03,\n",
       "                        3.1036e-02,  4.5738e-03],\n",
       "                      ...,\n",
       "                      [ 4.3259e-03,  2.7176e-02,  2.0630e-02,  ...,  8.6212e-03,\n",
       "                        5.7449e-03,  1.8921e-02],\n",
       "                      [-6.7024e-03, -2.8687e-03, -3.2776e-02,  ..., -6.7055e-05,\n",
       "                       -5.8746e-03,  7.9880e-03],\n",
       "                      [ 2.1805e-02, -2.5238e-02, -7.7820e-03,  ..., -4.9561e-02,\n",
       "                        2.1606e-02,  2.4338e-02]], dtype=torch.float16)),\n",
       "             ('model.layers.17.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0019, -0.0128, -0.0098,  ...,  0.0008, -0.0150,  0.0216],\n",
       "                      [-0.0115, -0.0254, -0.0373,  ...,  0.0066, -0.0072,  0.0555],\n",
       "                      [ 0.0215,  0.0092, -0.0062,  ..., -0.0077,  0.0167,  0.0018],\n",
       "                      ...,\n",
       "                      [ 0.0312,  0.0141, -0.0190,  ..., -0.0070,  0.0057,  0.0254],\n",
       "                      [-0.0031, -0.0118, -0.0238,  ..., -0.0023, -0.0125, -0.0029],\n",
       "                      [-0.0100, -0.0005,  0.0410,  ..., -0.0315,  0.0299, -0.0205]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.17.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0220, -0.0068,  0.0077,  ...,  0.0009,  0.0142,  0.0035],\n",
       "                      [-0.0203, -0.0019,  0.0401,  ...,  0.0118,  0.0131, -0.0287],\n",
       "                      [-0.0183,  0.0075,  0.0153,  ...,  0.0043, -0.0195, -0.0061],\n",
       "                      ...,\n",
       "                      [ 0.0234, -0.0098,  0.0027,  ..., -0.0399,  0.0223, -0.0499],\n",
       "                      [-0.0075, -0.0172, -0.0418,  ..., -0.0121, -0.0102,  0.0015],\n",
       "                      [-0.0112,  0.0339,  0.0076,  ...,  0.0008,  0.0082, -0.0324]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.17.input_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.17.post_attention_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.18.self_attn.q_proj.weight',\n",
       "              tensor([[ 0.0228,  0.0019,  0.0078,  ...,  0.0035,  0.0159,  0.0013],\n",
       "                      [ 0.0352, -0.0547, -0.0318,  ..., -0.0079,  0.0038,  0.0173],\n",
       "                      [ 0.0258, -0.0027, -0.0088,  ...,  0.0008, -0.0049, -0.0396],\n",
       "                      ...,\n",
       "                      [-0.0037,  0.0013, -0.0334,  ..., -0.0371, -0.0409,  0.0043],\n",
       "                      [-0.0094,  0.0056,  0.0002,  ..., -0.0208,  0.0184, -0.0250],\n",
       "                      [-0.0596, -0.0102,  0.0294,  ..., -0.0297,  0.0023,  0.0139]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.18.self_attn.k_proj.weight',\n",
       "              tensor([[ 1.6146e-03, -3.4828e-03, -3.9368e-02,  ..., -3.6201e-03,\n",
       "                        8.3542e-03,  2.5482e-02],\n",
       "                      [ 1.6693e-02,  1.4923e-02, -2.0584e-02,  ...,  5.7602e-03,\n",
       "                        1.1353e-02,  4.9591e-02],\n",
       "                      [ 3.4690e-05,  1.0574e-02,  1.2802e-02,  ..., -5.1384e-03,\n",
       "                        3.3569e-02,  2.8000e-02],\n",
       "                      ...,\n",
       "                      [-8.7662e-03,  1.7303e-02, -1.1078e-02,  ...,  5.3635e-03,\n",
       "                       -3.6957e-02,  8.2703e-03],\n",
       "                      [-3.1525e-02,  1.0269e-02,  5.3673e-03,  ..., -1.6388e-02,\n",
       "                        2.6764e-02, -4.0741e-02],\n",
       "                      [ 1.5602e-02, -5.7297e-03,  2.7496e-02,  ..., -6.1417e-03,\n",
       "                        2.2598e-02, -1.9119e-02]], dtype=torch.float16)),\n",
       "             ('model.layers.18.self_attn.v_proj.weight',\n",
       "              tensor([[ 0.0057, -0.0265, -0.0258,  ..., -0.0184,  0.0181,  0.0101],\n",
       "                      [ 0.0115, -0.0186,  0.0285,  ...,  0.0067,  0.0169, -0.0122],\n",
       "                      [ 0.0009, -0.0151, -0.0269,  ...,  0.0174,  0.0299, -0.0349],\n",
       "                      ...,\n",
       "                      [ 0.0225, -0.0058, -0.0248,  ..., -0.0264,  0.0190,  0.0329],\n",
       "                      [-0.0199,  0.0302, -0.0006,  ...,  0.0177,  0.0243, -0.0153],\n",
       "                      [ 0.0352,  0.0063, -0.0175,  ..., -0.0051,  0.0076,  0.0103]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.18.self_attn.o_proj.weight',\n",
       "              tensor([[ 1.2169e-02, -2.7390e-02,  1.6336e-03,  ..., -3.9902e-03,\n",
       "                        4.6921e-03,  6.9809e-03],\n",
       "                      [-4.7505e-05,  2.6321e-02,  1.1795e-02,  ...,  2.4567e-02,\n",
       "                       -4.1992e-02, -1.5266e-02],\n",
       "                      [ 2.4246e-02,  8.0566e-03,  1.7047e-05,  ...,  2.3224e-02,\n",
       "                       -3.0060e-02, -7.4577e-03],\n",
       "                      ...,\n",
       "                      [ 2.3346e-02,  6.6414e-03, -1.5854e-02,  ..., -5.7220e-04,\n",
       "                        5.6038e-03,  2.9495e-02],\n",
       "                      [ 3.2318e-02,  9.4528e-03, -2.8122e-02,  ..., -1.3374e-02,\n",
       "                       -1.3466e-02, -1.3161e-02],\n",
       "                      [-1.6129e-02, -4.2801e-03,  2.0733e-03,  ...,  2.6345e-05,\n",
       "                        1.1742e-02,  5.3131e-02]], dtype=torch.float16)),\n",
       "             ('model.layers.18.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0150, -0.0163, -0.0233,  ..., -0.0015,  0.0213, -0.0003],\n",
       "                      [ 0.0066, -0.0107,  0.0174,  ..., -0.0155, -0.0094,  0.0043],\n",
       "                      [ 0.0172,  0.0056, -0.0149,  ..., -0.0152,  0.0008,  0.0230],\n",
       "                      ...,\n",
       "                      [ 0.0079,  0.0242,  0.0051,  ...,  0.0048, -0.0255, -0.0102],\n",
       "                      [-0.0008, -0.0211,  0.0084,  ...,  0.0289,  0.0240, -0.0173],\n",
       "                      [ 0.0238,  0.0011,  0.0122,  ...,  0.0064, -0.0116,  0.0112]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.18.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0417,  0.0178,  0.0269,  ...,  0.0178, -0.0186,  0.0109],\n",
       "                      [ 0.0141, -0.0005, -0.0191,  ...,  0.0070,  0.0397,  0.0289],\n",
       "                      [-0.0353, -0.0137,  0.0065,  ..., -0.0190, -0.0302, -0.0020],\n",
       "                      ...,\n",
       "                      [ 0.0097, -0.0436, -0.0062,  ...,  0.0298, -0.0180,  0.0203],\n",
       "                      [ 0.0070, -0.0251, -0.0072,  ...,  0.0202,  0.0220,  0.0210],\n",
       "                      [-0.0373,  0.0021, -0.0240,  ...,  0.0312, -0.0197,  0.0230]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.18.mlp.down_proj.weight',\n",
       "              tensor([[-0.0398,  0.0482,  0.0015,  ..., -0.0037, -0.0004, -0.0427],\n",
       "                      [ 0.0195,  0.0009,  0.0193,  ...,  0.0223, -0.0101,  0.0201],\n",
       "                      [ 0.0188,  0.0084,  0.0181,  ..., -0.0374, -0.0263, -0.0121],\n",
       "                      ...,\n",
       "                      [-0.0146,  0.0096, -0.0342,  ...,  0.0294, -0.0218, -0.0205],\n",
       "                      [-0.0098, -0.0010, -0.0212,  ...,  0.0254, -0.0092, -0.0391],\n",
       "                      [ 0.0243,  0.0244,  0.0080,  ..., -0.0279, -0.0112,  0.0003]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.18.input_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.18.post_attention_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.19.self_attn.q_proj.weight',\n",
       "              tensor([[ 0.0199, -0.0483, -0.0270,  ...,  0.0103,  0.0307, -0.0264],\n",
       "                      [ 0.0067,  0.0108,  0.0429,  ...,  0.0205,  0.0063, -0.0036],\n",
       "                      [-0.0104, -0.0154,  0.0422,  ...,  0.0231,  0.0122, -0.0314],\n",
       "                      ...,\n",
       "                      [-0.0140, -0.0311, -0.0058,  ..., -0.0085,  0.0137,  0.0096],\n",
       "                      [ 0.0296, -0.0132, -0.0183,  ...,  0.0272,  0.0025, -0.0047],\n",
       "                      [-0.0083,  0.0017,  0.0116,  ...,  0.0099, -0.0078, -0.0016]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.19.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0035,  0.0110,  0.0136,  ...,  0.0070, -0.0204,  0.0242],\n",
       "                      [ 0.0273, -0.0302,  0.0006,  ...,  0.0043,  0.0117,  0.0047],\n",
       "                      [ 0.0082,  0.0149, -0.0074,  ...,  0.0145,  0.0020,  0.0034],\n",
       "                      ...,\n",
       "                      [-0.0132, -0.0214,  0.0002,  ...,  0.0205,  0.0077, -0.0062],\n",
       "                      [-0.0347,  0.0035,  0.0089,  ...,  0.0147,  0.0050, -0.0204],\n",
       "                      [ 0.0329, -0.0173,  0.0119,  ..., -0.0033,  0.0287, -0.0151]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.19.self_attn.v_proj.weight',\n",
       "              tensor([[-0.0071,  0.0257, -0.0069,  ...,  0.0111,  0.0088, -0.0140],\n",
       "                      [-0.0337,  0.0363, -0.0063,  ..., -0.0025, -0.0068,  0.0226],\n",
       "                      [-0.0004,  0.0319,  0.0237,  ..., -0.0144,  0.0179, -0.0015],\n",
       "                      ...,\n",
       "                      [-0.0089, -0.0162, -0.0271,  ...,  0.0021, -0.0228, -0.0111],\n",
       "                      [-0.0302, -0.0249,  0.0389,  ...,  0.0046, -0.0019,  0.0002],\n",
       "                      [-0.0012,  0.0030, -0.0201,  ...,  0.0157,  0.0578,  0.0338]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.19.self_attn.o_proj.weight',\n",
       "              tensor([[-0.0111,  0.0160,  0.0070,  ..., -0.0074, -0.0042,  0.0177],\n",
       "                      [-0.0238,  0.0083, -0.0053,  ..., -0.0175, -0.0190, -0.0046],\n",
       "                      [-0.0136, -0.0044,  0.0092,  ...,  0.0085, -0.0161,  0.0098],\n",
       "                      ...,\n",
       "                      [ 0.0026, -0.0208,  0.0305,  ..., -0.0053,  0.0043, -0.0347],\n",
       "                      [ 0.0144,  0.0075, -0.0205,  ..., -0.0197, -0.0034,  0.0206],\n",
       "                      [ 0.0025, -0.0239,  0.0211,  ...,  0.0168, -0.0053, -0.0003]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.19.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0216,  0.0258, -0.0410,  ...,  0.0192,  0.0113,  0.0228],\n",
       "                      [ 0.0054, -0.0188, -0.0149,  ...,  0.0063, -0.0127,  0.0413],\n",
       "                      [ 0.0124, -0.0034, -0.0179,  ..., -0.0144,  0.0158, -0.0003],\n",
       "                      ...,\n",
       "                      [ 0.0239, -0.0192, -0.0025,  ..., -0.0352,  0.0077, -0.0136],\n",
       "                      [ 0.0025,  0.0064, -0.0274,  ...,  0.0115, -0.0048,  0.0316],\n",
       "                      [-0.0201, -0.0141, -0.0111,  ..., -0.0186, -0.0359, -0.0117]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.19.mlp.up_proj.weight',\n",
       "              tensor([[-0.0158,  0.0037, -0.0105,  ...,  0.0109, -0.0090, -0.0330],\n",
       "                      [ 0.0085,  0.0151,  0.0282,  ..., -0.0526, -0.0291,  0.0181],\n",
       "                      [-0.0159, -0.0266, -0.0178,  ..., -0.0065,  0.0009, -0.0221],\n",
       "                      ...,\n",
       "                      [ 0.0084,  0.0257, -0.0174,  ..., -0.0232, -0.0058, -0.0003],\n",
       "                      [ 0.0132, -0.0108, -0.0150,  ...,  0.0085, -0.0178,  0.0564],\n",
       "                      [-0.0052, -0.0020, -0.0169,  ...,  0.0197, -0.0095,  0.0010]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.19.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0192,  0.0281,  0.0023,  ...,  0.0439, -0.0245, -0.0067],\n",
       "                      [-0.0140, -0.0106, -0.0263,  ..., -0.0160,  0.0269, -0.0179],\n",
       "                      [-0.0063,  0.0066, -0.0192,  ..., -0.0002, -0.0416, -0.0023],\n",
       "                      ...,\n",
       "                      [-0.0145,  0.0045,  0.0249,  ...,  0.0279, -0.0019, -0.0317],\n",
       "                      [ 0.0238,  0.0125, -0.0333,  ..., -0.0186, -0.0078, -0.0144],\n",
       "                      [-0.0017,  0.0022,  0.0184,  ..., -0.0109,  0.0025, -0.0238]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.19.input_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.19.post_attention_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.20.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0086,  0.0004, -0.0039,  ..., -0.0148, -0.0056,  0.0370],\n",
       "                      [ 0.0201, -0.0207, -0.0021,  ..., -0.0169,  0.0107,  0.0220],\n",
       "                      [-0.0007,  0.0175, -0.0092,  ..., -0.0158,  0.0336, -0.0439],\n",
       "                      ...,\n",
       "                      [ 0.0176, -0.0048,  0.0266,  ...,  0.0134,  0.0251,  0.0223],\n",
       "                      [-0.0109,  0.0112, -0.0067,  ..., -0.0018,  0.0149,  0.0314],\n",
       "                      [ 0.0108, -0.0219,  0.0171,  ...,  0.0098, -0.0286,  0.0347]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.20.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0163, -0.0136, -0.0025,  ..., -0.0014,  0.0078, -0.0103],\n",
       "                      [ 0.0036,  0.0075,  0.0024,  ...,  0.0143,  0.0357,  0.0148],\n",
       "                      [ 0.0160, -0.0207,  0.0090,  ...,  0.0232,  0.0220,  0.0355],\n",
       "                      ...,\n",
       "                      [ 0.0072,  0.0045, -0.0279,  ..., -0.0199, -0.0137, -0.0196],\n",
       "                      [ 0.0097,  0.0148, -0.0186,  ...,  0.0017, -0.0203, -0.0054],\n",
       "                      [-0.0002, -0.0017,  0.0485,  ..., -0.0230,  0.0475, -0.0104]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.20.self_attn.v_proj.weight',\n",
       "              tensor([[-2.6764e-02,  2.0126e-02,  1.8967e-02,  ...,  1.9089e-02,\n",
       "                       -5.3009e-02,  2.5806e-03],\n",
       "                      [ 1.3634e-02,  8.8043e-03,  2.5131e-02,  ...,  1.1692e-03,\n",
       "                       -1.0727e-02,  8.5449e-03],\n",
       "                      [ 3.6865e-02,  2.2141e-02, -8.8835e-04,  ...,  7.2336e-04,\n",
       "                       -1.8280e-02, -6.7558e-03],\n",
       "                      ...,\n",
       "                      [ 2.1851e-02,  1.8082e-02,  8.2245e-03,  ...,  2.7847e-02,\n",
       "                       -1.2077e-02,  4.7836e-03],\n",
       "                      [ 3.6001e-05,  1.2505e-02,  2.1332e-02,  ..., -1.5350e-02,\n",
       "                        3.3417e-02,  1.0004e-03],\n",
       "                      [ 1.3008e-03,  7.7019e-03,  1.8492e-03,  ...,  2.3148e-02,\n",
       "                        1.1070e-02, -2.1393e-02]], dtype=torch.float16)),\n",
       "             ('model.layers.20.self_attn.o_proj.weight',\n",
       "              tensor([[-0.0235,  0.0181,  0.0210,  ...,  0.0187, -0.0034,  0.0357],\n",
       "                      [-0.0045, -0.0305,  0.0052,  ..., -0.0083,  0.0405, -0.0031],\n",
       "                      [-0.0468, -0.0016,  0.0179,  ..., -0.0093, -0.0093, -0.0226],\n",
       "                      ...,\n",
       "                      [-0.0118, -0.0027, -0.0297,  ...,  0.0069,  0.0059, -0.0199],\n",
       "                      [ 0.0092, -0.0075, -0.0261,  ..., -0.0182,  0.0155,  0.0091],\n",
       "                      [ 0.0352,  0.0039,  0.0103,  ..., -0.0141,  0.0188, -0.0171]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.20.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0012,  0.0089, -0.0243,  ..., -0.0121, -0.0071,  0.0067],\n",
       "                      [-0.0222, -0.0007, -0.0003,  ..., -0.0187,  0.0188, -0.0231],\n",
       "                      [ 0.0113, -0.0177,  0.0211,  ...,  0.0195, -0.0035, -0.0307],\n",
       "                      ...,\n",
       "                      [-0.0164,  0.0163,  0.0226,  ..., -0.0111, -0.0078,  0.0031],\n",
       "                      [ 0.0022,  0.0152,  0.0016,  ...,  0.0228, -0.0302, -0.0158],\n",
       "                      [ 0.0242, -0.0118,  0.0290,  ..., -0.0034, -0.0077, -0.0192]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.20.mlp.up_proj.weight',\n",
       "              tensor([[-0.0275,  0.0243,  0.0049,  ...,  0.0079, -0.0249, -0.0227],\n",
       "                      [ 0.0035,  0.0089, -0.0515,  ...,  0.0079, -0.0129, -0.0116],\n",
       "                      [-0.0248, -0.0155, -0.0258,  ..., -0.0142,  0.0312, -0.0030],\n",
       "                      ...,\n",
       "                      [-0.0334,  0.0151, -0.0034,  ...,  0.0095,  0.0276, -0.0125],\n",
       "                      [ 0.0129,  0.0048,  0.0180,  ..., -0.0064, -0.0012,  0.0295],\n",
       "                      [ 0.0208, -0.0163, -0.0304,  ...,  0.0021, -0.0059,  0.0076]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.20.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0290,  0.0256,  0.0338,  ..., -0.0194, -0.0027,  0.0063],\n",
       "                      [ 0.0059, -0.0057,  0.0234,  ...,  0.0111, -0.0145,  0.0043],\n",
       "                      [-0.0258, -0.0191,  0.0334,  ..., -0.0026,  0.0039, -0.0163],\n",
       "                      ...,\n",
       "                      [-0.0120, -0.0011,  0.0296,  ...,  0.0327, -0.0121,  0.0076],\n",
       "                      [-0.0108, -0.0216, -0.0018,  ..., -0.0350,  0.0008, -0.0063],\n",
       "                      [ 0.0164,  0.0047, -0.0006,  ..., -0.0083,  0.0152, -0.0177]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.20.input_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.20.post_attention_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.21.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0083, -0.0071,  0.0313,  ..., -0.0454,  0.0396,  0.0155],\n",
       "                      [-0.0163,  0.0358,  0.0342,  ...,  0.0332,  0.0073, -0.0309],\n",
       "                      [ 0.0292, -0.0220, -0.0208,  ..., -0.0459, -0.0057, -0.0088],\n",
       "                      ...,\n",
       "                      [ 0.0013, -0.0224, -0.0252,  ...,  0.0040, -0.0146,  0.0143],\n",
       "                      [-0.0386,  0.0286, -0.0380,  ...,  0.0037, -0.0030,  0.0155],\n",
       "                      [ 0.0145, -0.0162,  0.0173,  ...,  0.0100, -0.0517, -0.0060]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.21.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0224, -0.0016, -0.0010,  ..., -0.0060, -0.0017, -0.0177],\n",
       "                      [ 0.0014,  0.0332, -0.0202,  ...,  0.0006, -0.0014, -0.0026],\n",
       "                      [-0.0049, -0.0288,  0.0137,  ..., -0.0101,  0.0248,  0.0027],\n",
       "                      ...,\n",
       "                      [-0.0028,  0.0022,  0.0261,  ...,  0.0166,  0.0203, -0.0073],\n",
       "                      [-0.0223, -0.0068,  0.0131,  ...,  0.0068,  0.0086, -0.0192],\n",
       "                      [ 0.0084, -0.0027, -0.0138,  ...,  0.0162, -0.0320, -0.0283]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.21.self_attn.v_proj.weight',\n",
       "              tensor([[-0.0163, -0.0537,  0.0211,  ...,  0.0093, -0.0143,  0.0235],\n",
       "                      [-0.0017,  0.0053,  0.0149,  ..., -0.0253,  0.0081, -0.0348],\n",
       "                      [ 0.0245,  0.0181,  0.0322,  ...,  0.0017,  0.0075, -0.0098],\n",
       "                      ...,\n",
       "                      [-0.0009,  0.0059,  0.0199,  ...,  0.0243, -0.0253,  0.0318],\n",
       "                      [-0.0122,  0.0482,  0.0168,  ..., -0.0342,  0.0331,  0.0260],\n",
       "                      [-0.0043,  0.0214,  0.0459,  ...,  0.0239, -0.0190, -0.0031]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.21.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0222, -0.0324,  0.0201,  ...,  0.0277, -0.0261,  0.0291],\n",
       "                      [-0.0252, -0.0026,  0.0156,  ..., -0.0021, -0.0095, -0.0150],\n",
       "                      [ 0.0364, -0.0239,  0.0265,  ...,  0.0074,  0.0275, -0.0120],\n",
       "                      ...,\n",
       "                      [ 0.0020,  0.0103,  0.0304,  ...,  0.0240, -0.0401,  0.0126],\n",
       "                      [-0.0208, -0.0173, -0.0499,  ...,  0.0191,  0.0003,  0.0128],\n",
       "                      [-0.0298, -0.0287,  0.0014,  ...,  0.0123,  0.0045,  0.0256]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.21.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0081, -0.0039, -0.0326,  ..., -0.0035,  0.0083, -0.0149],\n",
       "                      [-0.0277, -0.0569,  0.0380,  ...,  0.0331, -0.0372, -0.0090],\n",
       "                      [-0.0238,  0.0166, -0.0050,  ..., -0.0103,  0.0150, -0.0251],\n",
       "                      ...,\n",
       "                      [-0.0219,  0.0129,  0.0192,  ...,  0.0021,  0.0263, -0.0103],\n",
       "                      [ 0.0225, -0.0119, -0.0410,  ..., -0.0436,  0.0212, -0.0258],\n",
       "                      [-0.0222, -0.0364, -0.0321,  ...,  0.0101,  0.0197, -0.0122]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.21.mlp.up_proj.weight',\n",
       "              tensor([[-0.0089,  0.0077, -0.0089,  ..., -0.0174, -0.0191, -0.0030],\n",
       "                      [-0.0279, -0.0016,  0.0429,  ..., -0.0290,  0.0019,  0.0359],\n",
       "                      [-0.0220,  0.0201,  0.0162,  ..., -0.0107,  0.0137,  0.0165],\n",
       "                      ...,\n",
       "                      [-0.0236,  0.0024,  0.0048,  ..., -0.0122,  0.0435,  0.0089],\n",
       "                      [ 0.0040, -0.0444,  0.0157,  ...,  0.0109, -0.0081,  0.0004],\n",
       "                      [-0.0044,  0.0019,  0.0175,  ..., -0.0125, -0.0366,  0.0291]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.21.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0032,  0.0070, -0.0361,  ...,  0.0078,  0.0122,  0.0096],\n",
       "                      [-0.0224,  0.0317, -0.0158,  ..., -0.0017, -0.0017, -0.0033],\n",
       "                      [ 0.0069,  0.0011,  0.0141,  ..., -0.0061, -0.0009, -0.0158],\n",
       "                      ...,\n",
       "                      [-0.0287,  0.0065,  0.0027,  ..., -0.0193,  0.0359,  0.0229],\n",
       "                      [-0.0079,  0.0302, -0.0178,  ..., -0.0023, -0.0048, -0.0219],\n",
       "                      [-0.0065,  0.0156,  0.0010,  ..., -0.0072,  0.0104,  0.0097]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.21.input_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.21.post_attention_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.22.self_attn.q_proj.weight',\n",
       "              tensor([[ 0.0078, -0.0176,  0.0133,  ..., -0.0042,  0.0122,  0.0105],\n",
       "                      [ 0.0261,  0.0191, -0.0050,  ...,  0.0247,  0.0206,  0.0162],\n",
       "                      [-0.0062, -0.0364, -0.0087,  ...,  0.0043, -0.0166, -0.0323],\n",
       "                      ...,\n",
       "                      [-0.0001, -0.0375,  0.0066,  ..., -0.0192, -0.0050,  0.0113],\n",
       "                      [ 0.0059, -0.0009, -0.0283,  ...,  0.0195,  0.0090,  0.0143],\n",
       "                      [-0.0089, -0.0465, -0.0139,  ..., -0.0169, -0.0010,  0.0169]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.22.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0168, -0.0262, -0.0288,  ..., -0.0112,  0.0098,  0.0063],\n",
       "                      [ 0.0164,  0.0238, -0.0088,  ...,  0.0216, -0.0020, -0.0180],\n",
       "                      [ 0.0058, -0.0002,  0.0215,  ...,  0.0302, -0.0238, -0.0220],\n",
       "                      ...,\n",
       "                      [ 0.0004,  0.0071, -0.0063,  ...,  0.0177, -0.0283,  0.0012],\n",
       "                      [-0.0121, -0.0090,  0.0071,  ...,  0.0313,  0.0139,  0.0213],\n",
       "                      [ 0.0004,  0.0118,  0.0092,  ..., -0.0118,  0.0024,  0.0113]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.22.self_attn.v_proj.weight',\n",
       "              tensor([[-0.0039, -0.0011, -0.0215,  ...,  0.0342, -0.0010, -0.0028],\n",
       "                      [-0.0188, -0.0163,  0.0052,  ...,  0.0180, -0.0145,  0.0022],\n",
       "                      [-0.0185, -0.0096, -0.0016,  ...,  0.0131, -0.0453,  0.0203],\n",
       "                      ...,\n",
       "                      [-0.0052,  0.0013, -0.0067,  ..., -0.0271,  0.0436,  0.0054],\n",
       "                      [-0.0370,  0.0228,  0.0197,  ..., -0.0086,  0.0092, -0.0102],\n",
       "                      [-0.0258,  0.0102, -0.0120,  ..., -0.0333,  0.0116, -0.0352]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.22.self_attn.o_proj.weight',\n",
       "              tensor([[ 1.6037e-02,  2.1683e-02,  1.1971e-02,  ..., -1.6556e-02,\n",
       "                        3.2257e-02, -2.6749e-02],\n",
       "                      [ 1.6129e-02, -1.4748e-02, -9.0866e-03,  ..., -1.3176e-02,\n",
       "                       -1.7595e-03, -1.4145e-02],\n",
       "                      [ 2.5772e-02, -3.9459e-02, -4.4464e-02,  ...,  1.5457e-02,\n",
       "                       -5.7449e-03, -4.5052e-03],\n",
       "                      ...,\n",
       "                      [-3.5858e-02, -3.0842e-03, -6.6490e-03,  ..., -1.5854e-02,\n",
       "                       -3.3295e-02, -6.6161e-06],\n",
       "                      [ 1.3168e-02, -2.1248e-03, -1.0767e-03,  ...,  1.7181e-02,\n",
       "                        9.8267e-03, -8.1482e-03],\n",
       "                      [-9.4376e-03, -1.2100e-02, -1.2070e-02,  ...,  3.3588e-03,\n",
       "                       -4.5090e-03,  1.5732e-02]], dtype=torch.float16)),\n",
       "             ('model.layers.22.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0131,  0.0076, -0.0238,  ..., -0.0163,  0.0160,  0.0154],\n",
       "                      [ 0.0145, -0.0022,  0.0014,  ...,  0.0259,  0.0172, -0.0086],\n",
       "                      [-0.0053, -0.0059, -0.0182,  ...,  0.0313,  0.0079,  0.0011],\n",
       "                      ...,\n",
       "                      [-0.0021,  0.0205,  0.0138,  ...,  0.0342, -0.0213, -0.0770],\n",
       "                      [ 0.0106, -0.0182, -0.0137,  ...,  0.0163,  0.0192,  0.0070],\n",
       "                      [ 0.0007,  0.0087, -0.0243,  ...,  0.0164, -0.0232, -0.0253]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.22.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0094, -0.0154,  0.0046,  ...,  0.0275,  0.0555,  0.0428],\n",
       "                      [ 0.0194,  0.0283, -0.0125,  ...,  0.0406,  0.0152, -0.0093],\n",
       "                      [ 0.0251, -0.0039,  0.0124,  ..., -0.0145,  0.0022, -0.0121],\n",
       "                      ...,\n",
       "                      [-0.0090,  0.0138, -0.0208,  ...,  0.0189, -0.0308, -0.0464],\n",
       "                      [-0.0009, -0.0199, -0.0120,  ..., -0.0124,  0.0130,  0.0006],\n",
       "                      [ 0.0079, -0.0388, -0.0076,  ...,  0.0051,  0.0082, -0.0066]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.22.mlp.down_proj.weight',\n",
       "              tensor([[-0.0140, -0.0158,  0.0059,  ..., -0.0144, -0.0141,  0.0199],\n",
       "                      [-0.0139, -0.0124, -0.0143,  ..., -0.0202, -0.0027,  0.0227],\n",
       "                      [ 0.0308,  0.0030, -0.0088,  ...,  0.0134, -0.0019, -0.0190],\n",
       "                      ...,\n",
       "                      [ 0.0166, -0.0202,  0.0482,  ...,  0.0268,  0.0355,  0.0143],\n",
       "                      [-0.0099,  0.0508,  0.0195,  ..., -0.0332,  0.0239,  0.0236],\n",
       "                      [-0.0109,  0.0056, -0.0210,  ..., -0.0233,  0.0131, -0.0133]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.22.input_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.22.post_attention_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.23.self_attn.q_proj.weight',\n",
       "              tensor([[ 0.0043, -0.0089,  0.0121,  ...,  0.0090, -0.0210,  0.0217],\n",
       "                      [ 0.0082,  0.0259,  0.0002,  ..., -0.0062,  0.0079,  0.0160],\n",
       "                      [ 0.0005, -0.0233,  0.0017,  ..., -0.0164,  0.0078,  0.0206],\n",
       "                      ...,\n",
       "                      [-0.0006, -0.0013, -0.0169,  ...,  0.0121, -0.0470, -0.0101],\n",
       "                      [ 0.0135, -0.0059,  0.0036,  ...,  0.0344, -0.0278, -0.0139],\n",
       "                      [ 0.0104, -0.0144, -0.0360,  ...,  0.0048,  0.0186,  0.0238]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.23.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0253, -0.0298,  0.0214,  ..., -0.0022,  0.0059,  0.0219],\n",
       "                      [ 0.0380, -0.0393,  0.0211,  ...,  0.0327, -0.0152,  0.0056],\n",
       "                      [-0.0041, -0.0295,  0.0335,  ..., -0.0211, -0.0316, -0.0357],\n",
       "                      ...,\n",
       "                      [-0.0330, -0.0106, -0.0046,  ..., -0.0103,  0.0039, -0.0241],\n",
       "                      [-0.0147,  0.0089,  0.0046,  ..., -0.0078, -0.0213,  0.0012],\n",
       "                      [ 0.0103, -0.0003,  0.0091,  ..., -0.0198,  0.0097,  0.0044]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.23.self_attn.v_proj.weight',\n",
       "              tensor([[ 0.0442,  0.0252,  0.0121,  ..., -0.0085,  0.0012, -0.0521],\n",
       "                      [ 0.0012,  0.0076,  0.0011,  ...,  0.0297,  0.0225, -0.0161],\n",
       "                      [ 0.0034, -0.0396, -0.0132,  ...,  0.0345,  0.0076, -0.0289],\n",
       "                      ...,\n",
       "                      [ 0.0304,  0.0205, -0.0370,  ...,  0.0042, -0.0119,  0.0100],\n",
       "                      [-0.0323,  0.0250, -0.0049,  ...,  0.0282,  0.0233,  0.0156],\n",
       "                      [-0.0067,  0.0016, -0.0212,  ..., -0.0050, -0.0135, -0.0068]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.23.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0086, -0.0243, -0.0012,  ...,  0.0180, -0.0061, -0.0116],\n",
       "                      [-0.0026,  0.0098, -0.0249,  ..., -0.0269, -0.0421,  0.0117],\n",
       "                      [-0.0195, -0.0246, -0.0430,  ...,  0.0066, -0.0275, -0.0109],\n",
       "                      ...,\n",
       "                      [-0.0169, -0.0083,  0.0209,  ...,  0.0089,  0.0030, -0.0097],\n",
       "                      [-0.0064,  0.0347, -0.0091,  ..., -0.0164,  0.0063, -0.0075],\n",
       "                      [-0.0073,  0.0026,  0.0102,  ...,  0.0177,  0.0254,  0.0311]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.23.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0092,  0.0010, -0.0056,  ..., -0.0001,  0.0067, -0.0181],\n",
       "                      [ 0.0090, -0.0026, -0.0036,  ...,  0.0101,  0.0063, -0.0286],\n",
       "                      [ 0.0018, -0.0474,  0.0119,  ...,  0.0241, -0.0040,  0.0151],\n",
       "                      ...,\n",
       "                      [-0.0174, -0.0178,  0.0156,  ...,  0.0304, -0.0022, -0.0159],\n",
       "                      [ 0.0269,  0.0181, -0.0307,  ...,  0.0243, -0.0108,  0.0065],\n",
       "                      [-0.0565,  0.0139,  0.0283,  ..., -0.0620,  0.0060,  0.0095]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.23.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0173,  0.0253, -0.0403,  ...,  0.0047, -0.0198, -0.0153],\n",
       "                      [ 0.0083,  0.0281,  0.0006,  ...,  0.0350,  0.0045,  0.0192],\n",
       "                      [-0.0426, -0.0053, -0.0103,  ..., -0.0154, -0.0229, -0.0435],\n",
       "                      ...,\n",
       "                      [-0.0107,  0.0158,  0.0273,  ...,  0.0216, -0.0286, -0.0237],\n",
       "                      [ 0.0170, -0.0032,  0.0034,  ..., -0.0218, -0.0065, -0.0219],\n",
       "                      [ 0.0060,  0.0126,  0.0341,  ..., -0.0167, -0.0098,  0.0138]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.23.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0028, -0.0122, -0.0199,  ..., -0.0152, -0.0147, -0.0132],\n",
       "                      [ 0.0038, -0.0029,  0.0029,  ...,  0.0265,  0.0012,  0.0179],\n",
       "                      [ 0.0111,  0.0080, -0.0026,  ...,  0.0146,  0.0006, -0.0050],\n",
       "                      ...,\n",
       "                      [-0.0100, -0.0205,  0.0186,  ..., -0.0241,  0.0123, -0.0236],\n",
       "                      [-0.0348, -0.0007,  0.0099,  ..., -0.0205, -0.0142,  0.0167],\n",
       "                      [ 0.0128,  0.0047,  0.0406,  ..., -0.0301,  0.0011, -0.0107]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.23.input_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.23.post_attention_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.24.self_attn.q_proj.weight',\n",
       "              tensor([[ 0.0001,  0.0336,  0.0051,  ...,  0.0028,  0.0055,  0.0032],\n",
       "                      [-0.0018, -0.0276, -0.0062,  ..., -0.0057,  0.0229, -0.0146],\n",
       "                      [-0.0176,  0.0135,  0.0053,  ...,  0.0251, -0.0117, -0.0199],\n",
       "                      ...,\n",
       "                      [ 0.0132,  0.0171, -0.0086,  ..., -0.0243, -0.0266,  0.0028],\n",
       "                      [-0.0307, -0.0231, -0.0223,  ...,  0.0074, -0.0355, -0.0016],\n",
       "                      [ 0.0148, -0.0024, -0.0334,  ...,  0.0037,  0.0091,  0.0163]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.24.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0183, -0.0069,  0.0144,  ...,  0.0061,  0.0177, -0.0031],\n",
       "                      [ 0.0070,  0.0029,  0.0368,  ..., -0.0169, -0.0225, -0.0221],\n",
       "                      [-0.0193, -0.0167, -0.0259,  ...,  0.0084,  0.0210, -0.0029],\n",
       "                      ...,\n",
       "                      [ 0.0002, -0.0471,  0.0085,  ..., -0.0123, -0.0065, -0.0734],\n",
       "                      [ 0.0194,  0.0096, -0.0406,  ..., -0.0335, -0.0207,  0.0171],\n",
       "                      [-0.0288, -0.0070,  0.0206,  ..., -0.0297, -0.0002,  0.0051]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.24.self_attn.v_proj.weight',\n",
       "              tensor([[ 0.0001,  0.0441, -0.0191,  ...,  0.0239,  0.0131, -0.0115],\n",
       "                      [ 0.0305,  0.0482,  0.0157,  ...,  0.0074,  0.0355,  0.0076],\n",
       "                      [-0.0342, -0.0067, -0.0498,  ..., -0.0226,  0.0029, -0.0116],\n",
       "                      ...,\n",
       "                      [ 0.0504, -0.0176,  0.0475,  ...,  0.0014, -0.0094, -0.0035],\n",
       "                      [ 0.0334, -0.0120, -0.0160,  ..., -0.0006, -0.0100,  0.0448],\n",
       "                      [-0.0148,  0.0037, -0.0096,  ...,  0.0428, -0.0329,  0.0091]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.24.self_attn.o_proj.weight',\n",
       "              tensor([[-1.1887e-02, -3.4058e-02,  2.8214e-02,  ...,  4.4975e-03,\n",
       "                        3.3295e-02, -5.1537e-03],\n",
       "                      [ 8.6517e-03,  2.4353e-02, -1.5282e-02,  ...,  2.3392e-02,\n",
       "                        3.5114e-03,  5.7564e-03],\n",
       "                      [ 2.3117e-02,  1.5612e-03, -4.2603e-02,  ..., -5.8591e-05,\n",
       "                        1.8250e-02, -1.5732e-02],\n",
       "                      ...,\n",
       "                      [-1.1930e-03,  6.0234e-03,  1.1612e-02,  ..., -2.0966e-02,\n",
       "                        2.0325e-02,  1.8265e-02],\n",
       "                      [ 1.5030e-02, -1.6613e-03, -2.9316e-03,  ..., -2.4429e-02,\n",
       "                       -1.2215e-02,  2.6382e-02],\n",
       "                      [-2.4246e-02,  4.3526e-03,  6.3667e-03,  ..., -1.0139e-02,\n",
       "                        1.0063e-02,  1.3359e-02]], dtype=torch.float16)),\n",
       "             ('model.layers.24.mlp.gate_proj.weight',\n",
       "              tensor([[-1.7288e-02, -1.5869e-02, -1.6251e-02,  ..., -1.6983e-02,\n",
       "                        3.3142e-02,  2.3544e-02],\n",
       "                      [ 3.1769e-02, -2.6688e-02,  1.3016e-02,  ...,  1.2074e-03,\n",
       "                       -2.5620e-02, -3.6259e-03],\n",
       "                      [ 2.5299e-02, -1.9089e-02, -3.6530e-02,  ..., -2.6031e-02,\n",
       "                       -4.2877e-03, -6.7253e-03],\n",
       "                      ...,\n",
       "                      [ 2.8670e-05,  1.6403e-02, -9.6512e-04,  ...,  2.8519e-02,\n",
       "                       -7.3051e-03,  2.5818e-02],\n",
       "                      [ 2.3483e-02, -1.9379e-02,  1.7776e-02,  ..., -1.8478e-02,\n",
       "                       -1.0475e-02, -1.4572e-02],\n",
       "                      [-7.3166e-03, -2.2423e-04,  3.5439e-03,  ...,  2.6550e-02,\n",
       "                        6.6280e-04, -3.3226e-03]], dtype=torch.float16)),\n",
       "             ('model.layers.24.mlp.up_proj.weight',\n",
       "              tensor([[-0.0217, -0.0076, -0.0055,  ..., -0.0168,  0.0270, -0.0146],\n",
       "                      [ 0.0118,  0.0461,  0.0482,  ..., -0.0052,  0.0052, -0.0486],\n",
       "                      [ 0.0261,  0.0274,  0.0236,  ...,  0.0215, -0.0016, -0.0091],\n",
       "                      ...,\n",
       "                      [-0.0125, -0.0171,  0.0165,  ..., -0.0031, -0.0263,  0.0271],\n",
       "                      [ 0.0155, -0.0439, -0.0355,  ..., -0.0189, -0.0464, -0.0029],\n",
       "                      [ 0.0139,  0.0019,  0.0196,  ...,  0.0107, -0.0151,  0.0114]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.24.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0032, -0.0136,  0.0069,  ...,  0.0333,  0.0092,  0.0123],\n",
       "                      [-0.0154,  0.0031, -0.0044,  ...,  0.0266, -0.0146,  0.0026],\n",
       "                      [-0.0121, -0.0343,  0.0137,  ...,  0.0066,  0.0020, -0.0126],\n",
       "                      ...,\n",
       "                      [-0.0091, -0.0037,  0.0153,  ..., -0.0145,  0.0060, -0.0104],\n",
       "                      [-0.0215,  0.0065, -0.0326,  ..., -0.0078,  0.0022,  0.0019],\n",
       "                      [-0.0529, -0.0172, -0.0165,  ...,  0.0189, -0.0027, -0.0280]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.24.input_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.24.post_attention_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.25.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0019,  0.0388,  0.0106,  ...,  0.0443,  0.0010, -0.0039],\n",
       "                      [-0.0191, -0.0190, -0.0080,  ...,  0.0002, -0.0071, -0.0005],\n",
       "                      [-0.0122, -0.0050,  0.0107,  ..., -0.0270,  0.0170,  0.0081],\n",
       "                      ...,\n",
       "                      [ 0.0084,  0.0109, -0.0118,  ..., -0.0580, -0.0168,  0.0317],\n",
       "                      [-0.0242,  0.0374, -0.0029,  ..., -0.0135, -0.0047,  0.0085],\n",
       "                      [-0.0008, -0.0191, -0.0283,  ..., -0.0339, -0.0063, -0.0083]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.25.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0253, -0.0031,  0.0113,  ...,  0.0122, -0.0315, -0.0312],\n",
       "                      [-0.0190,  0.0356,  0.0124,  ...,  0.0136,  0.0195, -0.0038],\n",
       "                      [ 0.0002,  0.0417,  0.0414,  ...,  0.0417,  0.0050, -0.0122],\n",
       "                      ...,\n",
       "                      [-0.0216, -0.0097, -0.0356,  ...,  0.0034,  0.0005,  0.0097],\n",
       "                      [ 0.0131, -0.0195, -0.0243,  ...,  0.0075, -0.0177,  0.0008],\n",
       "                      [-0.0319,  0.0031,  0.0110,  ...,  0.0509, -0.0025,  0.0152]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.25.self_attn.v_proj.weight',\n",
       "              tensor([[-0.0194,  0.0020, -0.0031,  ..., -0.0165, -0.0103,  0.0183],\n",
       "                      [ 0.0185, -0.0100,  0.0171,  ..., -0.0414,  0.0240, -0.0201],\n",
       "                      [ 0.0114, -0.0395, -0.0014,  ...,  0.0167,  0.0086,  0.0035],\n",
       "                      ...,\n",
       "                      [-0.0045,  0.0106,  0.0029,  ..., -0.0087,  0.0416,  0.0046],\n",
       "                      [-0.0334,  0.0020,  0.0303,  ..., -0.0008,  0.0014,  0.0072],\n",
       "                      [-0.0055, -0.0062,  0.0387,  ..., -0.0405, -0.0061, -0.0122]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.25.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0100, -0.0295,  0.0157,  ...,  0.0152, -0.0063,  0.0073],\n",
       "                      [ 0.0056, -0.0009,  0.0293,  ..., -0.0273,  0.0083,  0.0059],\n",
       "                      [-0.0200,  0.0132,  0.0104,  ...,  0.0109,  0.0505, -0.0003],\n",
       "                      ...,\n",
       "                      [ 0.0172,  0.0125,  0.0118,  ..., -0.0549, -0.0070, -0.0328],\n",
       "                      [-0.0024,  0.0298, -0.0065,  ...,  0.0406, -0.0186, -0.0294],\n",
       "                      [-0.0164,  0.0023,  0.0044,  ...,  0.0130,  0.0235, -0.0104]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.25.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0241, -0.0156, -0.0219,  ..., -0.0022,  0.0007,  0.0079],\n",
       "                      [ 0.0024, -0.0508, -0.0010,  ..., -0.0069, -0.0206, -0.0167],\n",
       "                      [ 0.0151,  0.0077, -0.0024,  ..., -0.0061, -0.0329,  0.0277],\n",
       "                      ...,\n",
       "                      [ 0.0071, -0.0104,  0.0069,  ...,  0.0024, -0.0252, -0.0228],\n",
       "                      [ 0.0058, -0.0170,  0.0225,  ...,  0.0008, -0.0230, -0.0191],\n",
       "                      [ 0.0279,  0.0282,  0.0049,  ..., -0.0110, -0.0442,  0.0063]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.25.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0074,  0.0086, -0.0073,  ..., -0.0123,  0.0070,  0.0200],\n",
       "                      [ 0.0038,  0.0201,  0.0155,  ...,  0.0110,  0.0108,  0.0253],\n",
       "                      [-0.0164,  0.0226,  0.0091,  ...,  0.0270,  0.0023, -0.0117],\n",
       "                      ...,\n",
       "                      [-0.0197, -0.0003,  0.0141,  ...,  0.0184, -0.0087, -0.0192],\n",
       "                      [ 0.0469,  0.0095, -0.0061,  ...,  0.0242, -0.0058,  0.0212],\n",
       "                      [-0.0237,  0.0130,  0.0175,  ..., -0.0020, -0.0141,  0.0152]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.25.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0132,  0.0001,  0.0243,  ...,  0.0381,  0.0302, -0.0178],\n",
       "                      [-0.0094, -0.0115,  0.0240,  ...,  0.0039, -0.0209,  0.0252],\n",
       "                      [-0.0200, -0.0008,  0.0161,  ...,  0.0050, -0.0024,  0.0272],\n",
       "                      ...,\n",
       "                      [-0.0191, -0.0532,  0.0170,  ..., -0.0023, -0.0167,  0.0071],\n",
       "                      [-0.0187,  0.0105,  0.0076,  ...,  0.0411,  0.0184,  0.0004],\n",
       "                      [ 0.0127,  0.0009,  0.0129,  ..., -0.0238, -0.0131,  0.0018]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.25.input_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.25.post_attention_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.26.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0162,  0.0087,  0.0179,  ..., -0.0097, -0.0161, -0.0089],\n",
       "                      [ 0.0121,  0.0023,  0.0036,  ...,  0.0073, -0.0190,  0.0127],\n",
       "                      [ 0.0372,  0.0116,  0.0104,  ..., -0.0306,  0.0203, -0.0375],\n",
       "                      ...,\n",
       "                      [-0.0222,  0.0055, -0.0144,  ...,  0.0106,  0.0266, -0.0012],\n",
       "                      [ 0.0028, -0.0098,  0.0122,  ...,  0.0129, -0.0145,  0.0056],\n",
       "                      [ 0.0081,  0.0219, -0.0064,  ..., -0.0075,  0.0244,  0.0084]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.26.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0090,  0.0289, -0.0229,  ...,  0.0391,  0.0122,  0.0056],\n",
       "                      [ 0.0079,  0.0066, -0.0078,  ..., -0.0302, -0.0170, -0.0110],\n",
       "                      [-0.0434,  0.0147, -0.0339,  ..., -0.0253, -0.0096,  0.0062],\n",
       "                      ...,\n",
       "                      [-0.0217,  0.0207,  0.0189,  ..., -0.0055,  0.0002,  0.0420],\n",
       "                      [-0.0087,  0.0068,  0.0077,  ..., -0.0105, -0.0234,  0.0153],\n",
       "                      [ 0.0198, -0.0225,  0.0064,  ..., -0.0267, -0.0217,  0.0125]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.26.self_attn.v_proj.weight',\n",
       "              tensor([[-0.0246,  0.0190,  0.0192,  ..., -0.0017,  0.0004, -0.0059],\n",
       "                      [ 0.0295, -0.0175,  0.0167,  ..., -0.0144, -0.0015, -0.0050],\n",
       "                      [ 0.0025,  0.0164,  0.0264,  ..., -0.0065,  0.0139, -0.0056],\n",
       "                      ...,\n",
       "                      [-0.0147,  0.0032,  0.0017,  ...,  0.0013, -0.0063, -0.0069],\n",
       "                      [ 0.0018, -0.0363,  0.0063,  ...,  0.0288, -0.0184, -0.0373],\n",
       "                      [ 0.0057, -0.0129, -0.0155,  ..., -0.0129, -0.0020, -0.0008]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.26.self_attn.o_proj.weight',\n",
       "              tensor([[-0.0061,  0.0118,  0.0237,  ...,  0.0233,  0.0107,  0.0202],\n",
       "                      [-0.0041,  0.0114,  0.0101,  ...,  0.0162,  0.0069, -0.0088],\n",
       "                      [-0.0072,  0.0090,  0.0381,  ...,  0.0003,  0.0019,  0.0059],\n",
       "                      ...,\n",
       "                      [-0.0078, -0.0105,  0.0197,  ..., -0.0218,  0.0047,  0.0133],\n",
       "                      [ 0.0007, -0.0215, -0.0233,  ...,  0.0318,  0.0247, -0.0197],\n",
       "                      [ 0.0117, -0.0309, -0.0250,  ...,  0.0114, -0.0199, -0.0186]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.26.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0084, -0.0097, -0.0127,  ..., -0.0165,  0.0182,  0.0012],\n",
       "                      [-0.0112,  0.0068,  0.0367,  ..., -0.0127,  0.0311,  0.0226],\n",
       "                      [ 0.0199, -0.0325,  0.0279,  ...,  0.0243,  0.0100,  0.0049],\n",
       "                      ...,\n",
       "                      [-0.0097,  0.0346,  0.0106,  ..., -0.0093,  0.0082,  0.0227],\n",
       "                      [-0.0234, -0.0105,  0.0311,  ..., -0.0114, -0.0241, -0.0427],\n",
       "                      [-0.0580, -0.0273,  0.0137,  ..., -0.0036,  0.0026, -0.0163]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.26.mlp.up_proj.weight',\n",
       "              tensor([[-0.0005,  0.0359, -0.0228,  ...,  0.0383, -0.0139, -0.0021],\n",
       "                      [-0.0243, -0.0228, -0.0372,  ..., -0.0411, -0.0185, -0.0188],\n",
       "                      [-0.0011, -0.0080,  0.0149,  ...,  0.0266, -0.0035, -0.0066],\n",
       "                      ...,\n",
       "                      [-0.0152, -0.0088, -0.0059,  ..., -0.0248,  0.0112, -0.0041],\n",
       "                      [ 0.0073, -0.0258,  0.0247,  ...,  0.0149,  0.0195, -0.0134],\n",
       "                      [ 0.0476,  0.0065,  0.0182,  ...,  0.0096,  0.0089, -0.0052]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.26.mlp.down_proj.weight',\n",
       "              tensor([[-8.4763e-03,  1.1978e-02, -1.0193e-02,  ...,  2.6108e-02,\n",
       "                       -4.9782e-03,  1.4153e-03],\n",
       "                      [ 5.0087e-03, -2.9800e-02,  1.9569e-03,  ...,  5.5656e-03,\n",
       "                        3.3081e-02, -2.7008e-02],\n",
       "                      [-1.6174e-02,  1.0895e-02, -4.8943e-03,  ..., -1.7548e-02,\n",
       "                       -6.9141e-04, -1.2962e-02],\n",
       "                      ...,\n",
       "                      [ 1.9760e-02,  6.6161e-05,  3.2578e-03,  ..., -7.2632e-03,\n",
       "                       -4.8309e-02, -4.1885e-03],\n",
       "                      [-1.5778e-02,  1.1027e-05,  1.1322e-02,  ...,  6.9962e-03,\n",
       "                       -3.2104e-02, -2.5654e-03],\n",
       "                      [ 2.0462e-02, -2.8214e-02,  2.4338e-02,  ...,  2.8572e-03,\n",
       "                        2.5894e-02,  2.4521e-02]], dtype=torch.float16)),\n",
       "             ('model.layers.26.input_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.26.post_attention_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.27.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0237,  0.0039,  0.0057,  ..., -0.0210,  0.0073, -0.0153],\n",
       "                      [ 0.0117, -0.0032,  0.0054,  ..., -0.0027, -0.0054,  0.0007],\n",
       "                      [-0.0104, -0.0058, -0.0049,  ...,  0.0191,  0.0056, -0.0146],\n",
       "                      ...,\n",
       "                      [ 0.0031,  0.0276,  0.0233,  ..., -0.0069,  0.0074,  0.0108],\n",
       "                      [-0.0075,  0.0034,  0.0086,  ...,  0.0294,  0.0174,  0.0287],\n",
       "                      [ 0.0151, -0.0067,  0.0233,  ..., -0.0046, -0.0212,  0.0218]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.27.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0265, -0.0179,  0.0161,  ...,  0.0247, -0.0011, -0.0120],\n",
       "                      [-0.0356, -0.0270, -0.0232,  ...,  0.0092,  0.0015,  0.0016],\n",
       "                      [ 0.0229, -0.0157, -0.0082,  ..., -0.0403, -0.0188, -0.0300],\n",
       "                      ...,\n",
       "                      [ 0.0517, -0.0058, -0.0131,  ..., -0.0323,  0.0023,  0.0110],\n",
       "                      [ 0.0313, -0.0405,  0.0141,  ..., -0.0414,  0.0108,  0.0116],\n",
       "                      [-0.0017, -0.0331, -0.0025,  ..., -0.0082,  0.0276, -0.0240]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.27.self_attn.v_proj.weight',\n",
       "              tensor([[-1.0651e-02,  2.8744e-03,  2.2339e-02,  ..., -6.1836e-03,\n",
       "                       -1.9928e-02,  1.6495e-02],\n",
       "                      [-5.6314e-04,  1.8768e-02, -6.1493e-03,  ..., -2.6093e-02,\n",
       "                       -6.2561e-03,  3.6011e-02],\n",
       "                      [-1.2924e-02,  4.5395e-03, -1.9586e-04,  ..., -2.3590e-02,\n",
       "                       -2.7835e-05, -1.4847e-02],\n",
       "                      ...,\n",
       "                      [-1.0269e-02,  1.9958e-02,  3.0136e-02,  ..., -1.3762e-03,\n",
       "                       -8.2092e-03,  2.3087e-02],\n",
       "                      [-8.7280e-03,  2.0676e-03, -2.7924e-02,  ...,  3.4690e-04,\n",
       "                        1.7181e-02,  3.6011e-02],\n",
       "                      [-6.9771e-03, -1.2634e-02,  1.8723e-02,  ..., -2.2278e-02,\n",
       "                       -2.5406e-03, -1.4557e-02]], dtype=torch.float16)),\n",
       "             ('model.layers.27.self_attn.o_proj.weight',\n",
       "              tensor([[ 3.2898e-02,  2.8725e-03, -4.2542e-02,  ...,  5.5809e-03,\n",
       "                        1.1129e-03, -1.0559e-02],\n",
       "                      [-3.8028e-05,  2.6001e-02,  3.4058e-02,  ..., -1.9928e-02,\n",
       "                       -3.1223e-03,  4.4632e-03],\n",
       "                      [ 2.8896e-03, -9.9106e-03, -2.0103e-03,  ..., -1.3374e-02,\n",
       "                       -8.4763e-03,  4.4342e-02],\n",
       "                      ...,\n",
       "                      [-1.6998e-02, -3.3936e-02, -2.5513e-02,  ...,  2.3163e-02,\n",
       "                        1.6586e-02, -2.5864e-03],\n",
       "                      [ 1.0475e-02,  8.0948e-03,  3.7170e-02,  ..., -1.9257e-02,\n",
       "                       -1.6373e-02, -7.8964e-03],\n",
       "                      [-2.2308e-02, -1.1406e-02, -2.7466e-02,  ..., -2.0370e-02,\n",
       "                        1.0178e-02,  9.4376e-03]], dtype=torch.float16)),\n",
       "             ('model.layers.27.mlp.gate_proj.weight',\n",
       "              tensor([[-1.7487e-02, -4.2084e-02, -6.1417e-04,  ...,  1.7366e-03,\n",
       "                        1.2405e-02, -1.2566e-02],\n",
       "                      [-6.0387e-03, -1.4130e-02, -1.0727e-02,  ...,  1.6556e-02,\n",
       "                       -7.8278e-03,  1.5884e-02],\n",
       "                      [-1.6678e-02, -2.1423e-02,  1.7563e-02,  ..., -6.6109e-03,\n",
       "                       -3.0167e-02,  7.5281e-05],\n",
       "                      ...,\n",
       "                      [-1.4290e-02, -2.7252e-02, -1.5129e-02,  ...,  6.6376e-03,\n",
       "                       -1.7639e-02, -3.5839e-03],\n",
       "                      [-8.7967e-03,  2.4933e-02,  8.2550e-03,  ...,  1.4427e-02,\n",
       "                        1.7853e-02,  3.5286e-03],\n",
       "                      [ 2.2736e-02, -2.7871e-04, -1.0605e-02,  ..., -2.7679e-02,\n",
       "                       -5.2834e-03,  3.2776e-02]], dtype=torch.float16)),\n",
       "             ('model.layers.27.mlp.up_proj.weight',\n",
       "              tensor([[-0.0021,  0.0163, -0.0072,  ...,  0.0171,  0.0337, -0.0254],\n",
       "                      [ 0.0304, -0.0160,  0.0382,  ...,  0.0264, -0.0264,  0.0154],\n",
       "                      [ 0.0076,  0.0143, -0.0020,  ..., -0.0083,  0.0179, -0.0091],\n",
       "                      ...,\n",
       "                      [-0.0440, -0.0146, -0.0012,  ..., -0.0339,  0.0227,  0.0026],\n",
       "                      [ 0.0053,  0.0092,  0.0022,  ..., -0.0135,  0.0135, -0.0165],\n",
       "                      [-0.0057,  0.0402,  0.0171,  ...,  0.0134, -0.0132, -0.0535]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.27.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0332, -0.0053, -0.0509,  ..., -0.0170,  0.0008,  0.0156],\n",
       "                      [-0.0296,  0.0166,  0.0498,  ...,  0.0010,  0.0050,  0.0525],\n",
       "                      [-0.0009,  0.0086, -0.0049,  ...,  0.0164,  0.0130, -0.0227],\n",
       "                      ...,\n",
       "                      [ 0.0174, -0.0140, -0.0122,  ...,  0.0251,  0.0087, -0.0325],\n",
       "                      [ 0.0020, -0.0036, -0.0079,  ...,  0.0244, -0.0155,  0.0295],\n",
       "                      [ 0.0197, -0.0007,  0.0264,  ..., -0.0120,  0.0195, -0.0107]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.27.input_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.27.post_attention_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.28.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0111, -0.0147, -0.0226,  ...,  0.0231,  0.0323, -0.0197],\n",
       "                      [-0.0010, -0.0284, -0.0060,  ...,  0.0339,  0.0204,  0.0176],\n",
       "                      [ 0.0010,  0.0037, -0.0223,  ...,  0.0177, -0.0221,  0.0086],\n",
       "                      ...,\n",
       "                      [ 0.0166, -0.0052,  0.0025,  ..., -0.0251,  0.0499, -0.0328],\n",
       "                      [ 0.0032, -0.0067, -0.0007,  ..., -0.0077,  0.0158,  0.0084],\n",
       "                      [-0.0002,  0.0393, -0.0121,  ..., -0.0036,  0.0435,  0.0538]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.28.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0110, -0.0154,  0.0370,  ..., -0.0049, -0.0064,  0.0003],\n",
       "                      [-0.0222, -0.0022,  0.0114,  ..., -0.0478,  0.0006, -0.0397],\n",
       "                      [ 0.0194, -0.0147, -0.0160,  ...,  0.0513, -0.0156,  0.0041],\n",
       "                      ...,\n",
       "                      [ 0.0156,  0.0005, -0.0191,  ..., -0.0011,  0.0101, -0.0113],\n",
       "                      [-0.0381,  0.0126, -0.0039,  ...,  0.0301, -0.0055,  0.0073],\n",
       "                      [-0.0090,  0.0016, -0.0032,  ...,  0.0274,  0.0284,  0.0168]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.28.self_attn.v_proj.weight',\n",
       "              tensor([[ 0.0365,  0.0005,  0.0531,  ...,  0.0045, -0.0135, -0.0029],\n",
       "                      [-0.0006, -0.0176,  0.0446,  ..., -0.0025,  0.0112,  0.0044],\n",
       "                      [-0.0253,  0.0049, -0.0174,  ...,  0.0219, -0.0186, -0.0039],\n",
       "                      ...,\n",
       "                      [-0.0134,  0.0313, -0.0340,  ..., -0.0233,  0.0107,  0.0403],\n",
       "                      [ 0.0047,  0.0039,  0.0009,  ...,  0.0300, -0.0049, -0.0012],\n",
       "                      [ 0.0080, -0.0032, -0.0099,  ...,  0.0162, -0.0119, -0.0161]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.28.self_attn.o_proj.weight',\n",
       "              tensor([[-0.0358,  0.0217, -0.0368,  ..., -0.0071,  0.0019,  0.0307],\n",
       "                      [ 0.0068,  0.0261, -0.0194,  ..., -0.0210, -0.0017, -0.0681],\n",
       "                      [-0.0158, -0.0115,  0.0071,  ..., -0.0039, -0.0223,  0.0076],\n",
       "                      ...,\n",
       "                      [-0.0006,  0.0397, -0.0043,  ...,  0.0268, -0.0043,  0.0100],\n",
       "                      [ 0.0083,  0.0026, -0.0004,  ...,  0.0067,  0.0074,  0.0038],\n",
       "                      [-0.0128,  0.0168, -0.0038,  ..., -0.0023, -0.0059,  0.0066]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.28.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0104, -0.0188,  0.0265,  ..., -0.0158, -0.0132,  0.0202],\n",
       "                      [-0.0101,  0.0119,  0.0113,  ...,  0.0462, -0.0115, -0.0272],\n",
       "                      [-0.0273, -0.0082,  0.0218,  ..., -0.0041,  0.0202,  0.0161],\n",
       "                      ...,\n",
       "                      [ 0.0193, -0.0119,  0.0525,  ..., -0.0007, -0.0050, -0.0006],\n",
       "                      [ 0.0222,  0.0120, -0.0072,  ..., -0.0188,  0.0119, -0.0016],\n",
       "                      [-0.0046, -0.0203, -0.0113,  ..., -0.0377,  0.0158, -0.0068]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.28.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0205, -0.0030,  0.0056,  ...,  0.0031,  0.0157, -0.0189],\n",
       "                      [-0.0019, -0.0149,  0.0100,  ...,  0.0098,  0.0234, -0.0131],\n",
       "                      [-0.0139, -0.0106, -0.0083,  ...,  0.0250, -0.0681, -0.0067],\n",
       "                      ...,\n",
       "                      [-0.0124, -0.0444,  0.0079,  ..., -0.0086, -0.0175,  0.0336],\n",
       "                      [-0.0053, -0.0056,  0.0218,  ...,  0.0269, -0.0200,  0.0031],\n",
       "                      [ 0.0437,  0.0035,  0.0205,  ...,  0.0128, -0.0137, -0.0040]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.28.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0181,  0.0269, -0.0154,  ..., -0.0246, -0.0033, -0.0189],\n",
       "                      [-0.0027, -0.0251, -0.0117,  ..., -0.0152, -0.0425,  0.0059],\n",
       "                      [-0.0012,  0.0039, -0.0170,  ...,  0.0079, -0.0057,  0.0164],\n",
       "                      ...,\n",
       "                      [-0.0204,  0.0085,  0.0123,  ...,  0.0149,  0.0069,  0.0063],\n",
       "                      [ 0.0018,  0.0034, -0.0103,  ..., -0.0261,  0.0262,  0.0135],\n",
       "                      [-0.0413, -0.0106,  0.0117,  ..., -0.0242,  0.0256,  0.0022]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.28.input_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.28.post_attention_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.29.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0101,  0.0084, -0.0004,  ...,  0.0186, -0.0015, -0.0045],\n",
       "                      [-0.0176, -0.0106, -0.0207,  ...,  0.0266, -0.0144, -0.0007],\n",
       "                      [-0.0174,  0.0228, -0.0007,  ...,  0.0170, -0.0333,  0.0305],\n",
       "                      ...,\n",
       "                      [-0.0100, -0.0180, -0.0190,  ..., -0.0084, -0.0056, -0.0029],\n",
       "                      [ 0.0313, -0.0212,  0.0212,  ..., -0.0094,  0.0124, -0.0248],\n",
       "                      [-0.0588,  0.0052, -0.0102,  ...,  0.0234,  0.0214,  0.0005]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.29.self_attn.k_proj.weight',\n",
       "              tensor([[ 5.6076e-04, -1.7349e-02, -3.8788e-02,  ..., -1.3733e-02,\n",
       "                       -4.7073e-03,  4.8676e-03],\n",
       "                      [ 3.2257e-02,  2.0325e-02,  1.2924e-02,  ...,  5.5504e-03,\n",
       "                        1.7151e-02,  2.1591e-02],\n",
       "                      [-3.4515e-02,  3.1891e-03,  8.1024e-03,  ...,  3.0136e-02,\n",
       "                        2.7313e-02, -1.7517e-02],\n",
       "                      ...,\n",
       "                      [ 4.9973e-03, -9.8705e-04,  3.5801e-03,  ...,  6.1066e-02,\n",
       "                        4.4861e-03, -1.1337e-02],\n",
       "                      [ 3.1891e-02, -4.9095e-03,  7.8430e-03,  ...,  7.5798e-03,\n",
       "                        1.7944e-02, -7.8430e-03],\n",
       "                      [ 3.1677e-02, -3.3081e-02, -8.7738e-03,  ..., -3.7079e-02,\n",
       "                        7.6234e-05,  2.0950e-02]], dtype=torch.float16)),\n",
       "             ('model.layers.29.self_attn.v_proj.weight',\n",
       "              tensor([[ 0.0382,  0.0028,  0.0040,  ..., -0.0372,  0.0155, -0.0059],\n",
       "                      [-0.0037,  0.0165,  0.0205,  ..., -0.0181,  0.0236, -0.0478],\n",
       "                      [-0.0255,  0.0164,  0.0130,  ...,  0.0136,  0.0046, -0.0208],\n",
       "                      ...,\n",
       "                      [-0.0100, -0.0080, -0.0023,  ...,  0.0068, -0.0033,  0.0173],\n",
       "                      [ 0.0032, -0.0123,  0.0094,  ...,  0.0401,  0.0012, -0.0022],\n",
       "                      [-0.0326, -0.0142,  0.0213,  ..., -0.0317,  0.0427,  0.0273]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.29.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0033, -0.0124, -0.0120,  ...,  0.0031,  0.0334, -0.0237],\n",
       "                      [ 0.0283, -0.0157,  0.0125,  ...,  0.0027,  0.0299, -0.0101],\n",
       "                      [ 0.0082,  0.0350,  0.0194,  ...,  0.0021, -0.0177,  0.0100],\n",
       "                      ...,\n",
       "                      [-0.0112,  0.0107, -0.0017,  ...,  0.0209, -0.0338, -0.0177],\n",
       "                      [ 0.0251,  0.0003,  0.0210,  ..., -0.0183,  0.0038, -0.0302],\n",
       "                      [ 0.0249, -0.0062, -0.0029,  ..., -0.0081,  0.0003, -0.0012]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.29.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0142, -0.0113, -0.0232,  ..., -0.0150,  0.0105, -0.0235],\n",
       "                      [ 0.0013,  0.0406, -0.0031,  ..., -0.0170,  0.0063,  0.0085],\n",
       "                      [-0.0130, -0.0376,  0.0382,  ...,  0.0036, -0.0003, -0.0247],\n",
       "                      ...,\n",
       "                      [-0.0194,  0.0060,  0.0091,  ..., -0.0063,  0.0347,  0.0322],\n",
       "                      [-0.0132,  0.0157,  0.0020,  ...,  0.0190,  0.0191,  0.0082],\n",
       "                      [-0.0208,  0.0308, -0.0012,  ..., -0.0135, -0.0056,  0.0150]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.29.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0022, -0.0130, -0.0400,  ..., -0.0147,  0.0028,  0.0067],\n",
       "                      [ 0.0436,  0.0100, -0.0309,  ...,  0.0121, -0.0248,  0.0168],\n",
       "                      [-0.0042, -0.0005, -0.0073,  ...,  0.0151, -0.0278, -0.0186],\n",
       "                      ...,\n",
       "                      [-0.0253, -0.0136, -0.0149,  ..., -0.0272,  0.0087, -0.0033],\n",
       "                      [ 0.0087,  0.0045, -0.0337,  ..., -0.0137, -0.0085,  0.0153],\n",
       "                      [-0.0367,  0.0171,  0.0012,  ..., -0.0168, -0.0121,  0.0289]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.29.mlp.down_proj.weight',\n",
       "              tensor([[-1.2001e-02, -9.4681e-03,  2.8137e-02,  ...,  2.2583e-02,\n",
       "                        1.0773e-02, -8.4457e-03],\n",
       "                      [ 4.4365e-03, -1.5465e-02,  1.1063e-04,  ...,  2.9373e-02,\n",
       "                        1.1864e-02, -2.4750e-02],\n",
       "                      [-4.1351e-03, -1.8661e-02, -1.8402e-02,  ...,  9.6207e-03,\n",
       "                        9.5978e-03,  3.8052e-03],\n",
       "                      ...,\n",
       "                      [ 1.3916e-02,  1.5289e-02,  3.8605e-02,  ...,  1.6975e-03,\n",
       "                       -2.1271e-02,  4.8523e-03],\n",
       "                      [ 3.0319e-02,  7.7324e-03,  1.5497e-06,  ...,  4.5807e-02,\n",
       "                        1.3107e-02, -1.2375e-02],\n",
       "                      [ 2.5864e-02, -1.5106e-02,  2.4509e-03,  ..., -5.0278e-03,\n",
       "                       -3.7872e-02,  4.0344e-02]], dtype=torch.float16)),\n",
       "             ('model.layers.29.input_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.29.post_attention_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.30.self_attn.q_proj.weight',\n",
       "              tensor([[-1.9562e-02,  7.5531e-03, -2.0294e-02,  ...,  3.4393e-02,\n",
       "                        3.0945e-02,  3.0579e-02],\n",
       "                      [ 3.7567e-02, -1.0406e-02, -3.1395e-03,  ..., -4.2175e-02,\n",
       "                        8.9645e-03,  1.6129e-02],\n",
       "                      [-3.3752e-02,  2.2186e-02, -2.4963e-02,  ..., -2.9419e-02,\n",
       "                        8.9417e-03, -1.3763e-02],\n",
       "                      ...,\n",
       "                      [-5.5962e-03, -1.7872e-03, -1.5686e-02,  ..., -3.4103e-03,\n",
       "                       -2.2173e-05,  1.5748e-04],\n",
       "                      [-9.0179e-03,  7.1228e-05,  3.3832e-04,  ...,  8.5754e-03,\n",
       "                       -2.1271e-02, -4.8218e-02],\n",
       "                      [-1.2398e-02, -1.6083e-02,  8.1253e-03,  ..., -6.9008e-03,\n",
       "                        2.3880e-02, -2.6016e-03]], dtype=torch.float16)),\n",
       "             ('model.layers.30.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0263, -0.0076,  0.0055,  ...,  0.0115,  0.0197,  0.0022],\n",
       "                      [-0.0135,  0.0399, -0.0352,  ..., -0.0064, -0.0115, -0.0158],\n",
       "                      [-0.0017, -0.0394, -0.0027,  ...,  0.0264, -0.0094,  0.0419],\n",
       "                      ...,\n",
       "                      [ 0.0006, -0.0184, -0.0312,  ...,  0.0199,  0.0149,  0.0249],\n",
       "                      [ 0.0097, -0.0302,  0.0316,  ...,  0.0134,  0.0149, -0.0084],\n",
       "                      [-0.0089,  0.0083,  0.0102,  ...,  0.0182, -0.0004, -0.0328]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.30.self_attn.v_proj.weight',\n",
       "              tensor([[ 2.4200e-02, -1.5839e-02,  3.1036e-02,  ...,  9.6989e-04,\n",
       "                       -2.3865e-02, -5.0392e-03],\n",
       "                      [-6.3667e-03,  1.6327e-02,  7.6218e-03,  ..., -6.7444e-03,\n",
       "                       -7.3738e-03, -1.0704e-02],\n",
       "                      [-6.6719e-03, -9.4452e-03,  3.4161e-03,  ..., -8.9188e-03,\n",
       "                        2.4567e-02, -2.4462e-04],\n",
       "                      ...,\n",
       "                      [-3.8086e-02, -9.9869e-03, -9.1934e-03,  ..., -4.9438e-02,\n",
       "                       -7.9651e-03, -1.0742e-02],\n",
       "                      [ 3.5496e-03, -3.5309e-02,  5.8830e-05,  ...,  1.5879e-03,\n",
       "                        1.0735e-02,  2.2308e-02],\n",
       "                      [ 1.2192e-02, -1.4023e-02, -4.2152e-04,  ..., -2.9663e-02,\n",
       "                       -6.7596e-03,  1.3435e-02]], dtype=torch.float16)),\n",
       "             ('model.layers.30.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0044, -0.0174,  0.0281,  ..., -0.0068,  0.0059,  0.0246],\n",
       "                      [-0.0181, -0.0149,  0.0122,  ..., -0.0233,  0.0011, -0.0094],\n",
       "                      [ 0.0066, -0.0095,  0.0027,  ..., -0.0037,  0.0350,  0.0025],\n",
       "                      ...,\n",
       "                      [-0.0240,  0.0300, -0.0054,  ...,  0.0085, -0.0312,  0.0037],\n",
       "                      [ 0.0407,  0.0016,  0.0090,  ..., -0.0144, -0.0304,  0.0690],\n",
       "                      [ 0.0058, -0.0013,  0.0287,  ...,  0.0190, -0.0003,  0.0043]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.30.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0394,  0.0045, -0.0051,  ...,  0.0023,  0.0115,  0.0238],\n",
       "                      [-0.0022,  0.0068,  0.0287,  ..., -0.0208, -0.0257,  0.0147],\n",
       "                      [ 0.0180, -0.0006, -0.0130,  ..., -0.0116,  0.0027, -0.0267],\n",
       "                      ...,\n",
       "                      [ 0.0149,  0.0169,  0.0167,  ..., -0.0096, -0.0126, -0.0313],\n",
       "                      [-0.0026,  0.0057, -0.0357,  ...,  0.0054, -0.0108, -0.0236],\n",
       "                      [-0.0259, -0.0036, -0.0138,  ...,  0.0115,  0.0218,  0.0003]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.30.mlp.up_proj.weight',\n",
       "              tensor([[-0.0094,  0.0356,  0.0044,  ..., -0.0186,  0.0347,  0.0353],\n",
       "                      [-0.0125, -0.0388,  0.0182,  ..., -0.0215, -0.0006, -0.0024],\n",
       "                      [-0.0267,  0.0078, -0.0414,  ...,  0.0254, -0.0201, -0.0109],\n",
       "                      ...,\n",
       "                      [-0.0080,  0.0378,  0.0394,  ...,  0.0052,  0.0276,  0.0018],\n",
       "                      [-0.0400, -0.0048, -0.0315,  ..., -0.0061, -0.0140,  0.0147],\n",
       "                      [-0.0230, -0.0119, -0.0046,  ...,  0.0142, -0.0070,  0.0020]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.30.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0290,  0.0202, -0.0200,  ...,  0.0190,  0.0095, -0.0305],\n",
       "                      [ 0.0144,  0.0008, -0.0047,  ..., -0.0107,  0.0299, -0.0129],\n",
       "                      [-0.0248, -0.0361, -0.0053,  ...,  0.0049,  0.0032, -0.0299],\n",
       "                      ...,\n",
       "                      [-0.0070, -0.0140,  0.0299,  ...,  0.0041, -0.0140, -0.0156],\n",
       "                      [ 0.0032,  0.0233,  0.0185,  ...,  0.0165, -0.0142,  0.0220],\n",
       "                      [ 0.0071,  0.0024,  0.0006,  ..., -0.0231,  0.0246,  0.0264]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.30.input_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.30.post_attention_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.31.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0238,  0.0186, -0.0022,  ...,  0.0047,  0.0322,  0.0206],\n",
       "                      [-0.0088, -0.0016,  0.0439,  ..., -0.0098,  0.0323, -0.0125],\n",
       "                      [ 0.0077, -0.0260, -0.0069,  ..., -0.0164, -0.0280,  0.0195],\n",
       "                      ...,\n",
       "                      [-0.0067, -0.0109, -0.0125,  ...,  0.0041, -0.0284,  0.0083],\n",
       "                      [-0.0187, -0.0433,  0.0041,  ...,  0.0124, -0.0177, -0.0111],\n",
       "                      [ 0.0356,  0.0096, -0.0271,  ...,  0.0123,  0.0115, -0.0090]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.31.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0073, -0.0185, -0.0058,  ...,  0.0035,  0.0115, -0.0126],\n",
       "                      [-0.0025,  0.0033, -0.0034,  ...,  0.0138, -0.0034,  0.0287],\n",
       "                      [-0.0103,  0.0023,  0.0188,  ..., -0.0061,  0.0231,  0.0011],\n",
       "                      ...,\n",
       "                      [ 0.0033, -0.0135,  0.0108,  ...,  0.0090, -0.0181, -0.0129],\n",
       "                      [ 0.0103,  0.0223, -0.0207,  ...,  0.0150,  0.0303,  0.0001],\n",
       "                      [ 0.0405,  0.0057,  0.0259,  ...,  0.0079, -0.0144, -0.0153]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.31.self_attn.v_proj.weight',\n",
       "              tensor([[ 0.0086,  0.0110,  0.0013,  ...,  0.0122, -0.0011, -0.0262],\n",
       "                      [ 0.0044, -0.0160, -0.0017,  ...,  0.0333,  0.0082, -0.0084],\n",
       "                      [-0.0138,  0.0253,  0.0285,  ...,  0.0087,  0.0293,  0.0033],\n",
       "                      ...,\n",
       "                      [-0.0055,  0.0122, -0.0119,  ...,  0.0083,  0.0422, -0.0135],\n",
       "                      [ 0.0376, -0.0078,  0.0089,  ...,  0.0043, -0.0302, -0.0431],\n",
       "                      [ 0.0003,  0.0271, -0.0028,  ..., -0.0064, -0.0099,  0.0011]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.31.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0022, -0.0009, -0.0050,  ..., -0.0526,  0.0018, -0.0054],\n",
       "                      [-0.0098, -0.0082,  0.0120,  ..., -0.0019, -0.0184, -0.0164],\n",
       "                      [-0.0016,  0.0309, -0.0074,  ...,  0.0002,  0.0025,  0.0213],\n",
       "                      ...,\n",
       "                      [ 0.0085, -0.0195,  0.0023,  ...,  0.0060, -0.0056,  0.0489],\n",
       "                      [ 0.0159,  0.0114, -0.0066,  ...,  0.0033, -0.0143, -0.0183],\n",
       "                      [ 0.0200, -0.0296, -0.0373,  ...,  0.0297, -0.0089,  0.0263]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.31.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0479,  0.0085, -0.0487,  ..., -0.0004,  0.0283, -0.0231],\n",
       "                      [ 0.0136,  0.0107, -0.0059,  ..., -0.0041,  0.0075, -0.0200],\n",
       "                      [-0.0161,  0.0028, -0.0105,  ..., -0.0183, -0.0127, -0.0333],\n",
       "                      ...,\n",
       "                      [-0.0244, -0.0423, -0.0024,  ...,  0.0134,  0.0176,  0.0218],\n",
       "                      [ 0.0061, -0.0220,  0.0204,  ..., -0.0035,  0.0174, -0.0236],\n",
       "                      [-0.0289, -0.0373,  0.0307,  ...,  0.0238, -0.0202, -0.0006]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('model.layers.31.mlp.up_proj.weight',\n",
       "              tensor([[ 6.5117e-03, -2.2049e-02,  7.9498e-03,  ...,  9.7656e-03,\n",
       "                       -2.0294e-02,  2.2568e-02],\n",
       "                      [-2.5497e-02, -2.2373e-03,  1.4664e-02,  ..., -1.9989e-02,\n",
       "                        1.4938e-02,  2.5558e-02],\n",
       "                      [ 4.2145e-02, -2.7527e-02,  3.1525e-02,  ..., -4.6082e-03,\n",
       "                        6.3210e-03, -2.5528e-02],\n",
       "                      ...,\n",
       "                      [ 1.2550e-02,  8.8882e-03,  8.8425e-03,  ...,  1.7672e-03,\n",
       "                        2.6718e-02, -2.0444e-05],\n",
       "                      [-4.9194e-02,  1.5724e-04, -2.2736e-02,  ...,  2.3794e-04,\n",
       "                       -7.4883e-03, -1.5945e-02],\n",
       "                      [-3.2196e-02,  1.5732e-02, -6.1607e-03,  ..., -1.5266e-02,\n",
       "                       -1.1559e-02,  8.1635e-03]], dtype=torch.float16)),\n",
       "             ('model.layers.31.mlp.down_proj.weight',\n",
       "              tensor([[-9.1934e-03, -5.6267e-03,  3.0823e-02,  ...,  1.0262e-02,\n",
       "                        7.4272e-03, -1.0712e-02],\n",
       "                      [-1.4412e-02, -1.0887e-02,  1.5961e-02,  ..., -2.6855e-02,\n",
       "                       -4.1699e-04, -1.4122e-02],\n",
       "                      [ 2.2335e-03,  1.7807e-02, -9.7046e-03,  ...,  8.7204e-03,\n",
       "                       -1.6083e-02, -3.8513e-02],\n",
       "                      ...,\n",
       "                      [ 3.4809e-05, -2.7561e-03,  1.1230e-02,  ...,  5.4131e-03,\n",
       "                       -1.0689e-02,  4.3457e-02],\n",
       "                      [ 9.0103e-03,  2.8610e-03, -4.7913e-02,  ..., -4.0627e-03,\n",
       "                       -1.4366e-02, -2.0691e-02],\n",
       "                      [-1.6432e-03,  1.3123e-03,  2.1973e-02,  ...,  4.2610e-03,\n",
       "                       -3.4210e-02, -4.3427e-02]], dtype=torch.float16)),\n",
       "             ('model.layers.31.input_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.layers.31.post_attention_layernorm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('model.norm.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16)),\n",
       "             ('score.weight',\n",
       "              tensor([[ 0.0042, -0.0746,  0.0076,  ...,  0.2032, -0.0682,  0.1083],\n",
       "                      [ 0.0047,  0.0925,  0.0011,  ..., -0.1783,  0.0707, -0.1166]],\n",
       "                     dtype=torch.float16)),\n",
       "             ('score.bias', tensor([-0.1549,  0.1587], dtype=torch.float16))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime, date\n",
    "model_name = \"llama3_8b\"\n",
    "today = date.today().isoformat()\n",
    "\n",
    "\n",
    "loaded_state_dict = torch.load(f\"/home/it/environments/Genety/models/{model_name}/{today}_{model_name}.pth\", mmap=True)\n",
    "loaded_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f3e760a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(loaded_state_dict, assign=True, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3986d67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, f\"./models/{model_name}/{today}_{model_name}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd720bcc-1588-4703-8cb0-e34e0542e161",
   "metadata": {},
   "source": [
    "# Hyperparameter tunning with Ray Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "157810c7-48ef-420a-899f-300e4303765c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Disable Out-Of-Memory prevention for troubleshooting\n",
    "os.environ[\"RAY_memory_monitor_refresh_ms\"] = \"0\"\n",
    "os.environ[\"RAY_memory_usage_threshold\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f23a42cf-c7ae-462a-970e-f174620ba6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime, date\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import ray\n",
    "import ray.train.torch\n",
    "\n",
    "from ray import train, tune\n",
    "from ray.train import RunConfig, ScalingConfig, Checkpoint\n",
    "from ray.train.torch import TorchTrainer\n",
    "\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "# DeepSpeed ZeRO-3 and Ray Train\n",
    "import deepspeed\n",
    "from deepspeed.accelerator import get_accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8f5f1d9-eeef-4d53-b3a9-abfac4069485",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-14 11:09:54,300\tINFO worker.py:1740 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.train.torch.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3581cd39-907b-47e6-9b6c-15fe6a0a41bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# function passed to the DataLoader to process a batch of data as indicated\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def collate_batch(batch):\n",
    "    # Get label and text\n",
    "    y, x = list(zip(*batch))\n",
    "\n",
    "    # Create list with indices from tokeniser\n",
    "    encoded_x = tokenizer(x, padding=True, truncation=True)\n",
    "    encoded_x.input_ids = torch.tensor(encoded_x.input_ids)\n",
    "    encoded_x.attention_mask = torch.tensor(encoded_x.attention_mask)\n",
    "    \n",
    "    # Prepare the labels, by subtracting 1 to get them in the range 0-3\n",
    "    return encoded_x, torch.tensor(y, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2462286c-9bbe-4c11-826e-89274c4eeeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func(model, optimizer, train_loader, max_norm, device):  \n",
    "    model.train()\n",
    "    \n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 5\n",
    "    start_time = time.time()\n",
    "    total_loss = 0\n",
    "\n",
    "    for idx, (encoded_x, label) in enumerate(train_loader):           \n",
    "        label = label.to(device)\n",
    "        \n",
    "        \n",
    "        encoded_x.input_ids = encoded_x.input_ids.to(device)\n",
    "        encoded_x.attention_mask = encoded_x.attention_mask.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(input_ids=encoded_x.input_ids, attention_mask=encoded_x.attention_mask)\n",
    "        predicted_label = outputs.logits\n",
    "        loss = criterion(predicted_label, label)\n",
    "        \n",
    "        # Deepspeed model engine, backward pass \n",
    "        model.backward(loss)\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n",
    "        \n",
    "        # Deepspeed model engine, optimizer step\n",
    "        model.step()\n",
    "        \n",
    "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Deepspeed model engine, empty cache\n",
    "        model.empty_partition_cache()\n",
    "         \n",
    "    return total_acc / total_count, total_loss / total_count\n",
    "        \n",
    "\n",
    "def eval_func(model, data_loader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (encoded_x, label) in enumerate(data_loader):\n",
    "            label = label.to(device)\n",
    "            \n",
    "            encoded_x.input_ids = encoded_x.input_ids.to(device)\n",
    "            encoded_x.attention_mask = encoded_x.attention_mask.to(device)\n",
    "            \n",
    "            outputs = model(input_ids=encoded_x.input_ids, attention_mask=encoded_x.attention_mask)\n",
    "            predicted_label = outputs.logits\n",
    "            loss = criterion(predicted_label, label)\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "\n",
    "    return total_acc / total_count, loss.item() / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f8810fde-88ac-4e0b-8e77-1fc0633957ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    with deepspeed.zero.Init():\n",
    "        model = torch.hub.load(\n",
    "            \"huggingface/pytorch-transformers\",\n",
    "            \"modelForSequenceClassification\",\n",
    "            # \"meta-llama/Llama-2-7b-hf\",\n",
    "            \"meta-llama/Meta-Llama-3-8B\",\n",
    "            ignore_mismatched_sizes=True\n",
    "        )\n",
    "\n",
    "    for i, parameter in enumerate(model.parameters()):\n",
    "        parameter.requires_grad = False\n",
    "\n",
    "    model.score = nn.Linear(in_features=4096, out_features=2)\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "71b4f2b1-195e-4353-a1a3-e9606c031051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "today = date.today().isoformat()\n",
    "model_name = \"llama3_8b\"\n",
    "checkpoint_path = f\"./models/{model_name}\"\n",
    "num_class = 2\n",
    "\n",
    "def train_search(config):\n",
    "    print(\"Starting train_search\")\n",
    "    \n",
    "    # print(device)\n",
    "    # print(config)\n",
    "    # config_params = config[\"params\"]\n",
    "    config_params = config\n",
    "    # print(config_params)\n",
    "\n",
    "    print(\" Before create_model\")\n",
    "    model = create_model()\n",
    "    print(\"Model after create_model\")\n",
    "    \n",
    "    train_iter = iter(list(train_df.itertuples(index=False, name=None)))\n",
    "    test_iter = iter(list(test_df.itertuples(index=False, name=None)))\n",
    "    train_dataset = to_map_style_dataset(train_iter)\n",
    "    test_dataset = to_map_style_dataset(test_iter)\n",
    "    num_train = int(len(train_dataset) * 0.8)\n",
    "    split_train_, split_valid_ = random_split(\n",
    "        train_dataset, [num_train, len(train_dataset) - num_train]\n",
    "    )\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        split_train_, batch_size=config_params[\"batch_size\"], shuffle=True, collate_fn=collate_batch\n",
    "    )\n",
    "    valid_dataloader = DataLoader(\n",
    "        split_valid_, batch_size=config_params[\"batch_size\"], shuffle=True, collate_fn=collate_batch\n",
    "    )\n",
    "    test_dataloader = DataLoader(\n",
    "        test_dataset, batch_size=config_params[\"batch_size\"], shuffle=True, collate_fn=collate_batch\n",
    "    )\n",
    "    \n",
    "    deepspeed_config = {\n",
    "        \"optimizer\": {\n",
    "            \"type\": \"Adam\",\n",
    "            \"params\": {\n",
    "                \"lr\": 0.01,\n",
    "                \"betas\": [\n",
    "                    0.8,\n",
    "                    0.999\n",
    "                ],\n",
    "                \"eps\": 1e-8,\n",
    "                \"weight_decay\": 3e-7,\n",
    "            },\n",
    "        },\n",
    "        \"scheduler\": {\n",
    "            \"type\": \"WarmupLR\",\n",
    "            \"params\": {\n",
    "                \"warmup_min_lr\": 0,\n",
    "                \"warmup_max_lr\": 0.01,\n",
    "                \"warmup_num_steps\": 1000,\n",
    "            },\n",
    "        },\n",
    "        \"train_batch_size\": 16,\n",
    "        # \"train_micro_batch_size_per_gpu\": \"auto\",\n",
    "        # \"gradient_accumulation_steps\": \"auto\",\n",
    "        \"fp16\": {\"enabled\": True},\n",
    "        \"zero_optimization\": {\n",
    "            \"stage\": 3,\n",
    "            \"offload_optimizer\": {\n",
    "                \"device\": \"cpu\",\n",
    "            },\n",
    "            \"offload_param\": {\n",
    "                \"device\": \"cpu\",\n",
    "            },\n",
    "            \"allgather_partitions\": True,\n",
    "            \"allgather_bucket_size\": 2e8,\n",
    "            \"reduce_scatter\": True,\n",
    "            \"reduce_bucket_size\": 2e8,\n",
    "            \"overlap_comm\": True,\n",
    "            \"load_from_fp32_weights\": True,\n",
    "            \"gather_16bit_weights_on_model_save\": True,\n",
    "            \"contiguous_gradients\": True,\n",
    "            \"stage3_prefetch_bucket_size\": 0,\n",
    "        },\n",
    "        \"gradient_accumulation_steps\": 1,\n",
    "        \"train_batch_size\": 16,\n",
    "    }\n",
    "    \n",
    "    print(\"Before initializing deepspeed\")\n",
    "    \n",
    "    \n",
    "    # Initialize DeepSpeed Engine\n",
    "    model, optimizer, _, lr_scheduler = deepspeed.initialize(\n",
    "        model=model,\n",
    "        model_parameters=model.parameters(),\n",
    "        config=deepspeed_config,\n",
    "    )\n",
    "    device = get_accelerator().device_name(model.local_rank)\n",
    "    print(f\"deepspeed accelerator device: {device}\")\n",
    "    \n",
    "    best_accu_val = 0.85\n",
    "    for epoch in range(1, config_params[\"epochs\"] + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        accu_train, loss_train = train_func(model, optimizer, train_dataloader, config_params[\"max_norm\"], device)\n",
    "        accu_val, loss_val = eval_func(model, valid_dataloader, device)\n",
    "        \n",
    "            \n",
    "        # Report checkpoint and metrics to Ray Train\n",
    "        # ==============================================================\n",
    "        with tempfile.TemporaryDirectory() as tmpdir:\n",
    "            # Each worker saves its own checkpoint shard\n",
    "            if accu_val > best_accu_val:\n",
    "                model.save_checkpoint(tmpdir)\n",
    "                checkpoint = Checkpoint.from_directory(tmpdir)\n",
    "                best_accu_val = accu_val\n",
    "\n",
    "            # Ensure all workers finished saving their checkpoint shard\n",
    "            torch.distributed.barrier()\n",
    "\n",
    "            # Report checkpoint shards from each worker in parallel\n",
    "            ray.train.report(\n",
    "                metrics={\n",
    "                    # \"loss_train\": loss_train,\n",
    "                    # \"loss_val\": loss_val,\n",
    "                    \"accuracy_train\": accu_train,\n",
    "                    \"accuracy_val\": accu_val,\n",
    "                }, checkpoint=checkpoint\n",
    "            )\n",
    "        # ==============================================================\n",
    "        \n",
    "        get_accelerator().empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff94e22f-708e-4874-8ffa-b5a471199d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "model = None\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "get_accelerator().empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "002dec85-93b1-4623-a41b-dd99f912a9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free(GB): 8.82586669921875, Global(GB): 23.64971923828125, Free(%): 0.373191182960537\n"
     ]
    }
   ],
   "source": [
    "(free_memory, global_memory) = torch.cuda.mem_get_info()\n",
    "print(f\"Free(GB): {free_memory/1024/1024/1024}, Global(GB): {global_memory/1024/1024/1024}, Free(%): {free_memory/global_memory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf3ece80-fb27-46de-b624-9f4a5e513461",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-05-14 11:21:33</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:02.75        </td></tr>\n",
       "<tr><td>Memory:      </td><td>4.2/30.6 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 64.000: None | Iter 16.000: None | Iter 4.000: None | Iter 1.000: None<br>Logical resource usage: 12.0/16 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  \n",
       "  Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                                       </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_search_ad89ada5</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-05-14_11-09-52_807062_39219/artifacts/2024-05-14_11-21-30/llama3_8b/driver_artifacts/train_search_ad89ada5_1_batch_size=16,epochs=3,lr=0.3990,max_norm=0.2118_2024-05-14_11-21-30/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">      lr</th><th style=\"text-align: right;\">  max_norm</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_search_ad89ada5</td><td>ERROR   </td><td>10.1.1.204:40434</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">       3</td><td style=\"text-align: right;\">0.399008</td><td style=\"text-align: right;\">  0.211838</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(pid=40434) [2024-05-14 11:21:32,667] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "(pid=40434)  [WARNING]  async_io requires the dev libaio .so object and headers but these were not found.\n",
      "(pid=40434)  [WARNING]  If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
      "(pid=40434)  [WARNING]  Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
      "(pid=40434)  [WARNING]  sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3\n",
      "(pid=40434)  [WARNING]  using untested triton version (2.3.0), only 1.0.0 is known to be compatible\n",
      "(train_search pid=40434) Starting train_search\n",
      "(train_search pid=40434)  Before create_model\n",
      "(train_search pid=40434) [2024-05-14 11:21:33,253] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "(train_search pid=40434) [2024-05-14 11:21:33,253] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(pid=40434) /home/it/anaconda3/envs/genety/lib/python3.11/site-packages/torchtext/data/__init__.py:4: UserWarning: \n",
      "(pid=40434) /!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "(pid=40434) Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "(pid=40434)   warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train_search pid=40434) [2024-05-14 11:21:33,330] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=10.1.1.204, master_port=29500\n",
      "(train_search pid=40434) [2024-05-14 11:21:33,330] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train_search pid=40434) [W socket.cpp:464] [c10d] The server socket has failed to bind to [::]:29500 (errno: 98 - Address already in use).\n",
      "(train_search pid=40434) [W socket.cpp:464] [c10d] The server socket has failed to bind to 0.0.0.0:29500 (errno: 98 - Address already in use).\n",
      "(train_search pid=40434) [E socket.cpp:500] [c10d] The server socket has failed to listen on any local network address.\n",
      "2024-05-14 11:21:33,456\tERROR tune_controller.py:1331 -- Trial task failed for trial train_search_ad89ada5\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/it/anaconda3/envs/genety/lib/python3.11/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/it/anaconda3/envs/genety/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/it/anaconda3/envs/genety/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/it/anaconda3/envs/genety/lib/python3.11/site-packages/ray/_private/worker.py\", line 2623, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/it/anaconda3/envs/genety/lib/python3.11/site-packages/ray/_private/worker.py\", line 861, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(DistNetworkError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=40434, ip=10.1.1.204, actor_id=89e906be64b9bf0e195f45c401000000, repr=train_search)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/it/anaconda3/envs/genety/lib/python3.11/site-packages/ray/tune/trainable/trainable.py\", line 330, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/it/anaconda3/envs/genety/lib/python3.11/site-packages/ray/air/_internal/util.py\", line 98, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/it/anaconda3/envs/genety/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/it/anaconda3/envs/genety/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 253, in _trainable_func\n",
      "    output = fn()\n",
      "             ^^^^\n",
      "  File \"/tmp/ipykernel_39219/3323780950.py\", line 19, in train_search\n",
      "  File \"/tmp/ipykernel_39219/2492189394.py\", line 2, in create_model\n",
      "  File \"/home/it/anaconda3/envs/genety/lib/python3.11/site-packages/deepspeed/runtime/zero/partition_parameters.py\", line 923, in __init__\n",
      "    init_distributed()\n",
      "  File \"/home/it/anaconda3/envs/genety/lib/python3.11/site-packages/deepspeed/comm/comm.py\", line 670, in init_distributed\n",
      "    cdb = TorchBackend(dist_backend, timeout, init_method, rank, world_size)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/it/anaconda3/envs/genety/lib/python3.11/site-packages/deepspeed/comm/torch.py\", line 112, in __init__\n",
      "    self.init_process_group(backend, timeout, init_method, rank, world_size)\n",
      "  File \"/home/it/anaconda3/envs/genety/lib/python3.11/site-packages/deepspeed/comm/torch.py\", line 142, in init_process_group\n",
      "    torch.distributed.init_process_group(backend,\n",
      "  File \"/home/it/anaconda3/envs/genety/lib/python3.11/site-packages/torch/distributed/c10d_logger.py\", line 75, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/it/anaconda3/envs/genety/lib/python3.11/site-packages/torch/distributed/c10d_logger.py\", line 89, in wrapper\n",
      "    func_return = func(*args, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/it/anaconda3/envs/genety/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py\", line 1305, in init_process_group\n",
      "    store, rank, world_size = next(rendezvous_iterator)\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/it/anaconda3/envs/genety/lib/python3.11/site-packages/torch/distributed/rendezvous.py\", line 246, in _env_rendezvous_handler\n",
      "    store = _create_c10d_store(master_addr, master_port, rank, world_size, timeout, use_libuv)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/it/anaconda3/envs/genety/lib/python3.11/site-packages/torch/distributed/rendezvous.py\", line 174, in _create_c10d_store\n",
      "    return TCPStore(\n",
      "           ^^^^^^^^^\n",
      "torch.distributed.DistNetworkError: The server socket has failed to listen on any local network address. The server socket has failed to bind to [::]:29500 (errno: 98 - Address already in use). The server socket has failed to bind to 0.0.0.0:29500 (errno: 98 - Address already in use).\n",
      "2024-05-14 11:21:33,469\tWARNING experiment_state.py:205 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n",
      "You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n",
      "You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n",
      "2024-05-14 11:21:33,469\tINFO tune.py:1004 -- Wrote the latest version of all result files and experiment state to '/home/it/ray_results/llama3_8b' in 0.0020s.\n",
      "2024-05-14 11:21:33,471\tERROR tune.py:1032 -- Trials did not complete: [train_search_ad89ada5]\n",
      "2024-05-14 11:21:33,471\tINFO tune.py:1036 -- Total run time: 3.00 seconds (2.75 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from hyperopt import hp\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "\n",
    "exp_name = model_name\n",
    "\n",
    "space = {\n",
    "    \"lr\": hp.loguniform(\"lr\", -3, 1),\n",
    "    # \"momentum\": hp.uniform(\"momentum\", 0.1, 0.9),\n",
    "    \"epochs\": hp.choice(\"epochs\", [3]),\n",
    "    \"batch_size\": hp.choice(\"batch_size\", [16]),\n",
    "    # \"step_size\": hp.randint(\"step_size\", 1, 10),\n",
    "    # \"lr_gamma\": hp.uniform(\"lr_gamma\", 0.1, 0.9),\n",
    "    \"max_norm\": hp.uniform(\"max_norm\", 0.1, 0.9),\n",
    "}\n",
    "\n",
    "hyperopt_search = HyperOptSearch(space, metric=\"accuracy_val\", mode=\"max\")\n",
    "\n",
    "# Uncomment this to enable distributed execution\n",
    "# `ray.init(address=\"auto\")`\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    tune.with_resources(train_search, resources={\"cpu\":12, \"gpu\":1}),\n",
    "    tune_config=tune.TuneConfig(\n",
    "        num_samples=1,\n",
    "        scheduler=ASHAScheduler(metric=\"accuracy_val\", mode=\"max\"), # Early stopping\n",
    "        search_alg=hyperopt_search, # Hyperopt library for Hyper-parameter Optimization\n",
    "    ),\n",
    "    run_config=train.RunConfig(\n",
    "        name=exp_name,\n",
    "        checkpoint_config=train.CheckpointConfig(\n",
    "            checkpoint_score_attribute=\"accuracy_val\",\n",
    "            num_to_keep=2,\n",
    "            # checkpoint_at_end=True\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "results = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1f459c-0d45-4b76-85cc-fc6780bb98e6",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfs = {result.path: result.metrics_dataframe for result in results}\n",
    "[d[\"accuracy_val\"].plot() for d in dfs.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9a0807-46fa-48e8-96cd-024558a6d73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = results.get_best_result(\"accuracy_val\", \"max\")\n",
    "best_result.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025ebf6d-d166-44bb-881a-55a7ebb5ba57",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result.metrics_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cf4249-46dc-4434-859e-24e6ee4ac0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = best_result.metrics_dataframe\n",
    "\n",
    "plt.plot(df['accuracy_train'], label='accuracy_train')\n",
    "plt.plot(df['accuracy_val'], label='accuracy_val')\n",
    "\n",
    "plt.legend(title='')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe08344-b99f-48ee-83f9-fcf22cadc2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_checkpoints = best_result.best_checkpoints\n",
    "best_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf736eaa-1cc4-4e15-9e91-70e0e3a9b630",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_checkpoint = best_result.get_best_checkpoint(\"accuracy_val\", mode=\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c319be6-c68a-45f8-bc9c-67af80fbc633",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(x for x in best_checkpoints if x[0].path == best_checkpoint.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9e022e-1dbc-44f7-9967-dd6ac53a88f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(os.path.join(best_checkpoint.path, \"model.pth\"))\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a88df47-2bb2-408d-b902-c65b15114d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "uq_path = today + \"_\" + \"_\".join(best_result.path.split(\"=\")[0].split(\"/\")[-2:])\n",
    "save_path = os.path.join(f'./models/{model_name}', uq_path + \"_model.pt\")\n",
    "torch.save(model, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b083c09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Genety (conda)",
   "language": "python",
   "name": "genety-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
