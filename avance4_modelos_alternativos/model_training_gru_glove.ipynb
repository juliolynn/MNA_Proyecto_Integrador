{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "682cc4d4-ebb1-4e48-b84e-1e62006da233",
   "metadata": {},
   "source": [
    "# Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61331a7-f1dd-442e-b58a-a5adb337fec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873ec5c8-c16a-4697-86b5-e22292d3266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd5b450-0317-4c55-847e-7723042940f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c439d2-2280-4823-90dd-0867012b907c",
   "metadata": {},
   "source": [
    "# Load Excel File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a715f751-ab65-45a3-ae17-c795b8c78d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "master_df = pd.read_excel('./DATASETS/Training_Dataset.xlsx')\n",
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bdf637-9e84-4cee-a95c-e5c7bd8075d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = master_df[['E1','Text']].copy()\n",
    "model_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9296d035-a173-4c8e-81d9-a30a5021dcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c738bf70-5be7-4b1e-9d88-1e09f2f497a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df_label1 = model_df.query('E1 == 1')\n",
    "len(model_df_label1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a967f2ce-ce0f-4aa7-8b6e-759011eef775",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df_label0 = model_df.query('E1 == 0')\n",
    "len(model_df_label0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fceb9f5-cd13-4779-b8db-57ff9cda386f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = pd.concat([model_df_label1[:1500],model_df_label0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea7716b-cbb9-40df-8796-9e2718512f6b",
   "metadata": {},
   "source": [
    "# Data process and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e0084e-559e-46cc-b1a4-892e5e0fcb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection  import train_test_split\n",
    "train_df, test_df = train_test_split(model_df, test_size=0.1, shuffle=True)\n",
    "\n",
    "train_iter = iter(list(train_df.itertuples(index=False, name=None)))\n",
    "test_iter = iter(list(test_df.itertuples(index=False, name=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6daca09-ad60-40b6-90f2-e91c79aabb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7507ae81-cc24-4192-af5f-4126d6b059be",
   "metadata": {},
   "source": [
    "## Pre-trained embeddings GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dae2f6d-c342-4458-b2af-2400f3ead818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for _, text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d494a-23f1-4dbb-8514-a1ba31229bb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !wget http://nlp.stanford.edu/data/glove.6B.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954c3275-96df-486e-ba68-de4ab08604bb",
   "metadata": {},
   "source": [
    "2024-04-12 10:22:30 (4.53 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
    "\n",
    "2024-04-12 12:03:44 (3.88 MB/s) - ‘glove.42B.300d.zip’ saved [1877800501/1877800501]\n",
    "\n",
    "2024-04-12 12:12:06 (4.40 MB/s) - ‘glove.840B.300d.zip’ saved [2176768927/2176768927]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e87ca72-6599-4b5d-8e3f-1657d3660615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip -d glove glove.6B.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74488172-81a6-4bbc-93d2-b12b7610598f",
   "metadata": {},
   "source": [
    "Archive:  glove.6B.zip\n",
    "  inflating: glove/glove.6B.50d.txt  \n",
    "  inflating: glove/glove.6B.100d.txt  \n",
    "  inflating: glove/glove.6B.200d.txt  \n",
    "  inflating: glove/glove.6B.300d.txt  \n",
    "  \n",
    "Archive:  glove.42B.300d.zip\n",
    "  inflating: glove/glove.42B.300d.txt \n",
    "  \n",
    "Archive:  glove.840B.300d.zip\n",
    "  inflating: glove/glove.840B.300d.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda6ab00-e97c-454f-b593-14d6d3662cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOVE_NAME = \"840B\"\n",
    "# GLOVE_NAME = \"42B\"\n",
    "GLOVE_NAME = \"6B\"\n",
    "\n",
    "GLOVE_DIM = 100\n",
    "# GLOVE_DIM = 300\n",
    "\n",
    "def load_embs_npa(glove_name=GLOVE_NAME, glove_dim=GLOVE_DIM):\n",
    "    # Read embeddings from pre-downloaded file.\n",
    "    embeddings = []\n",
    "    \n",
    "    with open(f'/home/it/environments/Genety/glove/glove.{glove_name}.{glove_dim}d.txt','rt') as fi:\n",
    "        full_content = fi.read().strip().split('\\n')\n",
    "    for i in range(len(full_content)):\n",
    "        i_word = full_content[i].split(' ')[0]\n",
    "        i_embeddings = [float(val) for val in full_content[i].split(' ')[1:]]\n",
    "        embeddings.append(i_embeddings)\n",
    "    \n",
    "    # Convert tu numpy\n",
    "    embs_npa = np.array(embeddings)\n",
    "    \n",
    "    pad_emb_npa = np.zeros((1,embs_npa.shape[1]))   #embedding for '<pad>' token.\n",
    "    unk_emb_npa = np.mean(embs_npa,axis=0,keepdims=True)    #embedding for '<unk>' token.\n",
    "\n",
    "    #insert embeddings for pad and unk tokens at top of embs_npa.\n",
    "    embs_npa = np.vstack((pad_emb_npa,unk_emb_npa,embs_npa))\n",
    "    \n",
    "    return embs_npa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8d3a28-9b82-4b7a-ba6c-bf181784234d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_npa = load_embs_npa()\n",
    "print(embs_npa.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24d1986-12ed-45c3-8a18-bd1ada1e9440",
   "metadata": {},
   "source": [
    "# Dataset iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880ea8d4-bae1-48bc-996e-d352db324265",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = iter(list(train_df.itertuples(index=False, name=None)))\n",
    "test_iter = iter(list(test_df.itertuples(index=False, name=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c4e14f-9c36-4343-ba96-f05c6eb3196e",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d1a15f-3229-4b0b-abde-6f7e341d6d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_tensor(x, max_len):\n",
    "    padded = torch.zeros(max_len, GLOVE_DIM)\n",
    "    \n",
    "    if len(x) > max_len: padded[:] = x[:max_len]\n",
    "    else: padded[:len(x)] = x\n",
    "        \n",
    "    return padded\n",
    "\n",
    "def pad_sequences(x, max_len):\n",
    "    padded = np.zeros((max_len), dtype=np.int64)\n",
    "    \n",
    "    if len(x) > max_len: padded[:] = x[:max_len]\n",
    "    else: padded[:len(x)] = x\n",
    "        \n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4db3a0-073b-4553-b627-ed94516c0b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "label_pipeline = lambda x: int(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092203c5-49af-4337-abbd-38851caa6e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "MAX_LENGTH = 100\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list = [], []\n",
    "    for _label, _text in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = text_pipeline(_text)\n",
    "        padded = pad_sequences(processed_text, MAX_LENGTH)\n",
    "        text_list.append(padded)\n",
    "        \n",
    "    label_list = torch.tensor(np.array(label_list), dtype=torch.int64)\n",
    "    text_list = torch.tensor(np.array(text_list), dtype=torch.long)\n",
    "    return label_list.to(device), text_list.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a81c8d9-de06-4aed-9ff3-0c5f31985d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = iter(list(train_df.itertuples(index=False, name=None)))\n",
    "first = next(train_iter)\n",
    "second = next(train_iter)\n",
    "\n",
    "print(first)\n",
    "print(second)\n",
    "\n",
    "label, text = collate_batch([first, second])\n",
    "\n",
    "print(label)\n",
    "print(label.shape)\n",
    "print(text)\n",
    "print(text.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf18db8-7d58-43c0-ac22-d3e225cb2ed1",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d306ecb-d8ef-4389-ab6c-8fb803124ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_Model(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden, layers, num_classes, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embs_npa = load_embs_npa()\n",
    "        \n",
    "        self.embedding_layer = nn.Embedding.from_pretrained(torch.from_numpy(self.embs_npa).float())\n",
    "        \n",
    "        self.rnn = nn.GRU(input_size= embed_size,\n",
    "                            hidden_size=hidden,\n",
    "                            num_layers=layers,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=True, \n",
    "                            dropout=dropout\n",
    "                           )\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc = nn.Linear(in_features=hidden*2, out_features=num_classes) # Double the size of hidden neurons to account for the reverse pass\n",
    "        nn.init.kaiming_normal_(self.fc.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding_layer(x)\n",
    "        y, h = self.rnn(embedded)\n",
    "        y = self.dropout(y)\n",
    "        return self.fc(y[:,-1]) # Only use output for last timestep. The reason is because this is a classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6724c0-3768-48ee-9176-2518cabbfe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = len(set([label for (label, text) in train_iter]))\n",
    "num_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e98c25-1d44-4a02-997c-8ec0c4e123c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = iter(list(train_df.itertuples(index=False, name=None)))\n",
    "num_class = len(set([label for (label, text) in train_iter]))\n",
    "vocab_size = len(vocab)\n",
    "emsize = GLOVE_DIM\n",
    "hidden_size = 100\n",
    "num_layers = 5\n",
    "dropout = 0.1\n",
    "model = GRU_Model(vocab_size, emsize, hidden_size, num_layers, num_class, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8afdced-aa5f-4dae-9ef0-7183668838d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1421e4-51bc-490c-b47d-01d83e0a28cf",
   "metadata": {},
   "source": [
    "# Train and eval functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a28ea92-68d0-44a7-9a5d-313ee209533f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, date\n",
    "import time\n",
    "\n",
    "def train(model, dataloader, epoch):\n",
    "    \n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 5\n",
    "    start_time = time.time()\n",
    "    total_loss = 0\n",
    "\n",
    "\n",
    "    for idx, (label, text) in enumerate(dataloader):         \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predicted_label = model(text)\n",
    "        loss = criterion(predicted_label, label)\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print(\n",
    "                \"| epoch {:3d} | {:5d}/{:5d} batches \"\n",
    "                \"| accuracy {:8.3f} | {}\".format(\n",
    "                    epoch, idx, len(dataloader), total_acc / total_count, datetime.now().isoformat()\n",
    "                )\n",
    "            )\n",
    "            start_time = time.time()\n",
    "        \n",
    "     \n",
    "        \n",
    "    return total_acc / total_count, total_loss / total_count\n",
    "        \n",
    "\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text) in enumerate(dataloader):      \n",
    "            predicted_label = model(text)\n",
    "            loss = criterion(predicted_label, label)\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "\n",
    "    return total_acc / total_count, loss.item() / total_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab0ddbc-f1e1-4662-a3d2-c09beafd25ed",
   "metadata": {},
   "source": [
    "# Split the dataset and run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8adb52-47f3-4740-952f-639d21a70d6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "\n",
    "BATCH_SIZE = 64  # batch size for training\n",
    "\n",
    "train_iter = iter(list(train_df.itertuples(index=False, name=None)))\n",
    "train_dataset = to_map_style_dataset(train_iter)\n",
    "test_dataset = to_map_style_dataset(test_iter)\n",
    "num_train = int(len(train_dataset) * 0.8)\n",
    "split_train_, split_valid_ = random_split(\n",
    "    train_dataset, [num_train, len(train_dataset) - num_train]\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    split_train_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
    ")\n",
    "valid_dataloader = DataLoader(\n",
    "    split_valid_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2abb8af-8fe2-4382-8adf-7d2af9cd8e09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "today = date.today().isoformat()\n",
    "\n",
    "# Hyperparameters\n",
    "EPOCHS = 20  # epoch\n",
    "LR = 0.01 # learning rate\n",
    "    \n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "    \n",
    "def train_with_hist(model, checkpoint_path = './models/simple_embeddings_baseline'):\n",
    "    model = model.to(device)\n",
    "    \n",
    "    total_accu = None\n",
    "\n",
    "    loss_hist_train, loss_hist_valid, accuracy_hist_train, accuracy_hist_valid = [], [], [], []\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        accu_train, loss_train = train(model, train_dataloader, epoch)\n",
    "        accu_val, loss_val = evaluate(model, valid_dataloader)\n",
    "        if total_accu is not None and total_accu > accu_val:\n",
    "            scheduler.step()\n",
    "            print(\"Learning rate took a step by the scheduler {:8.3f} > {:8.3f}\".format(total_accu, accu_val))\n",
    "        else:\n",
    "            total_accu = accu_val\n",
    "        print(\"-\" * 59)\n",
    "        print(\n",
    "            \"| end of epoch {:3d} | time: {:5.2f}s | \"\n",
    "            \"valid accuracy {:8.3f} \".format(\n",
    "                epoch, time.time() - epoch_start_time, accu_val\n",
    "            )\n",
    "        )\n",
    "        print(\"-\" * 59)\n",
    "\n",
    "        loss_hist_train.append(loss_train)\n",
    "        loss_hist_valid.append(loss_val)\n",
    "        accuracy_hist_train.append(accu_train)\n",
    "        accuracy_hist_valid.append(accu_val)\n",
    "        \n",
    "    torch.save(model, f'{checkpoint_path}/{today}_bidirectional_gru_glove.pt')\n",
    "    return loss_hist_train, loss_hist_valid, accuracy_hist_train, accuracy_hist_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e7023b-7888-4afe-906a-76ac56aacab8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hist = train_with_hist(model, './models/bidirectional_gru_glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3a2a32-9601-4458-82d3-b169d7e74ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_learning_curves(hist):\n",
    "    x_arr = np.arange(len(hist[0])) + 1\n",
    "    fig = plt.figure(figsize=(12, 4))\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    ax.plot(x_arr, hist[0], '-o', label='Train loss')\n",
    "    ax.plot(x_arr, hist[1], '--<', label='Validation loss')\n",
    "    ax.legend(fontsize=15)\n",
    "    ax = fig.add_subplot(1, 2, 2)\n",
    "    ax.plot(x_arr, hist[2], '-o', label='Train acc.')\n",
    "    ax.plot(x_arr, hist[3], '--<', label='Validation acc.')\n",
    "    ax.legend(fontsize=15)\n",
    "    ax.set_xlabel('Epoch', size=15)\n",
    "    ax.set_ylabel('Accuracy', size=15)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6a0c1b-3a25-4cff-96c6-3266913e208e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3a230c-2886-4676-9a87-6bac8b503bb4",
   "metadata": {},
   "source": [
    "### Evaluate the model with test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29c316c-7bce-4176-b1fa-00dd769a6a1a",
   "metadata": {},
   "source": [
    "Checking the results of the test dataset…\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc0b680-b1de-4aee-bad4-baf7f50b9f0e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"Checking the results of test dataset.\")\n",
    "accu_test, _ = evaluate(model, test_dataloader)\n",
    "print(\"test accuracy {:8.3f}\".format(accu_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9b09f4-0640-4e59-aefc-9d2d136d9f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create confusion matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_confusion_matrix(model, dataloader):\n",
    "    model.eval()\n",
    "    y_test = np.asarray([])\n",
    "    y_predict = np.asarray([])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text) in enumerate(dataloader):\n",
    "            predicted_label = model(text)\n",
    "                  \n",
    "            y_test = np.concatenate((y_test, np.asarray(label.to(device='cpu', dtype=torch.long))), axis=None)\n",
    "            y_predict = np.concatenate((y_predict, np.asarray((predicted_label.argmax(1).to(device='cpu', dtype=torch.long)))), axis=None)\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_predict)\n",
    "    sns.heatmap(cm, annot=True, fmt = \"d\")\n",
    "    print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efeb419-1df7-4e6c-8814-ddf3294b9b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a457def5-9ac2-48c9-a2ef-69ead17b1834",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    with torch.no_grad():\n",
    "        text = torch.tensor(text_pipeline(text)).to('cpu')\n",
    "        padded = torch.tensor(pad_sequences(text, MAX_LENGTH), dtype=torch.long).to(device)\n",
    "        output = model(padded.unsqueeze(0))\n",
    "        return output.argmax(1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c741cb-e91b-406f-a1f7-3c0ff292ab24",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_text_str = 'The ePump Software shall define Fault ID 1 as follows:'\n",
    "\n",
    "print(\"This is a %s\" % predict(ex_text_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cc330f-c045-4453-a430-d19c5cac6bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_text = \"The IO Service shall select the XLR-PW DEV_INFO_DATA file if HPP_XLR_WIRING is grounded (logical 1) and bits AC_TYPE_BIT1 - AC_TYPE_BIT6 do not indicate a CFM engine configuration. NOTE: HPP_XLR_WIRING and bits AC_TYPE_BIT[1-6] are discrete inputs which are received on constant pins between hardware configurations. See 282100-ICD-x for more details.\"\n",
    "predict(pred_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587df1de-6144-420e-a789-7771209aeca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_text = \"I shall like waffles\"\n",
    "predict(pred_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f924b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_text = \"Bumblebe is red\"\n",
    "predict(pred_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0e6726",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_text = \"Bumblebee is red\"\n",
    "predict(pred_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086ab3e9-5b8e-4f0c-8975-b1f9f5a2d3d8",
   "metadata": {},
   "source": [
    "# Hyperparameter tunning with Ray Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d26d5c-91db-45ec-b401-a3119efaf4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime, date\n",
    "\n",
    "import ray\n",
    "import ray.train.torch\n",
    "\n",
    "from ray import train, tune\n",
    "from ray.train import RunConfig, ScalingConfig, Checkpoint\n",
    "from ray.train.torch import TorchTrainer\n",
    "\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68b25ef-4f6f-4a2d-bffe-f4f601d3065e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.train.torch.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8fcff0-dc66-47d0-93b0-97d36db30c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "MAX_LENGTH = 100\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list = [], []\n",
    "    for _label, _text in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = text_pipeline(_text)\n",
    "        padded = pad_sequences(processed_text, MAX_LENGTH)\n",
    "        text_list.append(padded)\n",
    "        \n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    text_list = torch.tensor(text_list, dtype=torch.long)\n",
    "    return label_list, text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a136fd2-2ad0-4eb2-80fe-b60e33ef08f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func(model, optimizer, train_loader, max_norm):  \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.train()\n",
    "    \n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 5\n",
    "    start_time = time.time()\n",
    "    total_loss = 0\n",
    "\n",
    "    for idx, (label, text) in enumerate(train_loader):           \n",
    "        label, text = label.to(device), text.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predicted_label = model(text)\n",
    "        loss = criterion(predicted_label, label)\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n",
    "        optimizer.step()\n",
    "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        total_loss += loss.item()\n",
    "         \n",
    "    return total_acc / total_count, total_loss / total_count\n",
    "        \n",
    "\n",
    "def eval_func(model, data_loader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    \n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text) in enumerate(data_loader):\n",
    "            label, text = label.to(device), text.to(device)\n",
    "            \n",
    "            predicted_label = model(text)\n",
    "            loss = criterion(predicted_label, label)\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "\n",
    "    return total_acc / total_count, loss.item() / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6d59bf-084a-445c-9723-2fe6b38678a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "today = date.today().isoformat()\n",
    "checkpoint_path = \"./models/bidirectional_gru_glove\"\n",
    "model_name = \"bidirectional_gru_glove\"\n",
    "num_class = 2\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "\n",
    "def train_search(config):\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    # print(device)\n",
    "    # print(config)\n",
    "    # config_params = config[\"params\"]\n",
    "    config_params = config\n",
    "    # print(config_params)\n",
    "    \n",
    "    \n",
    "    # Embeddings size depends on the GloVe embeddings defined for the tokenizer\n",
    "    model = GRU_Model(vocab_size, \n",
    "                      GLOVE_DIM, \n",
    "                      config_params[\"hidden_size\"], \n",
    "                      config_params[\"num_layers\"], \n",
    "                      num_class,\n",
    "                      config_params[\"dropout\"], \n",
    "                     )\n",
    "    model = model.to(device)\n",
    "    \n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        split_train_, batch_size=config_params[\"batch_size\"], shuffle=True, collate_fn=collate_batch\n",
    "    )\n",
    "    valid_dataloader = DataLoader(\n",
    "        split_valid_, batch_size=config_params[\"batch_size\"], shuffle=True, collate_fn=collate_batch\n",
    "    )\n",
    "    test_dataloader = DataLoader(\n",
    "        test_dataset, batch_size=config_params[\"batch_size\"], shuffle=True, collate_fn=collate_batch\n",
    "    )\n",
    "    \n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=config_params[\"lr\"])\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=config_params[\"lr\"], momentum=config_params[\"momentum\"])\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=config_params[\"step_size\"], gamma=config_params[\"lr_gamma\"])\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(1, config_params[\"epochs\"] + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        accu_train, loss_train = train_func(model, optimizer, train_dataloader, config_params[\"max_norm\"])\n",
    "        accu_val, loss_val = eval_func(model, valid_dataloader)\n",
    "        \n",
    "        # Always let the scheduler take a step because it will be optimized by Hyperopt\n",
    "        scheduler.step()\n",
    "            \n",
    "        with tempfile.TemporaryDirectory() as temp_checkpoint_dir:\n",
    "            checkpoint = None\n",
    "            if epoch % 5 == 0:\n",
    "                # This saves the model to the trial directory\n",
    "                torch.save(\n",
    "                    model.state_dict(),\n",
    "                    os.path.join(temp_checkpoint_dir, \"model.pth\")\n",
    "                )\n",
    "                checkpoint = Checkpoint.from_directory(temp_checkpoint_dir)\n",
    "\n",
    "            # Send the current training result back to Ray Tune\n",
    "            train.report({\n",
    "                \"loss_train\": loss_train,\n",
    "                \"loss_val\": loss_val,\n",
    "                \"accuracy_train\": accu_train,\n",
    "                \"accuracy_val\": accu_val,\n",
    "            }, checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d1747a-3da6-4ccf-ae86-06ba3f085def",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08169282-f1d6-4fab-976b-a1dc59bd4a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "(free_memory, global_memory) = torch.cuda.mem_get_info()\n",
    "print(f\"Free(GB): {free_memory/1024/1024/1024}, Global(GB): {global_memory/1024/1024/1024}, Free(%): {free_memory/global_memory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f969121-7186-4843-8199-eeeb32ecaa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from guppy import hpy\n",
    "h=hpy()\n",
    "h.heap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c97b083-e6c5-4494-925f-fc747c2622ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hyperopt import hp\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "\n",
    "exp_name = \"bidirectional_gru_glove\"\n",
    "\n",
    "space = {\n",
    "    \"lr\": hp.loguniform(\"lr\", -3, 1),\n",
    "    \"momentum\": hp.uniform(\"momentum\", 0.1, 0.9),\n",
    "    \"hidden_size\": hp.choice(\"hidden_size\", [32, 64, 128]), \n",
    "    \"num_layers\": hp.randint(\"num_layers\", 3, 10),\n",
    "    \"epochs\": hp.choice(\"epochs\", [30]),\n",
    "    \"batch_size\": hp.choice(\"batch_size\", [16, 32]),\n",
    "    \"step_size\": hp.randint(\"step_size\", 1, 10),\n",
    "    \"lr_gamma\": hp.uniform(\"lr_gamma\", 0.1, 0.9),\n",
    "    \"max_norm\": hp.uniform(\"max_norm\", 0.1, 0.9),\n",
    "    \"dropout\": hp.uniform(\"dropout\", 0.1, 0.9),\n",
    "}\n",
    "\n",
    "hyperopt_search = HyperOptSearch(space, metric=\"accuracy_val\", mode=\"max\")\n",
    "\n",
    "# Uncomment this to enable distributed execution\n",
    "# `ray.init(address=\"auto\")`\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    tune.with_resources(train_search, resources={\"cpu\":8, \"gpu\":0.5}),\n",
    "    tune_config=tune.TuneConfig(\n",
    "        num_samples=30,\n",
    "        scheduler=ASHAScheduler(metric=\"accuracy_val\", mode=\"max\"), # Early stopping\n",
    "        search_alg=hyperopt_search, # Hyperopt library for Hyper-parameter Optimization\n",
    "    ),\n",
    "    run_config=train.RunConfig(\n",
    "        name=exp_name,\n",
    "        checkpoint_config=train.CheckpointConfig(\n",
    "            checkpoint_score_attribute=\"accuracy_val\",\n",
    "            num_to_keep=2,\n",
    "            # checkpoint_at_end=True\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "results = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119d601f-dd66-4cd0-80fc-c20c9d1bbcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {result.path: result.metrics_dataframe for result in results}\n",
    "[d[\"accuracy_val\"].plot() for d in dfs.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378f0084-7590-44c3-93fc-1c9c3ffc1cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = results.get_best_result(\"accuracy_val\", \"max\")\n",
    "best_result.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5113bed-cb8a-4c83-93e5-9b9d97048b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result.metrics_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930804d9-9ed6-4f83-a5a9-7cbcbe80f865",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = best_result.metrics_dataframe\n",
    "\n",
    "plt.plot(df['accuracy_train'], label='accuracy_train')\n",
    "plt.plot(df['accuracy_val'], label='accuracy_val')\n",
    "\n",
    "plt.legend(title='')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68a3a4e-4dc2-405b-afb3-85ba39c1187c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_checkpoints = best_result.best_checkpoints\n",
    "best_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac0a6eb-a103-4311-9e0a-fec79ae9ed4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_checkpoint = best_result.get_best_checkpoint(\"accuracy_val\", mode=\"max\")\n",
    "next(x for x in best_checkpoints if x[0].path == best_checkpoint.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce37b88-08c0-4cd3-b052-dae63c0740c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(os.path.join(best_checkpoint.path, \"model.pth\"))\n",
    "\n",
    "num_class = 2\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "model = GRU_Model(vocab_size, \n",
    "                      GLOVE_DIM, \n",
    "                      best_result.config[\"hidden_size\"], \n",
    "                      best_result.config[\"num_layers\"], \n",
    "                      num_class,\n",
    "                      best_result.config[\"dropout\"], \n",
    "                     )\n",
    "\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28a29cd-018f-4c7c-b882-9d56487fdba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "uq_path = today + \"_\" + \"_\".join(best_result.path.split(\"=\")[0].split(\"/\")[-2:])\n",
    "save_path = os.path.join('./models/bidirectional_gru_glove', uq_path + \"_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89334d44-3c21-46eb-a29d-2d70ba9f1c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfaa04e-fcbb-493e-9132-eb1773de1f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_excel('TestDataset.xlsx')\n",
    "test_df = test_df[['E1','Text']]\n",
    "#Convert E1 column values to integers\n",
    "test_df['E1'] = test_df['E1'].astype(int)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a94a7bf-8b89-46af-84e4-84de174acdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.functional import to_map_style_dataset\n",
    "\n",
    "test_iter = iter(list(test_df.itertuples(index=False, name=None)))\n",
    "test_dataset = to_map_style_dataset(test_iter)\n",
    "    \n",
    "test_dataloader = DataLoader(test_dataset,\n",
    "                             batch_size=64,\n",
    "                             shuffle=False,\n",
    "                             collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b896ca26-25c1-4edd-a619-737e2f50e2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7503476a-6c2f-4329-bf19-4da50a9c9e88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genety",
   "language": "python",
   "name": "genety"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
